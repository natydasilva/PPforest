[{"path":"https://github.com/natydasilva/PPforest/articles/PPforest-vignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"PPforest","text":"PPforest package (projection pursuit random forest) contains functions fit projection pursuit random forest classification problems described (da Silva, Cook, Lee 2021). method utilize combinations variables tree construction. random forest split based single variable, chosen subset predictors. PPforest, split based linear combination randomly chosen variables. linear combination computed optimizing projection pursuit index, get projection variables best separates classes. PPforest uses PPtree algorithm (Y. D. Lee et al. 2013), fits single tree data. Utilizing linear combinations variables separate classes takes correlation variables account, can outperform basic forest separations groups occurs combinations variables. Two projection pursuit indexes, LDA PDA, used PPforest. improve speed performance PPforest package, PPtree algorithm translated Rcpp. PPforest package utilizes number R packages included “suggests” load package start-. can install package CRAN: development version PPforest can installed github using:","code":"install.package(PPforest) library(PPforest) library(devtools) install_github(\"natydasilva/PPforest\") library(PPforest)"},{"path":"https://github.com/natydasilva/PPforest/articles/PPforest-vignette.html","id":"projection-pursuit-classification-forest","dir":"Articles","previous_headings":"","what":"Projection pursuit classification forest","title":"PPforest","text":"PPforest, projection pursuit classification trees used individual model combined forest. original algorithm PPtreeViz package, translate original tree algorithm Rcpp improve speed performance run forest. One important characteristic PPtree treats data always two-class system, classes two algorithm uses two step projection pursuits optimization every node split. Let (Xi,yi)(X_i,y_i) data set, XiX_i p-dimensional vector explanatory variables yi∈1,2,…Gy_i\\{1,2,\\ldots G} represents class information =1,…ni=1,\\ldots n. first step optimize projection pursuit index find optimal one-dimension projection α*\\alpha^* separating classes current data. projected data redefine problem two class problem comparing means, assign new label G1G1 G2G2 observation, new variable yi*y_i^* created. new groups G1G1 G2G2 can contain one original classes. Next step find optimal one-dimensional projection α\\alpha, using (Xi,yi*)(X_i,y_i^*) separate two class problem G1G1 G2G2. best separation G1G1 G2G2 determine step decision rule defined current node, ∑=1pαiM1<c\\sum_{=1}^p \\alpha_i M1< c assign G1G1 left node else assign G2G2 right node, M1M1 mean G1G1. groups can repeat previous steps G1G1 G2G2 one class original classes. Base process grow tree, depth PPtree number classes one class assigned one final node. Trees PPtree algorithm simple, use association variables find separation. linear boundary exists, PPtree produces tree without misclassification. Projection pursuit random forest algorithm description Let N number cases training set Θ=(X,Y)\\Theta=(X,Y), BB bootstrap samples training set taking (samples size N replacement). bootstrap sample \\verb PPtree grown largest extent possible h(x,Θk)h(x, {\\Theta_k}). pruning. tree grown using step 3 modification. Let M number input variables, number m<<Mm<<M variables selected random node best split based linear combination randomly chosen variables. linear combination computed optimizing projection pursuit index, get projection variables best separates classes. Predict classes case included bootstrap sample compute oob error. Based majority vote predict class new data.","code":""},{"path":"https://github.com/natydasilva/PPforest/articles/PPforest-vignette.html","id":"overview-ppforest-package","dir":"Articles","previous_headings":"Projection pursuit classification forest","what":"Overview PPforest package","title":"PPforest","text":"PPforest package implements classification random forest using projection pursuit classification trees. following table present functions PPforest package. Also PPforest package includes data set used test predictive performance method. data sets included : crab, fishcatch, glass, image, leukemia, lymphoma NCI60, parkinson wine.","code":""},{"path":"https://github.com/natydasilva/PPforest/articles/PPforest-vignette.html","id":"example","dir":"Articles","previous_headings":"Projection pursuit classification forest","what":"Example","title":"PPforest","text":"Australian crab data set used example. data contains measurements rock crabs genus Leptograpsus. 200 observations two species (blue orange) specie (50 one) 50 males 50 females. Class variable 4 classes combinations specie sex (BlueMale, BlueFemale, OrangeMale OrangeFemale). data collected site Fremantle, Western Australia. specimen, five measurements made, using vernier calipers. FL size frontal lobe length, mm RW rear width, mm CL length mid line carapace, mm CW maximum width carapace, mm BD depth body; females, measured displacement abdomen, mm visualize data set use scatterplot matrix package GGally     Scatter plot matrix crab data     figure can see strong, positive linear association different variables. Also look like classes can separated linear combinations. main function package PPforest implements projection pursuit random forest. PPtree_split function implements projection pursuit classification tree random variable selection split, based original PPtree algorithm PPtreeViz R package (E.-K. Lee 2018). function returns PPtreeclass object. use function need specify formula describing model fitted response~predictors (form), data data frame complete data set. Also need specify method PPmethod, index use projection pursuit: ‘LDA’ ‘PDA’, size.p proportion variables randomly sampled split. size.p = 1 classic PPtreeclass object fitted using variables node partition instead subset . lambda penalty parameter PDA index 0 1 . following example fits projection pursuit classification tree constructed using 0.6 variables (3 5) node split. selected LDA method. PPforest function runs projection pursuit random forest. arguments data data.frame data information, y character name class variable. size.tr specify proportion observations using training. Using function option split data training test using size.tr internally PPforest function. size.tr proportion data used training test proportion 1- size.tr. number trees forest specified using argument m. argument size.p sample proportion variables used node split, PPmethod projection pursuit index optimized, two options LDA PDA available. algorithm can parallelized using parallel cores arguments. PPforest print summary result model confusion matrix information oob-error rate similar way randomForest packages . function returns predicted values training data, training error, test error predicted test values. Also information bag error forest also tree forest. Bootstrap samples, output trees forest , proximity matrix vote matrix, number trees grown forest, number predictor variables selected use splitting node. Confusion matrix prediction (based OOb data), training data test data vote matrix also returned. printed version PPforest object follows randomForest printed version make comparable. Based confusion matrix, can observe biggest error BlueMale class. wrong classified values BlueFemale BlueMale. output PPforest object contains lot information can see next output. example get predicted values test data can use PPforest output: new data available can use function trees_pred get predicted classes PPforest object. predict(object = pprf.crab,  newdata) PPforest algorithm calculates variable importance two ways: (1) permuted importance using accuracy, (2) importance based projection coefficients standardized variables. permuted variable importance comparable measure defined classical random forest algorithm. computed using bag (oob) sample tree k(B(k))k\\;\\;(B^{(k)}) XjX_j predictor variable. permuted importance variable XjX_j tree kk can defined : IMP(k)(Xj)=∑∈B(k)(yi=ŷ(k))−(yi=ŷ,Pj(k))|B(k)| IMP^{(k)}(X_j) = \\frac{\\sum_{\\B^{(k)} } (y_i=\\hat y_i^{(k)})-(y_i=\\hat y_{,P_j}^{(k)})}{|B^{(k)}|} ŷ(k)\\hat y_i^{(k)} predicted class observation ii tree kk yi,Pj(k)y_{,P_j}^{(k)} predicted class observation ii tree kk permuting values variable XjX_j. global permuted importance measure average importance trees forest. measure based comparing accuracy classifying --bag observations, using true class permuted (nonsense) class. compute measure use permute_importance function.         Permuted importance variable     function returns data frame permuted importance measures, imp permuted importance measure defined Brieman paper, imp2 permuted importance measure defined randomForest package, standard deviation (sd.im sd.imp2) measure computed also standardized measure. second importance measure, coefficients projection examined. magnitude values indicates importance, variables standardized. variable importance single tree computed weighted sum absolute values coefficients across nodes. weights takes number classes node account (Y. D. Lee et al. 2013). importance variable XjX_j PPtree kk can defined : IMPpptree(k)(Xj)=∑nd=1nn|αnd(k)|clnd   IMP_{pptree}^{(k)}(X_j)=\\sum_{nd = 1}^{nn}\\frac{|\\alpha_{nd}^{(k)}|}{cl_{nd} } αnd(k)\\alpha_{nd}^{(k)} projected coefficient node nsns variable kk nnnn total number node partitions tree kk. global variable importance PPforest can defined different ways. intuitive average variable importance PPtree across trees forest. IMPppforest1(Xj)=∑k=1KIMPpptree(k)(Xj)K IMP_{ppforest1}(X_j)=\\frac{\\sum_{k=1}^K IMP_{pptree}^{(k)}(X_j)}{K} Alternatively defined global importance measure forest weighted mean absolute value projection coefficients across nodes every tree. weights based projection pursuit indexes node (IxndIx_{nd}), 1-(OOB-error tree)(acckacc_k). IMPppforest2(Xj)=∑k=1Kacck∑nd=1nnIxnd|αnd(k)|nnKIMP_{ppforest2}(X_j)=\\frac{\\sum_{k=1}^K acc_k \\sum_{nd = 1}^{nn}\\frac{Ix_{nd}|\\alpha_{nd}^{(k)}|}{nn }}{K}          Average importance variable     Finally can get last importance measure proposed PPforest using `ppf_global_imp’ function.         Global importance variable Using information available PPforest object, visualization can done. include useful examples visualize data important diagnostics forest structure. describe data structure parallel plot can done, data standardized color represents class variable.     Parallel coordinate plot crab data     ternary_str auxiliary functions PPforest get data structure needed ternary plot generalized ternary plot 3 classes available. PPforest composed many tree fits subsets data, lot statistics can calculated analyze separate data set, better understand model working. diagnostics interest : variable importance, OOB error rate, vote matrix proximity matrix. decision tree can compute every pair observations proximity matrix. nxnnxn matrix two cases kik_i kjk_j terminal node increase proximity one, end normalize proximities dividing number trees. visualize proximity matrix use scatter plot information multidimensional scaling method. plot color indicates true species sex. data two dimensions enough see four groups separated quite well. crabs clearly similar different group, though, especially examining sex differences.     Multidimensional scaling plot examine similarities cases     vote matrix (n×pn \\times p) contains proportion times observation classified class, whole oob. Two possible approaches visualize vote matrix information shown, side--side jittered dot plot ternary plots. side--side jittered dotplot used display, class displayed one axis proportion displayed . dotplot, ideal arrangement points observations class values bigger 0.5, observations less. data close ideal perfect, e.g. blue male crabs (orange) frequently predicted blue females (green), blue female crabs predicted another class.     Vote matrix representation jittered side--side dotplot. dotplot shows proportion times case predicted group, 1 indicating case always predicted group 0 never.     ternary plot triangular diagram shows proportion three variables sum constant done using barycentric coordinates. Compositional data lies (p−1)(p-1)-D simplex pp-space. One advantage ternary plot good visualize compositional data proportion three variables two dimensional space can shown. tree classes ternary plot well defined. tree classes ternary plot idea need generalized.@sutherland2000orca suggest best approach visualize compositional data project data (p−1)−(p-1)-D space (ternary diagram 2−D2-D) approach used visualize vote matrix information. ternary plot triangular diagram used display compositional data three components. generally, compositional data can number components, say pp, hence contrained (p−1)(p-1)-D simplex pp-space. vote matrix example compositional data, GG components.     Generalized ternary plot representation vote matrix four classes. tetrahedron shown pairwise. point corresponds one observation color true class.     see complete description visualize PPforest object read Interactive Graphics Visually Diagnosing Forest Classifiers R (da Silva, Cook, Lee 2025).","code":"Tree.crab <- PPforest::PPtree_split(\"Type~.\", data = crab, PPmethod = \"LDA\", size.p = 0.6)  Tree.crab ## =============================================================  ## Projection Pursuit Classification Tree result  ## ============================================================= ##  ## 1) root ##    2)  proj1*X < cut1 ##       4)* proj2*X < cut2  ->  \"BlueMale\" ##       5)* proj2*X >= cut2  ->  \"BlueFemale\" ##    3)  proj1*X >= cut1 ##       6)* proj3*X < cut3  ->  \"OrangeMale\" ##       7)* proj3*X >= cut3  ->  \"OrangeFemale\" ##  ## Error rates of various cutoff values  ## ------------------------------------------------------------- ##            Rule1 Rule2 Rule3 Rule4 Rule5 Rule6 Rule7 Rule8 ## error.rate 0.065 0.065 0.065 0.065 0.075 0.075 0.075 0.075 pprf.crab <- PPforest::PPforest(data = crab, y = \"Type\", std = 'min-max', size.tr = .7, m = 200,                                 size.p =  .8,  PPmethod = 'LDA',  parallel = TRUE, cores = 2)  pprf.crab ##  ## Call: ##  PPforest::PPforest(data = crab, y = \"Type\", std = \"min-max\",      size.tr = 0.7, m = 200, PPmethod = \"LDA\", size.p = 0.8, parallel = TRUE,      cores = 2)  ##                Type of random forest: Classification ##                      Number of trees: 200 ## No. of variables tried at each split: 4 ##  ##         OOB estimate of  error rate: 5.71% ## Confusion matrix: ##              BlueFemale BlueMale OrangeFemale OrangeMale class.error ## BlueFemale           33        2            0          0        0.06 ## BlueMale              4       31            0          0        0.11 ## OrangeFemale          0        0           33          2        0.06 ## OrangeMale            0        0            0         35        0.00 str(pprf.crab, max.level = 1 ) ## List of 28 ##  $ predicting.training: Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 2 1 2 2 2 1 2 2 ... ##  $ training.error     : num 0.05 ##  $ prediction.test    : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 2 1 2 1 2 2 2 2 ... ##  $ error.test         : num 0.0833 ##  $ oob.error.forest   : num 0.0571 ##  $ oob.error.tree     : num [1:200, 1] 0.1346 0.06 0.08 0.08 0.0222 ... ##  $ boot.samp          :List of 200 ##  $ output.trees       :List of 200 ##  $ proximity          : num [1:140, 1:140] 0 0.805 0.825 0.35 0.835 0.675 0.665 0.625 0.805 0.635 ... ##  $ votes              : num [1:140, 1:4] 0.342 0.514 0.2 0.701 0.175 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##  $ prediction.oob     : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 1 2 1 2 2 2 1 2 2 ... ##  $ n.tree             : num 200 ##  $ n.var              : int 4 ##  $ type               : chr \"Classification\" ##  $ confusion          : num [1:4, 1:5] 33 4 0 0 2 31 0 0 0 0 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##  $ call               : language PPforest::PPforest(data = crab, y = \"Type\", std = \"min-max\", size.tr = 0.7,      m = 200, PPmethod = \"LDA\", size.| __truncated__ ##  $ train              :'data.frame': 140 obs. of  6 variables: ##  $ test               :'data.frame': 60 obs. of  6 variables: ##  $ vote.mat           : num [1:200, 1:140] 2 4 2 2 2 2 2 2 2 1 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##  $ vote.mat_cl        : chr [1:4] \"BlueFemale\" \"BlueMale\" \"OrangeFemale\" \"OrangeMale\" ##  $ class.var          : chr \"Type\" ##  $ oob.obs            : num [1:200, 1:140] 0 0 0 1 0 1 0 0 0 0 ... ##  $ std                : chr \"min-max\" ##  $ dataux             : tibble [140 × 5] (S3: tbl_df/tbl/data.frame) ##  $ mincol             : Named num [1:5] 8.1 6.7 16.1 18.6 7 ##   ..- attr(*, \"names\")= chr [1:5] \"FL\" \"RW\" \"CL\" \"CW\" ... ##  $ maxmincol          : Named num [1:5] 15 13.5 31.5 36 14.6 ##   ..- attr(*, \"names\")= chr [1:5] \"FL\" \"RW\" \"CL\" \"CW\" ... ##  $ train_mean         : NULL ##  $ train_sd           : NULL ##  - attr(*, \"class\")= chr \"PPforest\" pprf.crab$prediction.test ##  [1] BlueMale     BlueMale     BlueMale     BlueFemale   BlueMale     ##  [6] BlueFemale   BlueMale     BlueMale     BlueMale     BlueMale     ## [11] BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     ## [16] BlueMale     BlueFemale   BlueFemale   BlueFemale   BlueFemale   ## [21] BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   ## [26] BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   ## [31] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   ## [36] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   ## [41] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   ## [46] OrangeMale   OrangeMale   OrangeFemale OrangeFemale OrangeFemale ## [51] OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale ## [56] OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale ## Levels: BlueFemale BlueMale OrangeFemale OrangeMale impo1 <- permute_importance(pprf.crab) impo1 ##   nm    imp   sd.imp      imp2   sd.imp2 imp2.std  imp.std ## 1 BD 17.285 7.678448 0.3403903 0.1465104 2.323318 2.251106 ## 2 RW 18.295 6.377408 0.3615318 0.1231153 2.936530 2.868720 ## 3 CW 21.465 6.615710 0.4245943 0.1291092 3.288646 3.244550 ## 4 CL 21.790 7.267737 0.4300271 0.1394407 3.083942 2.998182 ## 5 FL 22.215 7.564714 0.4397407 0.1462055 3.007689 2.936661 impo2 <-  ppf_avg_imp(pprf.crab, \"Type\") impo2 ## # A tibble: 5 × 2 ##   variable  mean ##   <fct>    <dbl> ## 1 CL       0.573 ## 2 CW       0.532 ## 3 RW       0.431 ## 4 FL       0.294 ## 5 BD       0.185 impo3 <- ppf_global_imp(data = crab, y = \"Type\", pprf.crab) impo3 ## # A tibble: 5 × 2 ##   variable  mean ##   <fct>    <dbl> ## 1 CW       0.421 ## 2 CL       0.381 ## 3 RW       0.273 ## 4 FL       0.225 ## 5 BD       0.150"},{"path":[]},{"path":"https://github.com/natydasilva/PPforest/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Natalia da Silva. Author, maintainer. Dianne Cook. Author. Eun-Kyung Lee. Author.","code":""},{"path":"https://github.com/natydasilva/PPforest/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"da Silva N, Cook D, Lee E (2025). PPforest: Projection Pursuit Classification Forest. R package version 0.2.0, https://github.com/natydasilva/PPforest.","code":"@Manual{,   title = {PPforest: Projection Pursuit Classification Forest},   author = {Natalia {da Silva} and Dianne Cook and Eun-Kyung Lee},   year = {2025},   note = {R package version 0.2.0},   url = {https://github.com/natydasilva/PPforest}, }"},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"ppforest-package","dir":"","previous_headings":"","what":"Projection Pursuit Classification Forest","title":"Projection Pursuit Classification Forest","text":"Natalia da Silva, Dianne Cook & Eun-Kyung Lee","code":""},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Projection Pursuit Classification Forest","text":"PPforest package (projection pursuit random forest) contains functions run projection pursuit random forest classification problems. method utilize combinations variables tree construction. random forest split based single variable, chosen subset predictors. PPforest, split based linear combination randomly chosen variables. linear combination computed optimizing projection pursuit index, get projection variables best separates classes. PPforest uses PPtree algorithm, fits single tree data. Utilizing linear combinations variables separate classes takes correlation variables account, can outperform basic forest separations groups occurs combinations variables. Two projection pursuit indexes, LDA PDA, used PPforest. improve speed performance PPforest package, PPtree algorithm translated Rcpp. PPforest package utilizes number R packages included “suggests” load package start-. development version ofPPforest can installed github using: library(devtools) install_github(\"natydasilva/PPforest\") library(PPforest)","code":""},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"overview-ppforest-package","dir":"","previous_headings":"","what":"Overview PPforest package","title":"Projection Pursuit Classification Forest","text":"PPforest package implements classification random forest using projection pursuit classification trees. following table present functions PPforest package. Also PPforest package includes data set used test predictive performance method. data sets included : crab, fishcatch, glass, image, leukemia, lymphoma NCI60, parkinson wine.","code":""},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Projection Pursuit Classification Forest","text":"Australian crab data set used example. data contains measurements rock crabs genus Leptograpsus. 200 observations two species (blue orange) specie (50 one) 50 males 50 females. Class variable 4 classes combinations specie sex (BlueMale, BlueFemale, OrangeMale OrangeFemale). data collected site Fremantle, Western Australia. specimen, five measurements made, using vernier calipers. FL size frontal lobe length, mm RW rear width, mm CL length mid line carapace, mm CW maximum width carapace, mm BD depth body; females, measured displacement abdomen, mm PPforest function runs projection pursuit random forest.arguments data data.frame object data information, y character name class variable. size.tr specify proportion observations using training. Using function option split data training test internally forest PPforest object reports errors. size.tr proportion data used training test proportion 1- size.tr. number trees forest specified using argument m. argument size.p sample proportion variables used node split, PPmethod projection pursuit index optimized, two options LDA PDA available. algorithm can parallelized using parallel cores arguments. PPforest print summary result model confusion matrix information oob-error rate similar way randomForest packages . function returns predicted values training data, training error, test error predicted test values. Also information bag error forest also tree forest. Bootstrap samples, output trees forest , proximity matrix vote matrix, number trees grown forest, number predictor variables selected use splitting node. Confusion matrix prediction (based OOb data), training data test data vote matrix also returned. printed version PPforest object follows randomForest printed version make comparable. Based confusion matrix, can observe biggest error BlueMale class. wrong classified values BlueFemale BlueMale. Since PPforest object using internal split can check test error follows also can split data outside forest fit PPforest using training sample define argument size.tr = 1. prediction test data can donde using function predict.","code":"set.seed(123) pprf.crab <- PPforest::PPforest(data = crab, y = \"Type\", size.tr = 0.7, m = 200,                                 size.p =  .5,  PPmethod = 'LDA',  parallel =TRUE, cores = 2)  pprf.crab    Call:  PPforest(data = crab, y = \"Type\", xstd = \"no\", size.tr = 1, m = 3,  PPmethod = \"LDA\", size.p = 1, parallel = TRUE, cores = 2,      rule = 1)                 Type of random forest: Classification                      Number of trees: 3 No. of variables tried at each split: 5          OOB estimate of  error rate: 26.5% Confusion matrix:              BlueFemale BlueMale OrangeFemale OrangeMale class.error BlueFemale           48        2            0          0        0.04 BlueMale             21       29            0          0        0.42 OrangeFemale         14        0           33          3        0.34 OrangeMale           13        0            0         37        0.26 str(pprf.crab, max.level = 1) List of 28  $ predicting.training: Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 2 2 1 2 2 1 2 1 ...  $ training.error     : num 0.0571  $ prediction.test    : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 2 2 2 2 2 2 2 2 ...  $ error.test         : num 0.0667  $ oob.error.forest   : num 0.0643  $ oob.error.tree     : num [1:200, 1] 0.1961 0.0625 0.1429 0.0408 0.1923 ...  $ boot.samp          :List of 200  $ output.trees       :List of 200  $ proximity          : num [1:140, 1:140] 0 0.79 0.735 0.8 0.36 0.825 0.71 0.265 0.46 0.36 ...  $ votes              : num [1:140, 1:4] 0.243 0.288 0.183 0.235 0.835 ...   ..- attr(*, \"dimnames\")=List of 2  $ prediction.oob     : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 2 2 1 2 2 1 2 1 ...  $ n.tree             : num 200  $ n.var              : int 3  $ type               : chr \"Classification\"  $ confusion          : num [1:4, 1:5] 33 4 0 0 2 31 0 1 0 0 ...   ..- attr(*, \"dimnames\")=List of 2  $ call               : language PPforest::PPforest(data = crab, y = \"Type\", size.tr = 0.7, m = 200, PPmethod = \"LDA\", size.p = 0.5,      parallel| __truncated__  $ train              :'data.frame':    140 obs. of  6 variables:  $ test               :'data.frame':    60 obs. of  6 variables:  $ vote.mat           : num [1:200, 1:140] 1 2 4 2 2 2 2 4 1 1 ...   ..- attr(*, \"dimnames\")=List of 2  $ vote.mat_cl        : chr [1:4] \"BlueFemale\" \"BlueMale\" \"OrangeFemale\" \"OrangeMale\"  $ class.var          : chr \"Type\"  $ oob.obs            : num [1:200, 1:140] 0 0 0 0 0 0 1 1 0 1 ...  $ std                : chr \"scale\"  $ dataux             : num [1:140, 1:5] -2.14 -1.71 -1.65 -1.36 -1.28 ...   ..- attr(*, \"dimnames\")=List of 2   ..- attr(*, \"scaled:center\")= Named num [1:5] 15.5 12.8 32 36.3 14   .. ..- attr(*, \"names\")= chr [1:5] \"FL\" \"RW\" \"CL\" \"CW\" ...   ..- attr(*, \"scaled:scale\")= Named num [1:5] 3.47 2.57 7.06 7.84 3.4   .. ..- attr(*, \"names\")= chr [1:5] \"FL\" \"RW\" \"CL\" \"CW\" ...  $ mincol             : NULL  $ maxmincol          : NULL  $ train_mean         : Named num [1:5] 15.5 12.8 32 36.3 14   ..- attr(*, \"names\")= chr [1:5] \"FL\" \"RW\" \"CL\" \"CW\" ...  $ train_sd           : Named num [1:5] 3.47 2.57 7.06 7.84 3.4   ..- attr(*, \"names\")= chr [1:5] \"FL\" \"RW\" \"CL\" \"CW\" ...  - attr(*, \"class\")= chr \"PPforest\" pprf.crab$error.test [1] 0.06666667 set.seed(123)  train <- sample(1:nrow(crab), nrow(crab)*.7)  crab_train <- data.frame(crab[train, ])  crab_test <- data.frame(crab[-train, ])   pprf.crab <- PPforest(data = crab_train, class = 'Type',    std = 'scale', size.tr = 1, m = 200, size.p = .4, PPmethod = 'LDA', parallel = TRUE )  pred <- predict(pprf.crab, newdata = crab_test[,-1], parallel = TRUE)"},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":null,"dir":"Reference","previous_headings":"","what":"NCI60 data set — NCI60","title":"NCI60 data set — NCI60","text":"NCI60 data set","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NCI60 data set — NCI60","text":"","code":"data(NCI60)"},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NCI60 data set — NCI60","text":"cDNA microarrays used examine variation gene expression among 60 cell lines.  cell lines derived tumors different sites origin. data set contain 61 observations 30 feature variables 8 different tissue types. Type 8 different tissue types, 9 cases breast, 5 cases central nervous system (CNS), 7 cases pf colon, 8 cases leukemia, 8 cases melanoma, 9 cases  non-small-cell lung carcinoma (NSCLC), 6 cases ovarian 9 cases renal. Gene1, Gen2, ..., Gen30 Numeric gene expression information. data frame 61 rows 31 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NCI60 data set — NCI60","text":"Dudoit, S., Fridlyand, J. Speed, T. P. (2002). Comparison Discrimination Methods Classification Tumors Using Gene Expression Data. Journal American statistical Association 97 77-87.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"Predict class test set calculate prediction error finding PPtree structure, .","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"","code":"PPclassify( Tree.result, test.data = NULL, Rule = 1, true.class = NULL)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"Tree.result result PPtree_split test.data test dataset Rule split rule 1:mean two group means, 2:weighted mean, 3: mean max(left group) min(right group), 4: weighted mean max(left group) min(right group) true.class true class test dataset available","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"predict.class predicted class predict.error prediction error","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"Lee, YD, Cook, D., Park JW, Lee, EK(2013) PPtree: Projection pursuit classification tree, Electronic Journal Statistics, 7:1369-1386.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"Predict class test set calculate prediction error finding PPtree structure, .","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"","code":"PPclassify2( Tree.result, test.data = NULL, Rule = 1, true.class = NULL)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"Tree.result result PP.Tree test.data test dataset Rule split rule 1:mean two group means, 2:weighted mean, 3: mean max(left group) min(right group), 4: weighted mean max(left group) min(right group) true.class true class test dataset available","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"predict.class predicted class predict.error prediction error","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"Lee, YD, Cook, D., Park JW, Lee, EK(2013) PPtree: Projection pursuit classification tree, Electronic Journal Statistics, 7:1369-1386.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"","code":"#crab data set  Tree.crab <- PPtree_split('Type~.', data = crab, PPmethod = 'LDA', size.p = 0.5) Tree.crab #> $Tree.Struct #>      id L.node.ID R.F.node.ID Coef.ID     Index #> [1,]  1         2           3       1 0.8696281 #> [2,]  2         4           5       2 0.7106348 #> [3,]  3         6           7       3 0.8183021 #> [4,]  4         0           2       0 0.0000000 #> [5,]  5         0           1       0 0.0000000 #> [6,]  6         0           4       0 0.0000000 #> [7,]  7         0           3       0 0.0000000 #>  #> $projbest.node #>           [,1]      [,2]       [,3]       [,4]      [,5] #> [1,] 0.6702113 0.0000000  0.0000000 -0.4901992 0.5572447 #> [2,] 0.4102387 0.7901918 -0.4553033  0.0000000 0.0000000 #> [3,] 0.0000000 0.8647947 -0.4711478  0.1736371 0.0000000 #>  #> $splitCutoff.node #>       Rule1     Rule2    Rule3    Rule4     Rule5     Rule6     Rule7     Rule8 #> 1 0.4119657 0.4119657 0.262617 0.262617 0.4291882 0.4291882 0.2647079 0.2647079 #> 2 1.5062172 1.5062172 1.588110 1.588110 1.4780090 1.4780090 1.5739142 1.5739142 #> 3 2.2436484 2.2436484 2.030341 2.030341 2.2778575 2.2778575 2.1885841 2.1885841 #>  #> $origclass #>   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 #> [112] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 #> [149] 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [186] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  #> $origdata #>          FL   RW   CL   CW   BD #>   [1,]  8.1  6.7 16.1 19.0  7.0 #>   [2,]  8.8  7.7 18.1 20.8  7.4 #>   [3,]  9.2  7.8 19.0 22.4  7.7 #>   [4,]  9.6  7.9 20.1 23.1  8.2 #>   [5,]  9.8  8.0 20.3 23.0  8.2 #>   [6,] 10.8  9.0 23.0 26.5  9.8 #>   [7,] 11.1  9.9 23.8 27.1  9.8 #>   [8,] 11.6  9.1 24.5 28.4 10.4 #>   [9,] 11.8  9.6 24.2 27.8  9.7 #>  [10,] 11.8 10.5 25.2 29.3 10.3 #>  [11,] 12.2 10.8 27.3 31.6 10.9 #>  [12,] 12.3 11.0 26.8 31.5 11.4 #>  [13,] 12.6 10.0 27.7 31.7 11.4 #>  [14,] 12.8 10.2 27.2 31.8 10.9 #>  [15,] 12.8 10.9 27.4 31.5 11.0 #>  [16,] 12.9 11.0 26.8 30.9 11.4 #>  [17,] 13.1 10.6 28.2 32.3 11.0 #>  [18,] 13.1 10.9 28.3 32.4 11.2 #>  [19,] 13.3 11.1 27.8 32.3 11.3 #>  [20,] 13.9 11.1 29.2 33.3 12.1 #>  [21,] 14.3 11.6 31.3 35.5 12.7 #>  [22,] 14.6 11.3 31.9 36.4 13.7 #>  [23,] 15.0 10.9 31.4 36.4 13.2 #>  [24,] 15.0 11.5 32.4 37.0 13.4 #>  [25,] 15.0 11.9 32.5 37.2 13.6 #>  [26,] 15.2 12.1 32.3 36.7 13.6 #>  [27,] 15.4 11.8 33.0 37.5 13.6 #>  [28,] 15.7 12.6 35.8 40.3 14.5 #>  [29,] 15.9 12.7 34.0 38.9 14.2 #>  [30,] 16.1 11.6 33.8 39.0 14.4 #>  [31,] 16.1 12.8 34.9 40.7 15.7 #>  [32,] 16.2 13.3 36.0 41.7 15.4 #>  [33,] 16.3 12.7 35.6 40.9 14.9 #>  [34,] 16.4 13.0 35.7 41.8 15.2 #>  [35,] 16.6 13.5 38.1 43.4 14.9 #>  [36,] 16.8 12.8 36.2 41.8 14.9 #>  [37,] 16.9 13.2 37.3 42.7 15.6 #>  [38,] 17.1 12.6 36.4 42.0 15.1 #>  [39,] 17.1 12.7 36.7 41.9 15.6 #>  [40,] 17.2 13.5 37.6 43.9 16.1 #>  [41,] 17.7 13.6 38.7 44.5 16.0 #>  [42,] 17.9 14.1 39.7 44.6 16.8 #>  [43,] 18.0 13.7 39.2 44.4 16.2 #>  [44,] 18.8 15.8 42.1 49.0 17.8 #>  [45,] 19.3 13.5 41.6 47.4 17.8 #>  [46,] 19.3 13.8 40.9 46.5 16.8 #>  [47,] 19.7 15.3 41.9 48.5 17.8 #>  [48,] 19.8 14.2 43.2 49.7 18.6 #>  [49,] 19.8 14.3 42.4 48.9 18.3 #>  [50,] 21.3 15.7 47.1 54.6 20.0 #>  [51,]  7.2  6.5 14.7 17.1  6.1 #>  [52,]  9.0  8.5 19.3 22.7  7.7 #>  [53,]  9.1  8.1 18.5 21.6  7.7 #>  [54,]  9.1  8.2 19.2 22.2  7.7 #>  [55,]  9.5  8.2 19.6 22.4  7.8 #>  [56,]  9.8  8.9 20.4 23.9  8.8 #>  [57,] 10.1  9.3 20.9 24.4  8.4 #>  [58,] 10.3  9.5 21.3 24.7  8.9 #>  [59,] 10.4  9.7 21.7 25.4  8.3 #>  [60,] 10.8  9.5 22.5 26.3  9.1 #>  [61,] 11.0  9.8 22.5 25.7  8.2 #>  [62,] 11.2 10.0 22.8 26.9  9.4 #>  [63,] 11.5 11.0 24.7 29.2 10.1 #>  [64,] 11.6 11.0 24.6 28.5 10.4 #>  [65,] 11.6 11.4 23.7 27.7 10.0 #>  [66,] 11.7 10.6 24.9 28.5 10.4 #>  [67,] 11.9 11.4 26.0 30.1 10.9 #>  [68,] 12.0 10.7 24.6 28.9 10.5 #>  [69,] 12.0 11.1 25.4 29.2 11.0 #>  [70,] 12.6 12.2 26.1 31.6 11.2 #>  [71,] 12.8 11.7 27.1 31.2 11.9 #>  [72,] 12.8 12.2 26.7 31.1 11.1 #>  [73,] 12.8 12.2 27.9 31.9 11.5 #>  [74,] 13.0 11.4 27.3 31.8 11.3 #>  [75,] 13.1 11.5 27.6 32.6 11.1 #>  [76,] 13.2 12.2 27.9 32.1 11.5 #>  [77,] 13.4 11.8 28.4 32.7 11.7 #>  [78,] 13.7 12.5 28.6 33.8 11.9 #>  [79,] 13.9 13.0 30.0 34.9 13.1 #>  [80,] 14.7 12.5 30.1 34.7 12.5 #>  [81,] 14.9 13.2 30.1 35.6 12.0 #>  [82,] 15.0 13.8 31.7 36.9 14.0 #>  [83,] 15.0 14.2 32.8 37.4 14.0 #>  [84,] 15.1 13.3 31.8 36.3 13.5 #>  [85,] 15.1 13.5 31.9 37.0 13.8 #>  [86,] 15.1 13.8 31.7 36.6 13.0 #>  [87,] 15.2 14.3 33.9 38.5 14.7 #>  [88,] 15.3 14.2 32.6 38.3 13.8 #>  [89,] 15.4 13.3 32.4 37.6 13.8 #>  [90,] 15.5 13.8 33.4 38.7 14.7 #>  [91,] 15.6 13.9 32.8 37.9 13.4 #>  [92,] 15.6 14.7 33.9 39.5 14.3 #>  [93,] 15.7 13.9 33.6 38.5 14.1 #>  [94,] 15.8 15.0 34.5 40.3 15.3 #>  [95,] 16.2 15.2 34.5 40.1 13.9 #>  [96,] 16.4 14.0 34.2 39.8 15.2 #>  [97,] 16.7 16.1 36.6 41.9 15.4 #>  [98,] 17.4 16.9 38.2 44.1 16.6 #>  [99,] 17.5 16.7 38.6 44.5 17.0 #> [100,] 19.2 16.5 40.9 47.9 18.1 #> [101,]  9.1  6.9 16.7 18.6  7.4 #> [102,] 10.2  8.2 20.2 22.2  9.0 #> [103,] 10.7  8.6 20.7 22.7  9.2 #> [104,] 11.4  9.0 22.7 24.8 10.1 #> [105,] 12.5  9.4 23.2 26.0 10.8 #> [106,] 12.5  9.4 24.2 27.0 11.2 #> [107,] 12.7 10.4 26.0 28.8 12.1 #> [108,] 13.2 11.0 27.1 30.4 12.2 #> [109,] 13.4 10.1 26.6 29.6 12.0 #> [110,] 13.7 11.0 27.5 30.5 12.2 #> [111,] 14.0 11.5 29.2 32.2 13.1 #> [112,] 14.1 10.4 28.9 31.8 13.5 #> [113,] 14.1 10.5 29.1 31.6 13.1 #> [114,] 14.1 10.7 28.7 31.9 13.3 #> [115,] 14.2 10.6 28.7 31.7 12.9 #> [116,] 14.2 10.7 27.8 30.9 12.7 #> [117,] 14.2 11.3 29.2 32.2 13.5 #> [118,] 14.6 11.3 29.9 33.5 12.8 #> [119,] 14.7 11.1 29.0 32.1 13.1 #> [120,] 15.1 11.4 30.2 33.3 14.0 #> [121,] 15.1 11.5 30.9 34.0 13.9 #> [122,] 15.4 11.1 30.2 33.6 13.5 #> [123,] 15.7 12.2 31.7 34.2 14.2 #> [124,] 16.2 11.8 32.3 35.3 14.7 #> [125,] 16.3 11.6 31.6 34.2 14.5 #> [126,] 17.1 12.6 35.0 38.9 15.7 #> [127,] 17.4 12.8 36.1 39.5 16.2 #> [128,] 17.5 12.0 34.4 37.3 15.3 #> [129,] 17.5 12.7 34.6 38.4 16.1 #> [130,] 17.8 12.5 36.0 39.8 16.7 #> [131,] 17.9 12.9 36.9 40.9 16.5 #> [132,] 18.0 13.4 36.7 41.3 17.1 #> [133,] 18.2 13.7 38.8 42.7 17.2 #> [134,] 18.4 13.4 37.9 42.2 17.7 #> [135,] 18.6 13.4 37.8 41.9 17.3 #> [136,] 18.6 13.5 36.9 40.2 17.0 #> [137,] 18.8 13.4 37.2 41.1 17.5 #> [138,] 18.8 13.8 39.2 43.3 17.9 #> [139,] 19.4 14.1 39.1 43.2 17.8 #> [140,] 19.4 14.4 39.8 44.3 17.9 #> [141,] 20.1 13.7 40.6 44.5 18.0 #> [142,] 20.6 14.4 42.8 46.5 19.6 #> [143,] 21.0 15.0 42.9 47.2 19.4 #> [144,] 21.5 15.5 45.5 49.7 20.9 #> [145,] 21.6 15.4 45.7 49.7 20.6 #> [146,] 21.6 14.8 43.4 48.2 20.1 #> [147,] 21.9 15.7 45.4 51.0 21.1 #> [148,] 22.1 15.8 44.6 49.6 20.5 #> [149,] 23.0 16.8 47.2 52.1 21.5 #> [150,] 23.1 15.7 47.6 52.8 21.6 #> [151,] 10.7  9.7 21.4 24.0  9.8 #> [152,] 11.4  9.2 21.7 24.1  9.7 #> [153,] 12.5 10.0 24.1 27.0 10.9 #> [154,] 12.6 11.5 25.0 28.1 11.5 #> [155,] 12.9 11.2 25.8 29.1 11.9 #> [156,] 14.0 11.9 27.0 31.4 12.6 #> [157,] 14.0 12.8 28.8 32.4 12.7 #> [158,] 14.3 12.2 28.1 31.8 12.5 #> [159,] 14.7 13.2 29.6 33.4 12.9 #> [160,] 14.9 13.0 30.0 33.7 13.3 #> [161,] 15.0 12.3 30.1 33.3 14.0 #> [162,] 15.6 13.5 31.2 35.1 14.1 #> [163,] 15.6 14.0 31.6 35.3 13.8 #> [164,] 15.6 14.1 31.0 34.5 13.8 #> [165,] 15.7 13.6 31.0 34.8 13.8 #> [166,] 16.1 13.6 31.6 36.0 14.0 #> [167,] 16.1 13.7 31.4 36.1 13.9 #> [168,] 16.2 14.0 31.6 35.6 13.7 #> [169,] 16.7 14.3 32.3 37.0 14.7 #> [170,] 17.1 14.5 33.1 37.2 14.6 #> [171,] 17.5 14.3 34.5 39.6 15.6 #> [172,] 17.5 14.4 34.5 39.0 16.0 #> [173,] 17.5 14.7 33.3 37.6 14.6 #> [174,] 17.6 14.0 34.0 38.6 15.5 #> [175,] 18.0 14.9 34.7 39.5 15.7 #> [176,] 18.0 16.3 37.9 43.0 17.2 #> [177,] 18.3 15.7 35.1 40.5 16.1 #> [178,] 18.4 15.5 35.6 40.0 15.9 #> [179,] 18.4 15.7 36.5 41.6 16.4 #> [180,] 18.5 14.6 37.0 42.0 16.6 #> [181,] 18.6 14.5 34.7 39.4 15.0 #> [182,] 18.8 15.2 35.8 40.5 16.6 #> [183,] 18.9 16.7 36.3 41.7 15.3 #> [184,] 19.1 16.0 37.8 42.3 16.8 #> [185,] 19.1 16.3 37.9 42.6 17.2 #> [186,] 19.7 16.7 39.9 43.6 18.2 #> [187,] 19.9 16.6 39.4 43.9 17.9 #> [188,] 19.9 17.9 40.1 46.4 17.9 #> [189,] 20.0 16.7 40.4 45.1 17.7 #> [190,] 20.1 17.2 39.8 44.1 18.6 #> [191,] 20.3 16.0 39.4 44.1 18.0 #> [192,] 20.5 17.5 40.0 45.5 19.2 #> [193,] 20.6 17.5 41.5 46.2 19.2 #> [194,] 20.9 16.5 39.9 44.7 17.5 #> [195,] 21.3 18.4 43.8 48.4 20.0 #> [196,] 21.4 18.0 41.2 46.2 18.7 #> [197,] 21.7 17.1 41.7 47.2 19.6 #> [198,] 21.9 17.2 42.6 47.4 19.5 #> [199,] 22.5 17.2 43.0 48.7 19.8 #> [200,] 23.1 20.2 46.2 52.5 21.1 #>  #> attr(,\"class\") #> [1] \"list\"        \"PPtreeclass\"   PPclassify2(Tree.crab) #> $predict.error #> [1] NA #>  #> $predict.class #>        [,1] #>   [1,]    2 #>   [2,]    2 #>   [3,]    2 #>   [4,]    2 #>   [5,]    2 #>   [6,]    2 #>   [7,]    1 #>   [8,]    2 #>   [9,]    2 #>  [10,]    1 #>  [11,]    2 #>  [12,]    1 #>  [13,]    2 #>  [14,]    2 #>  [15,]    2 #>  [16,]    1 #>  [17,]    2 #>  [18,]    2 #>  [19,]    1 #>  [20,]    2 #>  [21,]    2 #>  [22,]    2 #>  [23,]    2 #>  [24,]    2 #>  [25,]    2 #>  [26,]    2 #>  [27,]    2 #>  [28,]    2 #>  [29,]    2 #>  [30,]    2 #>  [31,]    2 #>  [32,]    2 #>  [33,]    2 #>  [34,]    2 #>  [35,]    2 #>  [36,]    2 #>  [37,]    2 #>  [38,]    2 #>  [39,]    2 #>  [40,]    2 #>  [41,]    2 #>  [42,]    2 #>  [43,]    2 #>  [44,]    2 #>  [45,]    2 #>  [46,]    2 #>  [47,]    2 #>  [48,]    2 #>  [49,]    2 #>  [50,]    2 #>  [51,]    2 #>  [52,]    1 #>  [53,]    1 #>  [54,]    2 #>  [55,]    2 #>  [56,]    1 #>  [57,]    1 #>  [58,]    1 #>  [59,]    1 #>  [60,]    1 #>  [61,]    1 #>  [62,]    1 #>  [63,]    1 #>  [64,]    1 #>  [65,]    1 #>  [66,]    1 #>  [67,]    1 #>  [68,]    1 #>  [69,]    1 #>  [70,]    1 #>  [71,]    1 #>  [72,]    1 #>  [73,]    1 #>  [74,]    1 #>  [75,]    1 #>  [76,]    1 #>  [77,]    1 #>  [78,]    1 #>  [79,]    1 #>  [80,]    1 #>  [81,]    1 #>  [82,]    1 #>  [83,]    1 #>  [84,]    1 #>  [85,]    1 #>  [86,]    1 #>  [87,]    1 #>  [88,]    1 #>  [89,]    1 #>  [90,]    1 #>  [91,]    1 #>  [92,]    1 #>  [93,]    1 #>  [94,]    1 #>  [95,]    1 #>  [96,]    1 #>  [97,]    1 #>  [98,]    1 #>  [99,]    1 #> [100,]    1 #> [101,]    4 #> [102,]    4 #> [103,]    4 #> [104,]    4 #> [105,]    4 #> [106,]    4 #> [107,]    4 #> [108,]    4 #> [109,]    4 #> [110,]    4 #> [111,]    4 #> [112,]    4 #> [113,]    4 #> [114,]    4 #> [115,]    4 #> [116,]    4 #> [117,]    4 #> [118,]    4 #> [119,]    4 #> [120,]    4 #> [121,]    4 #> [122,]    4 #> [123,]    4 #> [124,]    4 #> [125,]    4 #> [126,]    4 #> [127,]    4 #> [128,]    4 #> [129,]    4 #> [130,]    4 #> [131,]    4 #> [132,]    4 #> [133,]    4 #> [134,]    4 #> [135,]    4 #> [136,]    4 #> [137,]    4 #> [138,]    4 #> [139,]    4 #> [140,]    4 #> [141,]    4 #> [142,]    4 #> [143,]    4 #> [144,]    4 #> [145,]    4 #> [146,]    4 #> [147,]    4 #> [148,]    4 #> [149,]    4 #> [150,]    4 #> [151,]    3 #> [152,]    4 #> [153,]    4 #> [154,]    3 #> [155,]    3 #> [156,]    3 #> [157,]    3 #> [158,]    3 #> [159,]    3 #> [160,]    3 #> [161,]    4 #> [162,]    3 #> [163,]    3 #> [164,]    3 #> [165,]    3 #> [166,]    3 #> [167,]    3 #> [168,]    3 #> [169,]    3 #> [170,]    3 #> [171,]    3 #> [172,]    3 #> [173,]    3 #> [174,]    3 #> [175,]    3 #> [176,]    3 #> [177,]    3 #> [178,]    3 #> [179,]    3 #> [180,]    3 #> [181,]    3 #> [182,]    3 #> [183,]    3 #> [184,]    3 #> [185,]    3 #> [186,]    3 #> [187,]    3 #> [188,]    3 #> [189,]    3 #> [190,]    3 #> [191,]    3 #> [192,]    3 #> [193,]    3 #> [194,]    3 #> [195,]    3 #> [196,]    3 #> [197,]    3 #> [198,]    3 #> [199,]    3 #> [200,]    3 #>"},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":null,"dir":"Reference","previous_headings":"","what":"Projection Pursuit Random Forest — PPforest","title":"Projection Pursuit Random Forest — PPforest","text":"PPforest implements random forest using projection pursuit trees algorithm (based PPtreeViz package).","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Projection Pursuit Random Forest — PPforest","text":"","code":"PPforest(data, y, std = 'scale', size.tr, m, PPmethod, size.p,  lambda = .1, parallel = FALSE, cores = 2, rule = 1)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Projection Pursuit Random Forest — PPforest","text":"data Data frame complete data set. y character name response variable. std TRUE standardize data set, needed compute global importance measure. size.tr size proportion training want split data training test. m number bootstrap replicates, corresponds number trees grow. ensure observation predicted times select number small. m = 500 default. PPmethod projection pursuit index optimize classification tree. options LDA PDA, linear discriminant penalized linear discriminant. default LDA. size.p proportion variables randomly sampled split. lambda penalty parameter PDA index 0 1 . lambda = 0, penalty parameter added PDA index LDA index. lambda = 1 variables treated uncorrelated. default value lambda = 0.1. parallel logical condition, TRUE  parallelize function cores number cores used parallelization rule split rule 1: mean two group means 2: weighted mean two group means - weight group size 3: weighted mean two group means - weight group sd 4: weighted mean two group means - weight group se 5: mean two group medians 6: weighted mean two group medians - weight group size 7: weighted mean two group median - weight group IQR 8: weighted mean two group median - weight group IQR size","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Projection Pursuit Random Forest — PPforest","text":"object class PPforest components. prediction.training predicted values training data set. training.error error training data set. prediction.test predicted values test data set testap = TRUE(default). error.test error test data set testap = TRUE(default). oob.error.forest bag error forest. oob.error.tree bag error tree forest. boot.samp information bootrap samples. output.trees output trees_pp bootrap sample. proximity Proximity matrix, two cases classified terminal node proximity matrix increased one PPforest one terminal node per class. votes matrix one row input data point one column class, giving fraction (OOB) votes PPforest. n.tree number trees grown PPforest. n.var number predictor variables selected use spliting node. type classification. confusion confusion matrix prediction (based OOB data). call original call PPforest. train training data based size.tr sample proportion test test data based 1-size.tr sample proportion","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Projection Pursuit Random Forest — PPforest","text":"da Silva, N., Cook, D., & Lee, E. K. (2021). projection pursuit forest algorithm supervised classification. Journal Computational Graphical Statistics, 30(4), 1168-1180.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Projection Pursuit Random Forest — PPforest","text":"","code":"#crab example with all the observations used as training set.seed(123) pprf.crab <- PPforest(data = crab, y = 'Type',  std = 'no', size.tr = 0.8, m = 100, size.p = 1,   PPmethod = 'LDA' , parallel = TRUE, cores = 2, rule = 1) pprf.crab #>  #> Call: #>  PPforest(data = crab, y = \"Type\", std = \"no\", size.tr = 0.8,      m = 100, PPmethod = \"LDA\", size.p = 1, parallel = TRUE, cores = 2,      rule = 1)  #>                Type of random forest: Classification #>                      Number of trees: 100 #> No. of variables tried at each split: 5 #>  #>         OOB estimate of  error rate: 6.25% #> Confusion matrix: #>              BlueFemale BlueMale OrangeFemale OrangeMale class.error #> BlueFemale           37        3            0          0        0.07 #> BlueMale              6       34            0          0        0.15 #> OrangeFemale          0        0           39          1        0.03 #> OrangeMale            0        0            0         40        0.00"},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"Find tree structure using  projection pursuit indices classification split.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"","code":"PPtree_split(form, data, PPmethod='LDA',  size.p=1,  lambda = 0.1,...)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"form character name class variable. data Data frame complete data set. PPmethod index use projection pursuit: 'LDA' 'PDA' size.p proportion variables randomly sampled split, default 1, returns PPtree. lambda penalty parameter PDA index 0 1 . lambda = 0, penalty parameter added PDA index LDA index. lambda = 1 variables treated uncorrelated. default value lambda = 0.1. ... arguments passed methods","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"object class PPtreeclass components Tree.Struct Tree structure projection pursuit classification tree projbest.node 1-dim optimal projections split node splitCutoff.node cutoff values split node origclass_num original class numeric origdata original data","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"Lee, YD, Cook, D., Park JW, Lee, EK (2013) PPtree: Projection pursuit classification tree, Electronic Journal Statistics, 7:1369-1386.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"","code":"#crab data set  Tree.crab <- PPtree_split('Type~.', data = crab, PPmethod = 'LDA', size.p = 0.5) Tree.crab #> $Tree.Struct #>      id L.node.ID R.F.node.ID Coef.ID     Index #> [1,]  1         2           3       1 0.7477711 #> [2,]  2         4           5       2 0.8103531 #> [3,]  3         6           7       3 0.7157610 #> [4,]  4         0           2       0 0.0000000 #> [5,]  5         0           4       0 0.0000000 #> [6,]  6         0           1       0 0.0000000 #> [7,]  7         0           3       0 0.0000000 #>  #> $projbest.node #>           [,1]      [,2]       [,3]       [,4]      [,5] #> [1,] 0.0000000 0.8907967 -0.4381660  0.1203820 0.0000000 #> [2,] 0.4693005 0.0000000 -0.5263431  0.0000000 0.7090275 #> [3,] 0.0000000 0.0000000  0.3847836 -0.6035929 0.6982959 #>  #> $splitCutoff.node #>        Rule1      Rule2       Rule3       Rule4      Rule5      Rule6 #> 1 1.66352638 1.66352638  1.64770219  1.64770219 1.66243164 1.66243164 #> 2 0.25840566 0.25840566  0.28835452  0.28835452 0.27907425 0.27907425 #> 3 0.02349414 0.02349414 -0.07204446 -0.07204446 0.01400513 0.01400513 #>         Rule7       Rule8 #> 1  1.65988194  1.65988194 #> 2  0.22293591  0.22293591 #> 3 -0.03254273 -0.03254273 #>  #> $origclass #>            1            2            3            4            5            6  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>            7            8            9           10           11           12  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           13           14           15           16           17           18  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           19           20           21           22           23           24  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           25           26           27           28           29           30  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           31           32           33           34           35           36  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           37           38           39           40           41           42  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           43           44           45           46           47           48  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           49           50           51           52           53           54  #>     BlueMale     BlueMale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           55           56           57           58           59           60  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           61           62           63           64           65           66  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           67           68           69           70           71           72  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           73           74           75           76           77           78  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           79           80           81           82           83           84  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           85           86           87           88           89           90  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           91           92           93           94           95           96  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           97           98           99          100          101          102  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   OrangeMale   OrangeMale  #>          103          104          105          106          107          108  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          109          110          111          112          113          114  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          115          116          117          118          119          120  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          121          122          123          124          125          126  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          127          128          129          130          131          132  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          133          134          135          136          137          138  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          139          140          141          142          143          144  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          145          146          147          148          149          150  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          151          152          153          154          155          156  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          157          158          159          160          161          162  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          163          164          165          166          167          168  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          169          170          171          172          173          174  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          175          176          177          178          179          180  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          181          182          183          184          185          186  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          187          188          189          190          191          192  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          193          194          195          196          197          198  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          199          200  #> OrangeFemale OrangeFemale  #> Levels: BlueFemale BlueMale OrangeFemale OrangeMale #>  #> $origclass_num #>   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 #> [112] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 #> [149] 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [186] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  #> $origdata #>          FL   RW   CL   CW   BD #>   [1,]  8.1  6.7 16.1 19.0  7.0 #>   [2,]  8.8  7.7 18.1 20.8  7.4 #>   [3,]  9.2  7.8 19.0 22.4  7.7 #>   [4,]  9.6  7.9 20.1 23.1  8.2 #>   [5,]  9.8  8.0 20.3 23.0  8.2 #>   [6,] 10.8  9.0 23.0 26.5  9.8 #>   [7,] 11.1  9.9 23.8 27.1  9.8 #>   [8,] 11.6  9.1 24.5 28.4 10.4 #>   [9,] 11.8  9.6 24.2 27.8  9.7 #>  [10,] 11.8 10.5 25.2 29.3 10.3 #>  [11,] 12.2 10.8 27.3 31.6 10.9 #>  [12,] 12.3 11.0 26.8 31.5 11.4 #>  [13,] 12.6 10.0 27.7 31.7 11.4 #>  [14,] 12.8 10.2 27.2 31.8 10.9 #>  [15,] 12.8 10.9 27.4 31.5 11.0 #>  [16,] 12.9 11.0 26.8 30.9 11.4 #>  [17,] 13.1 10.6 28.2 32.3 11.0 #>  [18,] 13.1 10.9 28.3 32.4 11.2 #>  [19,] 13.3 11.1 27.8 32.3 11.3 #>  [20,] 13.9 11.1 29.2 33.3 12.1 #>  [21,] 14.3 11.6 31.3 35.5 12.7 #>  [22,] 14.6 11.3 31.9 36.4 13.7 #>  [23,] 15.0 10.9 31.4 36.4 13.2 #>  [24,] 15.0 11.5 32.4 37.0 13.4 #>  [25,] 15.0 11.9 32.5 37.2 13.6 #>  [26,] 15.2 12.1 32.3 36.7 13.6 #>  [27,] 15.4 11.8 33.0 37.5 13.6 #>  [28,] 15.7 12.6 35.8 40.3 14.5 #>  [29,] 15.9 12.7 34.0 38.9 14.2 #>  [30,] 16.1 11.6 33.8 39.0 14.4 #>  [31,] 16.1 12.8 34.9 40.7 15.7 #>  [32,] 16.2 13.3 36.0 41.7 15.4 #>  [33,] 16.3 12.7 35.6 40.9 14.9 #>  [34,] 16.4 13.0 35.7 41.8 15.2 #>  [35,] 16.6 13.5 38.1 43.4 14.9 #>  [36,] 16.8 12.8 36.2 41.8 14.9 #>  [37,] 16.9 13.2 37.3 42.7 15.6 #>  [38,] 17.1 12.6 36.4 42.0 15.1 #>  [39,] 17.1 12.7 36.7 41.9 15.6 #>  [40,] 17.2 13.5 37.6 43.9 16.1 #>  [41,] 17.7 13.6 38.7 44.5 16.0 #>  [42,] 17.9 14.1 39.7 44.6 16.8 #>  [43,] 18.0 13.7 39.2 44.4 16.2 #>  [44,] 18.8 15.8 42.1 49.0 17.8 #>  [45,] 19.3 13.5 41.6 47.4 17.8 #>  [46,] 19.3 13.8 40.9 46.5 16.8 #>  [47,] 19.7 15.3 41.9 48.5 17.8 #>  [48,] 19.8 14.2 43.2 49.7 18.6 #>  [49,] 19.8 14.3 42.4 48.9 18.3 #>  [50,] 21.3 15.7 47.1 54.6 20.0 #>  [51,]  7.2  6.5 14.7 17.1  6.1 #>  [52,]  9.0  8.5 19.3 22.7  7.7 #>  [53,]  9.1  8.1 18.5 21.6  7.7 #>  [54,]  9.1  8.2 19.2 22.2  7.7 #>  [55,]  9.5  8.2 19.6 22.4  7.8 #>  [56,]  9.8  8.9 20.4 23.9  8.8 #>  [57,] 10.1  9.3 20.9 24.4  8.4 #>  [58,] 10.3  9.5 21.3 24.7  8.9 #>  [59,] 10.4  9.7 21.7 25.4  8.3 #>  [60,] 10.8  9.5 22.5 26.3  9.1 #>  [61,] 11.0  9.8 22.5 25.7  8.2 #>  [62,] 11.2 10.0 22.8 26.9  9.4 #>  [63,] 11.5 11.0 24.7 29.2 10.1 #>  [64,] 11.6 11.0 24.6 28.5 10.4 #>  [65,] 11.6 11.4 23.7 27.7 10.0 #>  [66,] 11.7 10.6 24.9 28.5 10.4 #>  [67,] 11.9 11.4 26.0 30.1 10.9 #>  [68,] 12.0 10.7 24.6 28.9 10.5 #>  [69,] 12.0 11.1 25.4 29.2 11.0 #>  [70,] 12.6 12.2 26.1 31.6 11.2 #>  [71,] 12.8 11.7 27.1 31.2 11.9 #>  [72,] 12.8 12.2 26.7 31.1 11.1 #>  [73,] 12.8 12.2 27.9 31.9 11.5 #>  [74,] 13.0 11.4 27.3 31.8 11.3 #>  [75,] 13.1 11.5 27.6 32.6 11.1 #>  [76,] 13.2 12.2 27.9 32.1 11.5 #>  [77,] 13.4 11.8 28.4 32.7 11.7 #>  [78,] 13.7 12.5 28.6 33.8 11.9 #>  [79,] 13.9 13.0 30.0 34.9 13.1 #>  [80,] 14.7 12.5 30.1 34.7 12.5 #>  [81,] 14.9 13.2 30.1 35.6 12.0 #>  [82,] 15.0 13.8 31.7 36.9 14.0 #>  [83,] 15.0 14.2 32.8 37.4 14.0 #>  [84,] 15.1 13.3 31.8 36.3 13.5 #>  [85,] 15.1 13.5 31.9 37.0 13.8 #>  [86,] 15.1 13.8 31.7 36.6 13.0 #>  [87,] 15.2 14.3 33.9 38.5 14.7 #>  [88,] 15.3 14.2 32.6 38.3 13.8 #>  [89,] 15.4 13.3 32.4 37.6 13.8 #>  [90,] 15.5 13.8 33.4 38.7 14.7 #>  [91,] 15.6 13.9 32.8 37.9 13.4 #>  [92,] 15.6 14.7 33.9 39.5 14.3 #>  [93,] 15.7 13.9 33.6 38.5 14.1 #>  [94,] 15.8 15.0 34.5 40.3 15.3 #>  [95,] 16.2 15.2 34.5 40.1 13.9 #>  [96,] 16.4 14.0 34.2 39.8 15.2 #>  [97,] 16.7 16.1 36.6 41.9 15.4 #>  [98,] 17.4 16.9 38.2 44.1 16.6 #>  [99,] 17.5 16.7 38.6 44.5 17.0 #> [100,] 19.2 16.5 40.9 47.9 18.1 #> [101,]  9.1  6.9 16.7 18.6  7.4 #> [102,] 10.2  8.2 20.2 22.2  9.0 #> [103,] 10.7  8.6 20.7 22.7  9.2 #> [104,] 11.4  9.0 22.7 24.8 10.1 #> [105,] 12.5  9.4 23.2 26.0 10.8 #> [106,] 12.5  9.4 24.2 27.0 11.2 #> [107,] 12.7 10.4 26.0 28.8 12.1 #> [108,] 13.2 11.0 27.1 30.4 12.2 #> [109,] 13.4 10.1 26.6 29.6 12.0 #> [110,] 13.7 11.0 27.5 30.5 12.2 #> [111,] 14.0 11.5 29.2 32.2 13.1 #> [112,] 14.1 10.4 28.9 31.8 13.5 #> [113,] 14.1 10.5 29.1 31.6 13.1 #> [114,] 14.1 10.7 28.7 31.9 13.3 #> [115,] 14.2 10.6 28.7 31.7 12.9 #> [116,] 14.2 10.7 27.8 30.9 12.7 #> [117,] 14.2 11.3 29.2 32.2 13.5 #> [118,] 14.6 11.3 29.9 33.5 12.8 #> [119,] 14.7 11.1 29.0 32.1 13.1 #> [120,] 15.1 11.4 30.2 33.3 14.0 #> [121,] 15.1 11.5 30.9 34.0 13.9 #> [122,] 15.4 11.1 30.2 33.6 13.5 #> [123,] 15.7 12.2 31.7 34.2 14.2 #> [124,] 16.2 11.8 32.3 35.3 14.7 #> [125,] 16.3 11.6 31.6 34.2 14.5 #> [126,] 17.1 12.6 35.0 38.9 15.7 #> [127,] 17.4 12.8 36.1 39.5 16.2 #> [128,] 17.5 12.0 34.4 37.3 15.3 #> [129,] 17.5 12.7 34.6 38.4 16.1 #> [130,] 17.8 12.5 36.0 39.8 16.7 #> [131,] 17.9 12.9 36.9 40.9 16.5 #> [132,] 18.0 13.4 36.7 41.3 17.1 #> [133,] 18.2 13.7 38.8 42.7 17.2 #> [134,] 18.4 13.4 37.9 42.2 17.7 #> [135,] 18.6 13.4 37.8 41.9 17.3 #> [136,] 18.6 13.5 36.9 40.2 17.0 #> [137,] 18.8 13.4 37.2 41.1 17.5 #> [138,] 18.8 13.8 39.2 43.3 17.9 #> [139,] 19.4 14.1 39.1 43.2 17.8 #> [140,] 19.4 14.4 39.8 44.3 17.9 #> [141,] 20.1 13.7 40.6 44.5 18.0 #> [142,] 20.6 14.4 42.8 46.5 19.6 #> [143,] 21.0 15.0 42.9 47.2 19.4 #> [144,] 21.5 15.5 45.5 49.7 20.9 #> [145,] 21.6 15.4 45.7 49.7 20.6 #> [146,] 21.6 14.8 43.4 48.2 20.1 #> [147,] 21.9 15.7 45.4 51.0 21.1 #> [148,] 22.1 15.8 44.6 49.6 20.5 #> [149,] 23.0 16.8 47.2 52.1 21.5 #> [150,] 23.1 15.7 47.6 52.8 21.6 #> [151,] 10.7  9.7 21.4 24.0  9.8 #> [152,] 11.4  9.2 21.7 24.1  9.7 #> [153,] 12.5 10.0 24.1 27.0 10.9 #> [154,] 12.6 11.5 25.0 28.1 11.5 #> [155,] 12.9 11.2 25.8 29.1 11.9 #> [156,] 14.0 11.9 27.0 31.4 12.6 #> [157,] 14.0 12.8 28.8 32.4 12.7 #> [158,] 14.3 12.2 28.1 31.8 12.5 #> [159,] 14.7 13.2 29.6 33.4 12.9 #> [160,] 14.9 13.0 30.0 33.7 13.3 #> [161,] 15.0 12.3 30.1 33.3 14.0 #> [162,] 15.6 13.5 31.2 35.1 14.1 #> [163,] 15.6 14.0 31.6 35.3 13.8 #> [164,] 15.6 14.1 31.0 34.5 13.8 #> [165,] 15.7 13.6 31.0 34.8 13.8 #> [166,] 16.1 13.6 31.6 36.0 14.0 #> [167,] 16.1 13.7 31.4 36.1 13.9 #> [168,] 16.2 14.0 31.6 35.6 13.7 #> [169,] 16.7 14.3 32.3 37.0 14.7 #> [170,] 17.1 14.5 33.1 37.2 14.6 #> [171,] 17.5 14.3 34.5 39.6 15.6 #> [172,] 17.5 14.4 34.5 39.0 16.0 #> [173,] 17.5 14.7 33.3 37.6 14.6 #> [174,] 17.6 14.0 34.0 38.6 15.5 #> [175,] 18.0 14.9 34.7 39.5 15.7 #> [176,] 18.0 16.3 37.9 43.0 17.2 #> [177,] 18.3 15.7 35.1 40.5 16.1 #> [178,] 18.4 15.5 35.6 40.0 15.9 #> [179,] 18.4 15.7 36.5 41.6 16.4 #> [180,] 18.5 14.6 37.0 42.0 16.6 #> [181,] 18.6 14.5 34.7 39.4 15.0 #> [182,] 18.8 15.2 35.8 40.5 16.6 #> [183,] 18.9 16.7 36.3 41.7 15.3 #> [184,] 19.1 16.0 37.8 42.3 16.8 #> [185,] 19.1 16.3 37.9 42.6 17.2 #> [186,] 19.7 16.7 39.9 43.6 18.2 #> [187,] 19.9 16.6 39.4 43.9 17.9 #> [188,] 19.9 17.9 40.1 46.4 17.9 #> [189,] 20.0 16.7 40.4 45.1 17.7 #> [190,] 20.1 17.2 39.8 44.1 18.6 #> [191,] 20.3 16.0 39.4 44.1 18.0 #> [192,] 20.5 17.5 40.0 45.5 19.2 #> [193,] 20.6 17.5 41.5 46.2 19.2 #> [194,] 20.9 16.5 39.9 44.7 17.5 #> [195,] 21.3 18.4 43.8 48.4 20.0 #> [196,] 21.4 18.0 41.2 46.2 18.7 #> [197,] 21.7 17.1 41.7 47.2 19.6 #> [198,] 21.9 17.2 42.6 47.4 19.5 #> [199,] 22.5 17.2 43.0 48.7 19.8 #> [200,] 23.1 20.2 46.2 52.5 21.1 #>  #> attr(,\"class\") #> [1] \"list\"        \"PPtreeclass\""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":null,"dir":"Reference","previous_headings":"","what":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"bootstrap sample grow projection pursuit tree (PPtree object).","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"","code":"baggtree(   data,   y,   m = 500,   PPmethod = \"LDA\",   lambda = 0.1,   size.p = 1,   parallel = FALSE,   cores = 2 )"},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"data Data frame complete data set. y character name y variable. m number bootstrap replicates, corresponds number trees grow. ensure observation predicted times select number small. m = 500 default. PPmethod projection pursuit index optimized, options LDA PDA, default LDA. lambda parameter PDA index size.p proportion random sample variables split  size.p= 1 bagging size.p<1 forest. parallel logical condition, TRUE  parallelize function cores number cores used parallelization","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"data frame trees_pp output bootstraps samples.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":null,"dir":"Reference","previous_headings":"","what":"Astralian crabs — crab","title":"Astralian crabs — crab","text":"Astralian crabs","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Astralian crabs — crab","text":"","code":"data(crab)"},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Astralian crabs — crab","text":"Measurements rock crabs genus Leptograpsus. data set contains 200 observations  two species crab (blue orange), 50 specimens sex species,   collected site Fremantle, Western Australia. Type class variable 4 classes combinations species sex (BlueMale, BlueFemale, OrangeMale OrangeFemale). FL size frontal lobe length, mm. RW rear width, mm CL length midline carapace, mm. CW maximum width carapace, mm. BD depth body; females, measured displacement abdomen, mm. data frame 200 rows 6 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Astralian crabs — crab","text":"Campbell, N. . & Mahon, R. J. (1974), Multivariate Study Variation Two Species Rock Crab genus Leptograpsus, Australian Journal Zoology 22(3), 417 - 425.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Fish catch data set — fishcatch","title":"Fish catch data set — fishcatch","text":"Fish catch data set","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fish catch data set — fishcatch","text":"","code":"data(fishcatch)"},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Fish catch data set — fishcatch","text":"159 fishes 7 species caught measured. Altogether   7 variables.  fishes caught lake(Laengelmavesi) near Tampere Finland. Type 7 fish classes, 35 cases Bream, 11 cases Parkki, 56 cases Perch, 17 cases Pike, 20 cases Roach, 14 cases Smelt 6 cases Whitewish. weight Weight fish (grams). length1 Length nose beginning tail (cm). length2 Length nose notch tail (cm). length3 Length nose end tail (cm). height Maximal height % Length3. width Maximal width % Length3. data frame 159 rows 7 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Fish catch data set — fishcatch","text":"<http://www.amstat.org/publications/jse/jse_data_archive.htm>","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/glass.html","id":null,"dir":"Reference","previous_headings":"","what":"Glass data set — glass","title":"Glass data set — glass","text":"Glass data set","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/glass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Glass data set — glass","text":"","code":"data(glass)"},{"path":"https://github.com/natydasilva/PPforest/reference/glass.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Glass data set — glass","text":"Contains measurements 214 observations 6 types glass; defined terms oxide content. Type 6 types glasses. X1 refractive index. X2 Sodium (unit measurement: weight percent corresponding oxide). X3 Magnesium. X4 Aluminum. X5 Silicon. X6 Potassium. X7 Calcium. X8 Barium. X9 Iron. data frame 214 rows 10 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/image.html","id":null,"dir":"Reference","previous_headings":"","what":"The image data set — image","title":"The image data set — image","text":"image data set","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/image.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The image data set — image","text":"","code":"data(image)"},{"path":"https://github.com/natydasilva/PPforest/reference/image.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The image data set — image","text":"Contains  2310 observations instances 7 outdoor images Type 7 types outdoor images, brickface, cement,  foliage, grass, path, sky, window. X1 column center pixel region X2 row center pixel region. X3 number pixels region = 9. X4 results line extraction algorithm counts many lines length 5 (orientation) low contrast, less equal 5, go region. X5 measure contrast horizontally adjacent pixels region. 6, mean standard deviation given. attribute used vertical edge detector. X6 X5 sd X7 measures contrast vertically adjacent pixels. Used horizontal line detection. X8 sd X7 X9 average region (R + G + B)/3 X10 average region R value. X11 average region B value. X12 average region G value. X13 measure excess red: (2R - (G + B)). X14 measure excess blue: (2B - (G + R)). X15 measure excess green: (2G - (R + B)). X16 3-d nonlinear transformation RGB. (Algorithm can found Foley VanDam, Fundamentals Interactive Computer Graphics). X17 mean X16. X18 hue  mean. data frame contains 2310 observations 19 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":null,"dir":"Reference","previous_headings":"","what":"Leukemia data set — leukemia","title":"Leukemia data set — leukemia","text":"Leukemia data set","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leukemia data set — leukemia","text":"","code":"data(leukemia)"},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Leukemia data set — leukemia","text":"dataset comes study gene expression two types acute leukemias, acute lymphoblastic leukemia () acute myeloid leukemia (AML). Gene expression levels measured using Affymetrix high density oligonucleotide arrays containing 6817 human genes. data set containing 72 observations 3 leukemia types classes. Type 3 classes 38 cases B-cell , 25 cases AML 9 cases T-cell . Gene1, Gen2, ..., Gen40 gene expression levels. data frame 72 rows 41 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Leukemia data set — leukemia","text":"Dudoit, S., Fridlyand, J. Speed, T. P. (2002). Comparison Discrimination Methods Classification Tumors Using Gene Expression Data. Journal American statistical Association 97 77-87.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":null,"dir":"Reference","previous_headings":"","what":"Lymphoma data set — lymphoma","title":"Lymphoma data set — lymphoma","text":"Lymphoma data set","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lymphoma data set — lymphoma","text":"","code":"data(lymphoma)"},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Lymphoma data set — lymphoma","text":"Gene expression three prevalent adult lymphoid malignancies: B-cell chronic lymphocytic leukemia (B-CLL), follicular lymphoma (FL), diffuse large B-cell lym- phoma (DLBCL). Gene expression levels measured using specialized cDNA microarray, Lymphochip, containing genes preferentially expressed lymphoid cells known immunologic oncologic importance. data set contain 80 observations 3 lymphoma types. Type Class variable 3 classes 29 cases B-cell (B-CLL), 42 cases diffuse large B-cell lymphoma (DLBCL) 9 cases follicular lymphoma (FL). Gene1, Gen2, ..., Gen50 gene expression. data frame 80 rows 51 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Lymphoma data set — lymphoma","text":"Dudoit, S., Fridlyand, J. Speed, T. P. (2002). Comparison Discrimination Methods Classification Tumors Using Gene Ex- pression Data. Journal American statistical Association 97 77-87.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Data structure with the projected and boundary by node and class. — node_data","title":"Data structure with the projected and boundary by node and class. — node_data","text":"Data structure  projected boundary node class.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data structure with the projected and boundary by node and class. — node_data","text":"","code":"node_data(ppf, tr, Rule = 1)"},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data structure with the projected and boundary by node and class. — node_data","text":"ppf PPforest object tr numerical value  identify tree Rule split rule 1:mean two group means, 2:weighted mean, 3: mean max(left group) min(right group), 4: weighted mean max(left group) min(right group)","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data structure with the projected and boundary by node and class. — node_data","text":"Data frame projected data class node id boundaries","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data structure with the projected and boundary by node and class. — node_data","text":"","code":"#crab data set with all the observations used as training  pprf.crab <- PPforest(data = crab, std = 'min-max', y = 'Type',  size.tr = 1, m = 200, size.p = .5, PPmethod = 'LDA') node_data(ppf = pprf.crab, tr = 1)  #>                 proj.data        Class          cut node.id LR.class   Dir #> 99...1       0.0022341643   BlueFemale -0.021714183       1        R  TRUE #> 80...2      -0.0037080026   BlueFemale -0.021714183       1        R  TRUE #> 89...3      -0.0029009777   BlueFemale -0.021714183       1        R  TRUE #> 69...4      -0.0045210440   BlueFemale -0.021714183       1        R  TRUE #> 89.1...5    -0.0029009777   BlueFemale -0.021714183       1        R  TRUE #> 77...6       0.0117300948   BlueFemale -0.021714183       1        R  TRUE #> 96...7      -0.0249024946   BlueFemale -0.021714183       1        R FALSE #> 60...8       0.0101318554   BlueFemale -0.021714183       1        R  TRUE #> 65...9      -0.0071010544   BlueFemale -0.021714183       1        R  TRUE #> 55...10      0.0105444582   BlueFemale -0.021714183       1        R  TRUE #> 61...11      0.0301789424   BlueFemale -0.021714183       1        R  TRUE #> 99.1...12    0.0022341643   BlueFemale -0.021714183       1        R  TRUE #> 65.1...13   -0.0071010544   BlueFemale -0.021714183       1        R  TRUE #> 87...14      0.0134036087   BlueFemale -0.021714183       1        R  TRUE #> 90...15     -0.0065937643   BlueFemale -0.021714183       1        R  TRUE #> 56...16     -0.0060598192   BlueFemale -0.021714183       1        R  TRUE #> 62...17     -0.0015381810   BlueFemale -0.021714183       1        R  TRUE #> 64...18      0.0034652744   BlueFemale -0.021714183       1        R  TRUE #> 56.1...19   -0.0060598192   BlueFemale -0.021714183       1        R  TRUE #> 56.2...20   -0.0060598192   BlueFemale -0.021714183       1        R  TRUE #> 100...21    -0.0176036349   BlueFemale -0.021714183       1        R  TRUE #> 100.1...22  -0.0176036349   BlueFemale -0.021714183       1        R  TRUE #> 57...23      0.0094219320   BlueFemale -0.021714183       1        R  TRUE #> 96.1...24   -0.0249024946   BlueFemale -0.021714183       1        R FALSE #> 79...25     -0.0019847310   BlueFemale -0.021714183       1        R  TRUE #> 70...26     -0.0089395644   BlueFemale -0.021714183       1        R  TRUE #> 73...27      0.0209955049   BlueFemale -0.021714183       1        R  TRUE #> 86...28      0.0105044070   BlueFemale -0.021714183       1        R  TRUE #> 55.1...29    0.0105444582   BlueFemale -0.021714183       1        R  TRUE #> 67...30      0.0154575103   BlueFemale -0.021714183       1        R  TRUE #> 85...31     -0.0071380537   BlueFemale -0.021714183       1        R  TRUE #> 66...32      0.0081088929   BlueFemale -0.021714183       1        R  TRUE #> 92...33      0.0141414193   BlueFemale -0.021714183       1        R  TRUE #> 61.1...34    0.0301789424   BlueFemale -0.021714183       1        R  TRUE #> 75...35      0.0170896970   BlueFemale -0.021714183       1        R  TRUE #> 64.1...36    0.0034652744   BlueFemale -0.021714183       1        R  TRUE #> 60.1...37    0.0101318554   BlueFemale -0.021714183       1        R  TRUE #> 98...38      0.0064117761   BlueFemale -0.021714183       1        R  TRUE #> 67.1...39    0.0154575103   BlueFemale -0.021714183       1        R  TRUE #> 74...40      0.0068237409   BlueFemale -0.021714183       1        R  TRUE #> 52...41      0.0192188732   BlueFemale -0.021714183       1        R  TRUE #> 78...42      0.0030744985   BlueFemale -0.021714183       1        R  TRUE #> 83...43      0.0116773289   BlueFemale -0.021714183       1        R  TRUE #> 80.1...44   -0.0037080026   BlueFemale -0.021714183       1        R  TRUE #> 67.2...45    0.0154575103   BlueFemale -0.021714183       1        R  TRUE #> 95...46      0.0241664669   BlueFemale -0.021714183       1        R  TRUE #> 82...47     -0.0149805649   BlueFemale -0.021714183       1        R  TRUE #> 66.1...48    0.0081088929   BlueFemale -0.021714183       1        R  TRUE #> 70.1...49   -0.0089395644   BlueFemale -0.021714183       1        R  TRUE #> 59...50      0.0237405114   BlueFemale -0.021714183       1        R  TRUE #> 44...51      0.0304180749     BlueMale -0.021714183       1        R  TRUE #> 48...52      0.0083194566     BlueMale -0.021714183       1        R  TRUE #> 29...53      0.0114958845     BlueMale -0.021714183       1        R  TRUE #> 17...54      0.0344415352     BlueMale -0.021714183       1        R  TRUE #> 50...55      0.0240767016     BlueMale -0.021714183       1        R  TRUE #> 12...56      0.0102823608     BlueMale -0.021714183       1        R  TRUE #> 31...57     -0.0141140759     BlueMale -0.021714183       1        R  TRUE #> 6...58       0.0025708982     BlueMale -0.021714183       1        R  TRUE #> 25...59      0.0156516694     BlueMale -0.021714183       1        R  TRUE #> 5...60       0.0083837487     BlueMale -0.021714183       1        R  TRUE #> 9...61       0.0081962441     BlueMale -0.021714183       1        R  TRUE #> 15...62      0.0229341245     BlueMale -0.021714183       1        R  TRUE #> 30...63     -0.0042267753     BlueMale -0.021714183       1        R  TRUE #> 37...64      0.0258460410     BlueMale -0.021714183       1        R  TRUE #> 9.1...65     0.0081962441     BlueMale -0.021714183       1        R  TRUE #> 44.1...66    0.0304180749     BlueMale -0.021714183       1        R  TRUE #> 36...67      0.0214930450     BlueMale -0.021714183       1        R  TRUE #> 39...68      0.0060519393     BlueMale -0.021714183       1        R  TRUE #> 8...69       0.0010418295     BlueMale -0.021714183       1        R  TRUE #> 18...70      0.0312426424     BlueMale -0.021714183       1        R  TRUE #> 34...71      0.0114491787     BlueMale -0.021714183       1        R  TRUE #> 27...72      0.0172620292     BlueMale -0.021714183       1        R  TRUE #> 18.1...73    0.0312426424     BlueMale -0.021714183       1        R  TRUE #> 13...74      0.0242132163     BlueMale -0.021714183       1        R  TRUE #> 3...75       0.0066951062     BlueMale -0.021714183       1        R  TRUE #> 12.1...76    0.0102823608     BlueMale -0.021714183       1        R  TRUE #> 45...77      0.0051672696     BlueMale -0.021714183       1        R  TRUE #> 41...78      0.0275158649     BlueMale -0.021714183       1        R  TRUE #> 38...79      0.0128374486     BlueMale -0.021714183       1        R  TRUE #> 8.1...80     0.0010418295     BlueMale -0.021714183       1        R  TRUE #> 7...81       0.0140783089     BlueMale -0.021714183       1        R  TRUE #> 49...82     -0.0026345961     BlueMale -0.021714183       1        R  TRUE #> 22...83      0.0088066959     BlueMale -0.021714183       1        R  TRUE #> 24...84      0.0188505621     BlueMale -0.021714183       1        R  TRUE #> 9.2...85     0.0081962441     BlueMale -0.021714183       1        R  TRUE #> 30.1...86   -0.0042267753     BlueMale -0.021714183       1        R  TRUE #> 14...87      0.0208984035     BlueMale -0.021714183       1        R  TRUE #> 12.2...88    0.0102823608     BlueMale -0.021714183       1        R  TRUE #> 35...89      0.0727919302     BlueMale -0.021714183       1        R  TRUE #> 15.1...90    0.0229341245     BlueMale -0.021714183       1        R  TRUE #> 41.1...91    0.0275158649     BlueMale -0.021714183       1        R  TRUE #> 5.1...92     0.0083837487     BlueMale -0.021714183       1        R  TRUE #> 42...93      0.0240075310     BlueMale -0.021714183       1        R  TRUE #> 22.1...94    0.0088066959     BlueMale -0.021714183       1        R  TRUE #> 38.1...95    0.0128374486     BlueMale -0.021714183       1        R  TRUE #> 34.1...96    0.0114491787     BlueMale -0.021714183       1        R  TRUE #> 23...97      0.0002384508     BlueMale -0.021714183       1        R  TRUE #> 32...98      0.0183506081     BlueMale -0.021714183       1        R  TRUE #> 1...99      -0.0150127363     BlueMale -0.021714183       1        R  TRUE #> 11...100     0.0390821454     BlueMale -0.021714183       1        R  TRUE #> 186...101   -0.0577828334 OrangeFemale -0.021714183       1        L FALSE #> 161...102   -0.0537556832 OrangeFemale -0.021714183       1        L FALSE #> 191...103   -0.0800380172 OrangeFemale -0.021714183       1        L FALSE #> 166...104   -0.0462978876 OrangeFemale -0.021714183       1        L FALSE #> 185...105   -0.0623797462 OrangeFemale -0.021714183       1        L FALSE #> 197...106   -0.1060515119 OrangeFemale -0.021714183       1        L FALSE #> 156...107   -0.0632589499 OrangeFemale -0.021714183       1        L FALSE #> 157...108   -0.0224481107 OrangeFemale -0.021714183       1        L FALSE #> 184...109   -0.0535585158 OrangeFemale -0.021714183       1        L FALSE #> 172...110   -0.0690153882 OrangeFemale -0.021714183       1        L FALSE #> 192...111   -0.1044848059 OrangeFemale -0.021714183       1        L FALSE #> 199...112   -0.1011827952 OrangeFemale -0.021714183       1        L FALSE #> 154...113   -0.0440309646 OrangeFemale -0.021714183       1        L FALSE #> 173...114   -0.0587403636 OrangeFemale -0.021714183       1        L FALSE #> 186.1...115 -0.0577828334 OrangeFemale -0.021714183       1        L FALSE #> 155...116   -0.0437682292 OrangeFemale -0.021714183       1        L FALSE #> 200...117   -0.0759380502 OrangeFemale -0.021714183       1        L FALSE #> 163...118   -0.0275419692 OrangeFemale -0.021714183       1        L FALSE #> 153...119   -0.0463482396 OrangeFemale -0.021714183       1        L FALSE #> 185.1...120 -0.0623797462 OrangeFemale -0.021714183       1        L FALSE #> 190...121   -0.0819578182 OrangeFemale -0.021714183       1        L FALSE #> 168...122   -0.0404910974 OrangeFemale -0.021714183       1        L FALSE #> 169...123   -0.0647722520 OrangeFemale -0.021714183       1        L FALSE #> 165...124   -0.0447093547 OrangeFemale -0.021714183       1        L FALSE #> 154.1...125 -0.0440309646 OrangeFemale -0.021714183       1        L FALSE #> 169.1...126 -0.0647722520 OrangeFemale -0.021714183       1        L FALSE #> 159...127   -0.0270699023 OrangeFemale -0.021714183       1        L FALSE #> 177...128   -0.0782996170 OrangeFemale -0.021714183       1        L FALSE #> 176...129   -0.0334858684 OrangeFemale -0.021714183       1        L FALSE #> 198...130   -0.0866827714 OrangeFemale -0.021714183       1        L FALSE #> 168.1...131 -0.0404910974 OrangeFemale -0.021714183       1        L FALSE #> 174...132   -0.0697034848 OrangeFemale -0.021714183       1        L FALSE #> 155.1...133 -0.0437682292 OrangeFemale -0.021714183       1        L FALSE #> 194...134   -0.0696252457 OrangeFemale -0.021714183       1        L FALSE #> 170...135   -0.0530803887 OrangeFemale -0.021714183       1        L FALSE #> 187...136   -0.0667199838 OrangeFemale -0.021714183       1        L FALSE #> 159.1...137 -0.0270699023 OrangeFemale -0.021714183       1        L FALSE #> 173.1...138 -0.0587403636 OrangeFemale -0.021714183       1        L FALSE #> 189...139   -0.0394899134 OrangeFemale -0.021714183       1        L FALSE #> 154.2...140 -0.0440309646 OrangeFemale -0.021714183       1        L FALSE #> 191.1...141 -0.0800380172 OrangeFemale -0.021714183       1        L FALSE #> 166.1...142 -0.0462978876 OrangeFemale -0.021714183       1        L FALSE #> 169.2...143 -0.0647722520 OrangeFemale -0.021714183       1        L FALSE #> 166.2...144 -0.0462978876 OrangeFemale -0.021714183       1        L FALSE #> 152...145   -0.0418830135 OrangeFemale -0.021714183       1        L FALSE #> 176.1...146 -0.0334858684 OrangeFemale -0.021714183       1        L FALSE #> 184.1...147 -0.0535585158 OrangeFemale -0.021714183       1        L FALSE #> 196...148   -0.0849880686 OrangeFemale -0.021714183       1        L FALSE #> 152.1...149 -0.0418830135 OrangeFemale -0.021714183       1        L FALSE #> 200.1...150 -0.0759380502 OrangeFemale -0.021714183       1        L FALSE #> 116...151   -0.0519359919   OrangeMale -0.021714183       1        L FALSE #> 147...152   -0.0638050154   OrangeMale -0.021714183       1        L FALSE #> 135...153   -0.0544807791   OrangeMale -0.021714183       1        L FALSE #> 123...154   -0.0389899157   OrangeMale -0.021714183       1        L FALSE #> 141...155   -0.0457032462   OrangeMale -0.021714183       1        L FALSE #> 102...156   -0.0270359113   OrangeMale -0.021714183       1        L FALSE #> 137...157   -0.0798972184   OrangeMale -0.021714183       1        L FALSE #> 118...158   -0.0143616827   OrangeMale -0.021714183       1        L  TRUE #> 142...159   -0.0504997403   OrangeMale -0.021714183       1        L FALSE #> 127...160   -0.0332358914   OrangeMale -0.021714183       1        L FALSE #> 114...161   -0.0443652846   OrangeMale -0.021714183       1        L FALSE #> 141.1...162 -0.0457032462   OrangeMale -0.021714183       1        L FALSE #> 105...163   -0.0653480748   OrangeMale -0.021714183       1        L FALSE #> 142.1...164 -0.0504997403   OrangeMale -0.021714183       1        L FALSE #> 114.1...165 -0.0443652846   OrangeMale -0.021714183       1        L FALSE #> 138...166   -0.0426729958   OrangeMale -0.021714183       1        L FALSE #> 149...167   -0.0603215604   OrangeMale -0.021714183       1        L FALSE #> 105.1...168 -0.0653480748   OrangeMale -0.021714183       1        L FALSE #> 143...169   -0.0529608225   OrangeMale -0.021714183       1        L FALSE #> 141.2...170 -0.0457032462   OrangeMale -0.021714183       1        L FALSE #> 120...171   -0.0539589545   OrangeMale -0.021714183       1        L FALSE #> 117...172   -0.0404971139   OrangeMale -0.021714183       1        L FALSE #> 111...173   -0.0239990063   OrangeMale -0.021714183       1        L FALSE #> 129...174   -0.0694031121   OrangeMale -0.021714183       1        L FALSE #> 145...175   -0.0345986882   OrangeMale -0.021714183       1        L FALSE #> 127.1...176 -0.0332358914   OrangeMale -0.021714183       1        L FALSE #> 130...177   -0.0602220450   OrangeMale -0.021714183       1        L FALSE #> 134...178   -0.0580485771   OrangeMale -0.021714183       1        L FALSE #> 127.2...179 -0.0332358914   OrangeMale -0.021714183       1        L FALSE #> 126...180   -0.0379577927   OrangeMale -0.021714183       1        L FALSE #> 101...181   -0.0379839038   OrangeMale -0.021714183       1        L FALSE #> 103...182   -0.0336746052   OrangeMale -0.021714183       1        L FALSE #> 147.1...183 -0.0638050154   OrangeMale -0.021714183       1        L FALSE #> 139...184   -0.0580455688   OrangeMale -0.021714183       1        L FALSE #> 111.1...185 -0.0239990063   OrangeMale -0.021714183       1        L FALSE #> 133...186   -0.0169282967   OrangeMale -0.021714183       1        L  TRUE #> 133.1...187 -0.0169282967   OrangeMale -0.021714183       1        L  TRUE #> 120.1...188 -0.0539589545   OrangeMale -0.021714183       1        L FALSE #> 141.3...189 -0.0457032462   OrangeMale -0.021714183       1        L FALSE #> 128...190   -0.0517606514   OrangeMale -0.021714183       1        L FALSE #> 145.1...191 -0.0345986882   OrangeMale -0.021714183       1        L FALSE #> 128.1...192 -0.0517606514   OrangeMale -0.021714183       1        L FALSE #> 146...193   -0.0762820766   OrangeMale -0.021714183       1        L FALSE #> 130.1...194 -0.0602220450   OrangeMale -0.021714183       1        L FALSE #> 122...195   -0.0477832589   OrangeMale -0.021714183       1        L FALSE #> 148...196   -0.0715789940   OrangeMale -0.021714183       1        L FALSE #> 136...197   -0.0678582767   OrangeMale -0.021714183       1        L FALSE #> 121...198   -0.0341836714   OrangeMale -0.021714183       1        L FALSE #> 101.1...199 -0.0379839038   OrangeMale -0.021714183       1        L FALSE #> 129.1...200 -0.0694031121   OrangeMale -0.021714183       1        L FALSE #> 186...201    0.0945703809 OrangeFemale  0.028269280       2        R  TRUE #> 161...202    0.0351289019 OrangeFemale  0.028269280       2        R  TRUE #> 191...203    0.0699859003 OrangeFemale  0.028269280       2        R  TRUE #> 166...204    0.0806788980 OrangeFemale  0.028269280       2        R  TRUE #> 185...205    0.1120916442 OrangeFemale  0.028269280       2        R  TRUE #> 197...206    0.0896837235 OrangeFemale  0.028269280       2        R  TRUE #> 156...207    0.0726631537 OrangeFemale  0.028269280       2        R  TRUE #> 157...208    0.0854850270 OrangeFemale  0.028269280       2        R  TRUE #> 184...209    0.0974977493 OrangeFemale  0.028269280       2        R  TRUE #> 172...210    0.0718340279 OrangeFemale  0.028269280       2        R  TRUE #> 192...211    0.1405441779 OrangeFemale  0.028269280       2        R  TRUE #> 199...212    0.0726867641 OrangeFemale  0.028269280       2        R  TRUE #> 154...213    0.0826977136 OrangeFemale  0.028269280       2        R  TRUE #> 173...214    0.1080082167 OrangeFemale  0.028269280       2        R  TRUE #> 186.1...215  0.0945703809 OrangeFemale  0.028269280       2        R  TRUE #> 155...216    0.0535642416 OrangeFemale  0.028269280       2        R  TRUE #> 200...217    0.1753446475 OrangeFemale  0.028269280       2        R  TRUE #> 163...218    0.0993377446 OrangeFemale  0.028269280       2        R  TRUE #> 153...219    0.0193730266 OrangeFemale  0.028269280       2        R FALSE #> 185.1...220  0.1120916442 OrangeFemale  0.028269280       2        R  TRUE #> 190...221    0.1244553738 OrangeFemale  0.028269280       2        R  TRUE #> 168...222    0.1003142711 OrangeFemale  0.028269280       2        R  TRUE #> 169...223    0.1059746352 OrangeFemale  0.028269280       2        R  TRUE #> 165...224    0.0892869200 OrangeFemale  0.028269280       2        R  TRUE #> 154.1...225  0.0826977136 OrangeFemale  0.028269280       2        R  TRUE #> 169.1...226  0.1059746352 OrangeFemale  0.028269280       2        R  TRUE #> 159...227    0.0929920199 OrangeFemale  0.028269280       2        R  TRUE #> 177...228    0.1322491101 OrangeFemale  0.028269280       2        R  TRUE #> 176...229    0.1133936796 OrangeFemale  0.028269280       2        R  TRUE #> 198...230    0.0767979012 OrangeFemale  0.028269280       2        R  TRUE #> 168.1...231  0.1003142711 OrangeFemale  0.028269280       2        R  TRUE #> 174...232    0.0600230241 OrangeFemale  0.028269280       2        R  TRUE #> 155.1...233  0.0535642416 OrangeFemale  0.028269280       2        R  TRUE #> 194...234    0.0876822739 OrangeFemale  0.028269280       2        R  TRUE #> 170...235    0.1004088531 OrangeFemale  0.028269280       2        R  TRUE #> 187...236    0.1007409954 OrangeFemale  0.028269280       2        R  TRUE #> 159.1...237  0.0929920199 OrangeFemale  0.028269280       2        R  TRUE #> 173.1...238  0.1080082167 OrangeFemale  0.028269280       2        R  TRUE #> 189...239    0.0890245735 OrangeFemale  0.028269280       2        R  TRUE #> 154.2...240  0.0826977136 OrangeFemale  0.028269280       2        R  TRUE #> 191.1...241  0.0699859003 OrangeFemale  0.028269280       2        R  TRUE #> 166.1...242  0.0806788980 OrangeFemale  0.028269280       2        R  TRUE #> 169.2...243  0.1059746352 OrangeFemale  0.028269280       2        R  TRUE #> 166.2...244  0.0806788980 OrangeFemale  0.028269280       2        R  TRUE #> 152...245    0.0181149655 OrangeFemale  0.028269280       2        R FALSE #> 176.1...246  0.1133936796 OrangeFemale  0.028269280       2        R  TRUE #> 184.1...247  0.0974977493 OrangeFemale  0.028269280       2        R  TRUE #> 196...248    0.1439662443 OrangeFemale  0.028269280       2        R  TRUE #> 152.1...249  0.0181149655 OrangeFemale  0.028269280       2        R FALSE #> 200.1...250  0.1753446475 OrangeFemale  0.028269280       2        R  TRUE #> 116...251   -0.0084621201   OrangeMale  0.028269280       2        L FALSE #> 147...252   -0.0483983266   OrangeMale  0.028269280       2        L FALSE #> 135...253   -0.0398974412   OrangeMale  0.028269280       2        L FALSE #> 123...254   -0.0005468789   OrangeMale  0.028269280       2        L FALSE #> 141...255   -0.0741304193   OrangeMale  0.028269280       2        L FALSE #> 102...256   -0.0091279036   OrangeMale  0.028269280       2        L FALSE #> 137...257   -0.0299873839   OrangeMale  0.028269280       2        L FALSE #> 118...258   -0.0123922257   OrangeMale  0.028269280       2        L FALSE #> 142...259   -0.0768649138   OrangeMale  0.028269280       2        L FALSE #> 127...260   -0.0436590700   OrangeMale  0.028269280       2        L FALSE #> 114...261   -0.0239782237   OrangeMale  0.028269280       2        L FALSE #> 141.1...262 -0.0741304193   OrangeMale  0.028269280       2        L FALSE #> 105...263    0.0034830176   OrangeMale  0.028269280       2        L FALSE #> 142.1...264 -0.0768649138   OrangeMale  0.028269280       2        L FALSE #> 114.1...265 -0.0239782237   OrangeMale  0.028269280       2        L FALSE #> 138...266   -0.0436025411   OrangeMale  0.028269280       2        L FALSE #> 149...267   -0.0247822402   OrangeMale  0.028269280       2        L FALSE #> 105.1...268  0.0034830176   OrangeMale  0.028269280       2        L FALSE #> 143...269   -0.0452659272   OrangeMale  0.028269280       2        L FALSE #> 141.2...270 -0.0741304193   OrangeMale  0.028269280       2        L FALSE #> 120...271   -0.0140659553   OrangeMale  0.028269280       2        L FALSE #> 117...272   -0.0020240245   OrangeMale  0.028269280       2        L FALSE #> 111...273    0.0084446797   OrangeMale  0.028269280       2        L FALSE #> 129...274   -0.0211886992   OrangeMale  0.028269280       2        L FALSE #> 145...275   -0.0745900619   OrangeMale  0.028269280       2        L FALSE #> 127.1...276 -0.0436590700   OrangeMale  0.028269280       2        L FALSE #> 130...277   -0.0562999118   OrangeMale  0.028269280       2        L FALSE #> 134...278   -0.0410066027   OrangeMale  0.028269280       2        L FALSE #> 127.2...279 -0.0436590700   OrangeMale  0.028269280       2        L FALSE #> 126...280   -0.0331382592   OrangeMale  0.028269280       2        L FALSE #> 101...281   -0.0158937191   OrangeMale  0.028269280       2        L FALSE #> 103...282    0.0030086091   OrangeMale  0.028269280       2        L FALSE #> 147.1...283 -0.0483983266   OrangeMale  0.028269280       2        L FALSE #> 139...284   -0.0261393056   OrangeMale  0.028269280       2        L FALSE #> 111.1...285  0.0084446797   OrangeMale  0.028269280       2        L FALSE #> 133...286   -0.0424471942   OrangeMale  0.028269280       2        L FALSE #> 133.1...287 -0.0424471942   OrangeMale  0.028269280       2        L FALSE #> 120.1...288 -0.0140659553   OrangeMale  0.028269280       2        L FALSE #> 141.3...289 -0.0741304193   OrangeMale  0.028269280       2        L FALSE #> 128...290   -0.0572383853   OrangeMale  0.028269280       2        L FALSE #> 145.1...291 -0.0745900619   OrangeMale  0.028269280       2        L FALSE #> 128.1...292 -0.0572383853   OrangeMale  0.028269280       2        L FALSE #> 146...293   -0.0629079831   OrangeMale  0.028269280       2        L FALSE #> 130.1...294 -0.0562999118   OrangeMale  0.028269280       2        L FALSE #> 122...295   -0.0287924851   OrangeMale  0.028269280       2        L FALSE #> 148...296   -0.0310355942   OrangeMale  0.028269280       2        L FALSE #> 136...297   -0.0214255473   OrangeMale  0.028269280       2        L FALSE #> 121...298   -0.0211528573   OrangeMale  0.028269280       2        L FALSE #> 101.1...299 -0.0158937191   OrangeMale  0.028269280       2        L FALSE #> 129.1...300 -0.0211886992   OrangeMale  0.028269280       2        L FALSE #> 99...301    -0.0990600036   BlueFemale -0.001016054       3        L FALSE #> 80...302    -0.0299141396   BlueFemale -0.001016054       3        L FALSE #> 89...303    -0.0316605756   BlueFemale -0.001016054       3        L FALSE #> 69...304    -0.0462239246   BlueFemale -0.001016054       3        L FALSE #> 89.1...305  -0.0316605756   BlueFemale -0.001016054       3        L FALSE #> 77...306    -0.0240326620   BlueFemale -0.001016054       3        L FALSE #> 96...307    -0.0394080966   BlueFemale -0.001016054       3        L FALSE #> 60...308    -0.0115237407   BlueFemale -0.001016054       3        L FALSE #> 65...309    -0.0910552724   BlueFemale -0.001016054       3        L FALSE #> 55...310     0.0035906133   BlueFemale -0.001016054       3        L  TRUE #> 61...311    -0.0211732472   BlueFemale -0.001016054       3        L FALSE #> 99.1...312  -0.0990600036   BlueFemale -0.001016054       3        L FALSE #> 65.1...313  -0.0910552724   BlueFemale -0.001016054       3        L FALSE #> 87...314    -0.0580327475   BlueFemale -0.001016054       3        L FALSE #> 90...315    -0.0425563435   BlueFemale -0.001016054       3        L FALSE #> 56...316    -0.0225920819   BlueFemale -0.001016054       3        L FALSE #> 62...317    -0.0332043815   BlueFemale -0.001016054       3        L FALSE #> 64...318    -0.0539135167   BlueFemale -0.001016054       3        L FALSE #> 56.1...319  -0.0225920819   BlueFemale -0.001016054       3        L FALSE #> 56.2...320  -0.0225920819   BlueFemale -0.001016054       3        L FALSE #> 100...321   -0.0474439279   BlueFemale -0.001016054       3        L FALSE #> 100.1...322 -0.0474439279   BlueFemale -0.001016054       3        L FALSE #> 57...323    -0.0302150328   BlueFemale -0.001016054       3        L FALSE #> 96.1...324  -0.0394080966   BlueFemale -0.001016054       3        L FALSE #> 79...325    -0.0620159893   BlueFemale -0.001016054       3        L FALSE #> 70...326    -0.0900308008   BlueFemale -0.001016054       3        L FALSE #> 73...327    -0.0540653166   BlueFemale -0.001016054       3        L FALSE #> 86...328    -0.0671394398   BlueFemale -0.001016054       3        L FALSE #> 55.1...329   0.0035906133   BlueFemale -0.001016054       3        L  TRUE #> 67...330    -0.0485218873   BlueFemale -0.001016054       3        L FALSE #> 85...331    -0.0526105396   BlueFemale -0.001016054       3        L FALSE #> 66...332    -0.0267729912   BlueFemale -0.001016054       3        L FALSE #> 92...333    -0.0761981287   BlueFemale -0.001016054       3        L FALSE #> 61.1...334  -0.0211732472   BlueFemale -0.001016054       3        L FALSE #> 75...335    -0.0213147205   BlueFemale -0.001016054       3        L FALSE #> 64.1...336  -0.0539135167   BlueFemale -0.001016054       3        L FALSE #> 60.1...337  -0.0115237407   BlueFemale -0.001016054       3        L FALSE #> 98...338    -0.1152517953   BlueFemale -0.001016054       3        L FALSE #> 67.1...339  -0.0485218873   BlueFemale -0.001016054       3        L FALSE #> 74...340    -0.0237612549   BlueFemale -0.001016054       3        L FALSE #> 52...341    -0.0176837238   BlueFemale -0.001016054       3        L FALSE #> 78...342    -0.0575669010   BlueFemale -0.001016054       3        L FALSE #> 83...343    -0.0713853763   BlueFemale -0.001016054       3        L FALSE #> 80.1...344  -0.0299141396   BlueFemale -0.001016054       3        L FALSE #> 67.2...345  -0.0485218873   BlueFemale -0.001016054       3        L FALSE #> 95...346    -0.0869163604   BlueFemale -0.001016054       3        L FALSE #> 82...347    -0.0737636554   BlueFemale -0.001016054       3        L FALSE #> 66.1...348  -0.0267729912   BlueFemale -0.001016054       3        L FALSE #> 70.1...349  -0.0900308008   BlueFemale -0.001016054       3        L FALSE #> 59...350    -0.0334997903   BlueFemale -0.001016054       3        L FALSE #> 44...351     0.0162715373     BlueMale -0.001016054       3        R  TRUE #> 48...352     0.1174257811     BlueMale -0.001016054       3        R  TRUE #> 29...353     0.0306481161     BlueMale -0.001016054       3        R  TRUE #> 17...354     0.0388325191     BlueMale -0.001016054       3        R  TRUE #> 50...355     0.1123263324     BlueMale -0.001016054       3        R  TRUE #> 12...356    -0.0141510393     BlueMale -0.001016054       3        R FALSE #> 31...357     0.0344844002     BlueMale -0.001016054       3        R  TRUE #> 6...358      0.0204005730     BlueMale -0.001016054       3        R  TRUE #> 25...359     0.0446254895     BlueMale -0.001016054       3        R  TRUE #> 5...360      0.0261078632     BlueMale -0.001016054       3        R  TRUE #> 9...361      0.0151422260     BlueMale -0.001016054       3        R  TRUE #> 15...362     0.0063533301     BlueMale -0.001016054       3        R  TRUE #> 30...363     0.0823477363     BlueMale -0.001016054       3        R  TRUE #> 37...364     0.0649354196     BlueMale -0.001016054       3        R  TRUE #> 9.1...365    0.0151422260     BlueMale -0.001016054       3        R  TRUE #> 44.1...366   0.0162715373     BlueMale -0.001016054       3        R  TRUE #> 36...367     0.0671940914     BlueMale -0.001016054       3        R  TRUE #> 39...368     0.0783033376     BlueMale -0.001016054       3        R  TRUE #> 8...369      0.0428495675     BlueMale -0.001016054       3        R  TRUE #> 18...370     0.0240048615     BlueMale -0.001016054       3        R  TRUE #> 34...371     0.0442568627     BlueMale -0.001016054       3        R  TRUE #> 27...372     0.0603716866     BlueMale -0.001016054       3        R  TRUE #> 18.1...373   0.0240048615     BlueMale -0.001016054       3        R  TRUE #> 13...374     0.0568630038     BlueMale -0.001016054       3        R  TRUE #> 3...375      0.0124171860     BlueMale -0.001016054       3        R  TRUE #> 12.1...376  -0.0141510393     BlueMale -0.001016054       3        R FALSE #> 45...377     0.1254157448     BlueMale -0.001016054       3        R  TRUE #> 41...378     0.0709894706     BlueMale -0.001016054       3        R  TRUE #> 38...379     0.0804937541     BlueMale -0.001016054       3        R  TRUE #> 8.1...380    0.0428495675     BlueMale -0.001016054       3        R  TRUE #> 7...381     -0.0095654404     BlueMale -0.001016054       3        R FALSE #> 49...382     0.0973413905     BlueMale -0.001016054       3        R  TRUE #> 22...383     0.0625347528     BlueMale -0.001016054       3        R  TRUE #> 24...384     0.0646569140     BlueMale -0.001016054       3        R  TRUE #> 9.2...385    0.0151422260     BlueMale -0.001016054       3        R  TRUE #> 30.1...386   0.0823477363     BlueMale -0.001016054       3        R  TRUE #> 14...387     0.0392251476     BlueMale -0.001016054       3        R  TRUE #> 12.2...388  -0.0141510393     BlueMale -0.001016054       3        R FALSE #> 35...389     0.0708289583     BlueMale -0.001016054       3        R  TRUE #> 15.1...390   0.0063533301     BlueMale -0.001016054       3        R  TRUE #> 41.1...391   0.0709894706     BlueMale -0.001016054       3        R  TRUE #> 5.1...392    0.0261078632     BlueMale -0.001016054       3        R  TRUE #> 42...393     0.0607561243     BlueMale -0.001016054       3        R  TRUE #> 22.1...394   0.0625347528     BlueMale -0.001016054       3        R  TRUE #> 38.1...395   0.0804937541     BlueMale -0.001016054       3        R  TRUE #> 34.1...396   0.0442568627     BlueMale -0.001016054       3        R  TRUE #> 23...397     0.0761194978     BlueMale -0.001016054       3        R  TRUE #> 32...398     0.0336461772     BlueMale -0.001016054       3        R  TRUE #> 1...399      0.0131494769     BlueMale -0.001016054       3        R  TRUE #> 11...400     0.0101110325     BlueMale -0.001016054       3        R  TRUE"},{"path":"https://github.com/natydasilva/PPforest/reference/olive.html","id":null,"dir":"Reference","previous_headings":"","what":"The olive data set — olive","title":"The olive data set — olive","text":"olive data set","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/olive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The olive data set — olive","text":"","code":"data(olive)"},{"path":"https://github.com/natydasilva/PPforest/reference/olive.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The olive data set — olive","text":"Contains  572 observations 10 variables Region Three super-classes Italy: North, South island Sardinia. area Nine collection areas: three North, four South 2 Sardinia. palmitic fatty acids percent x 100. palmitoleic fatty acids percent x 100. stearic fatty acids percent x 100. oleic fatty acids percent x 100. linoleic fatty acids percent x 100. linolenic fatty acids percent x 100. arachidic fatty acids percent x 100. eicosenoic fatty acids percent x 100. data frame contains 573 observations 10 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":null,"dir":"Reference","previous_headings":"","what":"Parkinson data set — parkinson","title":"Parkinson data set — parkinson","text":"Parkinson data set","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parkinson data set — parkinson","text":"","code":"data(parkinson)"},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Parkinson data set — parkinson","text":"data set containing 195 observations 2 parkinson types. Type Class variable 2 classes, 48 cases healthy people 147 cases Parkinson. feature variables biomedical voice measures. X1 Average vocal fundamental frequency. X2 Maximum vocal fundamental frequency. X3 Minimum vocal fundamental frequency. X4 MDVP:Jitter(%) measures variation fundamental frequency. X5 MDVP:Jitter(Abs) measures variation fundamental frequency. X6 MDVP:RAP measures variation fundamental frequency. X7 MDVP:PPQ measures variation fundamental frequency. X8 Jitter:DDP measures variation fundamental frequency. X9 MDVP:Shimmer measures variation amplitude. X10 MDVP:Shimmer(dB) measures variation amplitude. X11 Shimmer:APQ3 measures variation amplitude. X12 Shimmer:APQ5 measures variation amplitude. X13 MDVP:APQ measures variation amplitude. X14 Shimmer:DDA measures variation amplitude. X15 NHR measures ratio noise tonal components voice. X16 HNR measures ratio noise tonal components voice. X17 RPDE nonlinear dynamical complexity measures. X18 D2 nonlinear dynamical complexity measures. X19 DFA - Signal fractal scaling exponent. X20 spread1 Nonlinear measures fundamental frequency variation. X21 spread2 Nonlinear measures fundamental frequency variation. X22 PPE Nonlinear measures fundamental frequency variation. data frame 195 rows 23 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Parkinson data set — parkinson","text":"<https://archive.ics.uci.edu/ml/datasets/Parkinsons>","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain the permuted importance variable measure — permute_importance","title":"Obtain the permuted importance variable measure — permute_importance","text":"Obtain permuted importance variable measure","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain the permuted importance variable measure — permute_importance","text":"","code":"permute_importance(ppf)"},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain the permuted importance variable measure — permute_importance","text":"ppf PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain the permuted importance variable measure — permute_importance","text":"data frame permuted importance measures, imp permuted importance measure defined Brieman paper, imp2 permuted importance measure defined randomForest package, standard deviation (sd.im sd.imp2) measure computed also standardized mesure.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain the permuted importance variable measure — permute_importance","text":"","code":"pprf.crab <- PPforest(data = crab, y = 'Type', std = 'min-max', size.tr = 1, m = 100, size.p = .4, PPmethod = 'LDA', parallel = TRUE, core = 2) permute_importance(ppf = pprf.crab)  #>   nm   imp   sd.imp      imp2   sd.imp2 imp2.std  imp.std #> 1 CW 12.33 10.18620 0.1683782 0.1369413 1.229565 1.210461 #> 2 CL 13.53 11.46664 0.1863579 0.1566416 1.189709 1.179944 #> 3 BD 15.38 12.76420 0.2105262 0.1738368 1.211056 1.204932 #> 4 FL 17.02 13.37190 0.2329609 0.1807638 1.288759 1.272818 #> 5 RW 17.32 11.24734 0.2363852 0.1525993 1.549058 1.539920"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"Global importance measure PPforest object average IMP PPtree measure trees forest","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"","code":"ppf_avg_imp(ppf, y)"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"ppf PPforest object y character name class variable.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"Data frame global importance measure","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"da Silva, N., Cook, D., & Lee, E. K. (2021). projection pursuit forest algorithm supervised classification. Journal Computational Graphical Statistics, 30(4), 1168-1180.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"","code":"#crab data set with all the observations used as training  pprf.crab <- PPforest(data = crab, std = 'min-max', y = 'Type',  size.tr = 1, m = 100, size.p = .5, PPmethod = 'LDA')  ppf_avg_imp(pprf.crab, 'Type')  #> # A tibble: 5 × 2 #>   variable  mean #>   <fct>    <dbl> #> 1 CL       0.477 #> 2 CW       0.412 #> 3 RW       0.377 #> 4 BD       0.306 #> 5 FL       0.294"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Global importance measure for a PPforest object — ppf_global_imp","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"Global importance measure PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"","code":"ppf_global_imp(data, y, ppf)"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"data Data frame complete data set. y character name class variable. ppf PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"Data frame global importance measure","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"da Silva, N., Cook, D., & Lee, E. K. (2021). projection pursuit forest algorithm supervised classification. Journal Computational Graphical Statistics, 30(4), 1168-1180.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"","code":"#crab data set with all the observations used as training pprf.crab <- PPforest(data = crab, y = 'Type',  std = 'no',  size.tr = 1, m = 200, size.p = .5,   PPmethod = 'LDA', parallel = TRUE, cores = 2)   ppf_global_imp(data = crab, y = 'Type', pprf.crab)  #> # A tibble: 5 × 2 #>   variable  mean #>   <fct>    <dbl> #> 1 RW       0.404 #> 2 FL       0.295 #> 3 BD       0.291 #> 4 CL       0.241 #> 5 CW       0.238"},{"path":"https://github.com/natydasilva/PPforest/reference/predict.PPforest.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for PPforest objects — predict.PPforest","title":"Predict method for PPforest objects — predict.PPforest","text":"Predict method PPforest objects","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/predict.PPforest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for PPforest objects — predict.PPforest","text":"","code":"# S3 method for class 'PPforest' predict(object, newdata, rule = 1, parallel = TRUE, cores = 2, ...)"},{"path":"https://github.com/natydasilva/PPforest/reference/predict.PPforest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for PPforest objects — predict.PPforest","text":"object fitted PPforest object newdata data frame predictors (structure training data) rule Split rule used classification (integer 1 8) 1: mean two group means 2: weighted mean two group means - weight group size 3: weighted mean two group means - weight group sd 4: weighted mean two group means - weight group se 5: mean two group medians 6: weighted mean two group medians - weight group size 7: weighted mean two group median - weight group IQR 8: weighted mean two group median - weight group IQR size parallel Logical, whether use parallel processing cores Number cores use parallel = TRUE ... Additional arguments (ignored)","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/predict.PPforest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict method for PPforest objects — predict.PPforest","text":"list : predtree Matrix individual tree predictions predforest Final predicted classes based majority vote","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/predict.PPforest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict method for PPforest objects — predict.PPforest","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(123) train <- sample(1:nrow(crab), nrow(crab)*.7) crab_train <- data.frame(crab[train, ]) crab_test <- data.frame(crab[-train, ])  # if you split your data in training and test outside PPforest size.tr should be 1. pprf.crab <- PPforest(data = crab_train, class = 'Type',  std = 'scale', size.tr = 1, m = 200, size.p = .4, PPmethod = 'LDA', parallel = TRUE )   pred <- predict(pprf.crab, newdata = crab_test[,-1], parallel = TRUE)  } # }"},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":null,"dir":"Reference","previous_headings":"","what":"Print PPforest object — print.PPforest","title":"Print PPforest object — print.PPforest","text":"Print PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print PPforest object — print.PPforest","text":"","code":"# S3 method for class 'PPforest' print(x, ...)"},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print PPforest object — print.PPforest","text":"x PPforest class object ... additional parameter","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print PPforest object — print.PPforest","text":"printed results PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":null,"dir":"Reference","previous_headings":"","what":"Data structure with the projected and boundary by node and class. — ternary_str","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"Data structure  projected boundary node class.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"","code":"ternary_str(ppf, id, sp, dx, dy)"},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"ppf PPforest object id vector selected projection directions sp simplex dimensions, k number classes sp = k - 1 dx first direction included id dy second direction included id","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"Data frame needed visualize ternary plot","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"da da Silva, N., Cook, D. & Lee, EK. Interactive graphics visually diagnosing forest classifiers R. Comput Stat 40, 3105–3125 (2025). https://doi.org/10.1007/s00180-023-01323-x","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"","code":"#crab data set with all the observations used as training pprf.crab <- PPforest(data = crab, std ='min-max', y = \"Type\",  size.tr = 1, m = 100, size.p = .5, PPmethod = 'LDA')  require(dplyr) #> Loading required package: dplyr #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union pl_ter <- function(dat, dx, dy ){   p1  <- dat[[1]] %>% dplyr::filter(pair %in% paste(dx, dy, sep = \"-\") ) %>%     dplyr::select(Class, x, y) %>%     ggplot2::ggplot(ggplot2::aes(x, y, color = Class)) +     ggplot2::geom_segment(data = dat[[2]], ggplot2::aes(x = x1, xend = x2,                                                y = y1, yend = y2), color = \"black\" ) +     ggplot2::geom_point(size = I(3), alpha = .5) +     ggplot2::labs(y = \" \",  x = \" \") +     ggplot2::theme(legend.position = \"none\", aspect.ratio = 1) +     ggplot2::scale_colour_brewer(type = \"qual\", palette = \"Dark2\") +     ggplot2::labs(x = paste0(\"T\", dx, \" \"), y = paste0(\"T\", dy, \" \")) +     ggplot2::theme(aspect.ratio = 1)   p1 } #ternary plot in tree different selected dierections  pl_ter(ternary_str(pprf.crab, id = c(1, 2, 3), sp = 3, dx = 1, dy = 2), 1, 2 )"},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"Obtain predicted class new data baggtree function PPforest","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"","code":"trees_pred(object, xnew, parallel = FALSE, cores = 2, rule = 1)"},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"object Projection pursuit classification forest structure PPforest baggtree xnew data frame explicative variables used get new predicted values. parallel logical condition, TRUE  parallelize function cores number cores used parallelization rule Split rule used classification (integer 1 8). 1: mean two group means 2: weighted mean two group means - weight group size 3: weighted mean two group means - weight group sd 4: weighted mean two group means - weight group se 5: mean two group medians 6: weighted mean two group medians - weight group size 7: weighted mean two group median - weight group IQR 8: weighted mean two group median - weight group IQR size","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"predicted values PPforest baggtree","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/wine.html","id":null,"dir":"Reference","previous_headings":"","what":"Wine data set — wine","title":"Wine data set — wine","text":"Wine data set","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/wine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wine data set — wine","text":"","code":"data(wine)"},{"path":"https://github.com/natydasilva/PPforest/reference/wine.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Wine data set — wine","text":"data set containing 178 observations 3 wine grown cultivares Italy. Type Class variable 3 classes 3 different wine grown cultivares Italy. X1 X13 Check vbles data frame 178 rows 14 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/news/index.html","id":"ppforest-020","dir":"Changelog","previous_headings":"","what":"PPforest 0.2.0","title":"PPforest 0.2.0","text":"CRAN release: 2025-07-23 Changes version 0.2.0 fifth release package, minor changes. Added predict() S3 method PPforest objects. Included new data standardization methods: min-max, quantile, scale. PPforest object fitted using standardizations, predict() method apply transformation newdata. Argument class PPforest version 0.1.3 renamed y version 0.1.3, functions PPclasifly, baggtrees, tres.pred exported. version, now kept internal functions. Fixed several bugs.","code":""}]
