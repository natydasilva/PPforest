[{"path":"https://github.com/natydasilva/PPforest/articles/PPforest-vignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Projection pursuit classification random forest","text":"PPforest package (projection pursuit random forest) contains functions run projection pursuit random forest classification problems. method utilize combinations variables tree construction. random forest split based single variable, chosen subset predictors. PPforest, split based linear combination randomly chosen variables. linear combination computed optimizing projection pursuit index, get projection variables best separates classes. PPforest uses PPtree algorithm, fits single tree data. Utilizing linear combinations variables separate classes takes correlation variables account, can outperform basic forest separations groups occurs combinations variables. Two projection pursuit indexes, LDA PDA, used PPforest. improve speed performance PPforest package, PPtree algorithm translated Rcpp. PPforest package utilizes number R packages included “suggests” load package start-. can install package CRAN: development version PPforest can installed github using: ##Projection pursuit classification forest PPforest, projection pursuit classification trees used individual model combined forest. original algorithm PPtreeViz package, translate original tree algorithm Rcpp improve speed performance run forest. One important characteristic PPtree treats data always two-class system, classes two algorithm uses two step projection pursuits optimization every node split. Let \\((X_i,y_i)\\) data set, \\(X_i\\) p-dimensional vector explanatory variables \\(y_i\\{1,2,\\ldots G}\\) represents class information \\(=1,\\ldots n\\). first step optimize projection pursuit index find optimal one-dimension projection \\(\\alpha^*\\) separating classes current data. projected data redefine problem two class problem comparing means, assign new label \\(G1\\) \\(G2\\) observation, new variable \\(y_i^*\\) created. new groups \\(G1\\) \\(G2\\) can contain one original classes. Next step find optimal one-dimensional projection \\(\\alpha\\), using \\((X_i,y_i^*)\\) separate two class problem \\(G1\\) \\(G2\\). best separation \\(G1\\) \\(G2\\) determine step decision rule defined current node, \\(\\sum_{=1}^p \\alpha_i M1< c\\) assign \\(G1\\) left node else assign \\(G2\\) right node, \\(M1\\) mean \\(G1\\). groups can repeat previous steps \\(G1\\) \\(G2\\) one class original classes. Base process grow tree, depth PPtree number classes one class assigned one final node. Trees PPtree algorithm simple, use association variables find separation. linear boundary exists, PPtree produces tree without misclassification. Projection pursuit random forest algorithm description Let N number cases training set \\(\\Theta=(X,Y)\\), \\(B\\) bootstrap samples training set taking (samples size N replacement). bootstrap sample \\verb PPtree grown largest extent possible \\(h(x, {\\Theta_k})\\). pruning. tree grown using step 3 modification. Let M number input variables, number \\(m<<M\\) variables selected random node best split based linear combination randomly chosen variables. linear combination computed optimizing projection pursuit index, get projection variables best separates classes. Predict classes case included bootstrap sample compute oob error. Based majority vote predict class new data. ###Overview PPforest package PPforest package implements classification random forest using projection pursuit classification trees. following table present functions PPforest package. Also PPforest package includes data set used test predictive performance method. data sets included : crab, fishcatch, glass, image, leukemia, lymphoma NCI60, parkinson wine.","code":"install.package(PPforest) library(PPforest) library(devtools) install_github(\"natydasilva/PPforest\") library(PPforest)"},{"path":"https://github.com/natydasilva/PPforest/articles/PPforest-vignette.html","id":"example","dir":"Articles","previous_headings":"Introduction","what":"Example","title":"Projection pursuit classification random forest","text":"Australian crab data set used example. data contains measurements rock crabs genus Leptograpsus. 200 observations two species (blue orange) specie (50 one) 50 males 50 females. Class variable 4 classes combinations specie sex (BlueMale, BlueFemale, OrangeMale OrangeFemale). data collected site Fremantle, Western Australia. specimen, five measurements made, using vernier calipers. FL size frontal lobe length, mm RW rear width, mm CL length mid line carapace, mm CW maximum width carapace, mm BD depth body; females, measured displacement abdomen, mm visualize data set use scatterplot matrix package GGally     Scatter plot matrix crab data     figure can see strong, positive linear association different variables. Also look like classes can separated linear combinations. main function package PPforest implements projection pursuit random forest. PPtree_split function implements projection pursuit classification tree random variable selection split, based original PPtreeViz algorithm. function returns PPtreeclass object. use function need specify formula describing model fitted response~predictors (form), data data frame complete data set. Also need specify method PPmethod, index use projection pursuit: ‘LDA’ ‘PDA’, size.p proportion variables randomly sampled split. size.p = 1 classic PPtreeclass object fitted using variables node partition instead subset . lambda penalty parameter PDA index 0 1 . following example fits projection pursuit classification tree constructed using 0.6 variables (3 5) node split. selected LDA method. PPforest function runs projection pursuit random forest. arguments data frame data information, class name class variable argument. size.tr specify proportion observations using training. Using function option split data training test using size.tr directly. size.tr proportion data used training test proportion 1- size.tr. number trees forest specified using argument m. argument size.p sample proportion variables used node split, PPmethod projection pursuit index optimized, two options LDA PDA available. PPforest print summary result model confusion matrix information oob-error rate similar way randomForest packages . function returns predicted values training data, training error, test error predicted test values. Also information bag error forest also tree forest. Bootstrap samples, output trees forest , proximity matrix vote matrix, number trees grown forest, number predictor variables selected use splitting node. Confusion matrix prediction (based OOb data), training data test data vote matrix also returned. printed version PPforest object follows randomForest printed version make comparable. Based confusion matrix, can observe biggest error BlueMale class. wrong classified values BlueFemale BlueMale. output PPforest object contains lot information can see next output. example get predicted values test data can use PPforest output: new data available can use function trees_pred get predicted classes PPforest object. PPforest algorithm calculates variable importance two ways: (1) permuted importance using accuracy, (2) importance based projection coefficients standardized variables. permuted variable importance comparable measure defined classical random forest algorithm. computed using bag (oob) sample tree \\(k\\;\\;(B^{(k)})\\) \\(X_j\\) predictor variable. permuted importance variable \\(X_j\\) tree \\(k\\) can defined : \\[ IMP^{(k)}(X_j) = \\frac{\\sum_{\\B^{(k)} } (y_i=\\hat y_i^{(k)})-(y_i=\\hat y_{,P_j}^{(k)})}{|B^{(k)}|} \\] \\(\\hat y_i^{(k)}\\) predicted class observation \\(\\) tree \\(k\\) \\(y_{,P_j}^{(k)}\\) predicted class observation \\(\\) tree \\(k\\) permuting values variable \\(X_j\\). global permuted importance measure average importance trees forest. measure based comparing accuracy classifying --bag observations, using true class permuted (nonsense) class. compute measure use permute_importance function.         Permuted importance variable     function returns data frame permuted importance measures, imp permuted importance measure defined Brieman paper, imp2 permuted importance measure defined randomForest package, standard deviation (sd.im sd.imp2) measure computed also standardized measure. second importance measure, coefficients projection examined. magnitude values indicates importance, variables standardized. variable importance single tree computed weighted sum absolute values coefficients across nodes. weights takes number classes node account (Lee et al. 2013). importance variable \\(X_j\\) PPtree \\(k\\) can defined : \\[   IMP_{pptree}^{(k)}(X_j)=\\sum_{nd = 1}^{nn}\\frac{|\\alpha_{nd}^{(k)}|}{cl_{nd} } \\] \\(\\alpha_{nd}^{(k)}\\) projected coefficient node \\(ns\\) variable \\(k\\) \\(nn\\) total number node partitions tree \\(k\\). global variable importance PPforest can defined different ways. intuitive average variable importance PPtree across trees forest. \\[ IMP_{ppforest1}(X_j)=\\frac{\\sum_{k=1}^K IMP_{pptree}^{(k)}(X_j)}{K} \\] Alternatively defined global importance measure forest weighted mean absolute value projection coefficients across nodes every tree. weights based projection pursuit indexes node (\\(Ix_{nd}\\)), 1-(OOB-error tree)(\\(acc_k\\)). \\[IMP_{ppforest2}(X_j)=\\frac{\\sum_{k=1}^K acc_k \\sum_{nd = 1}^{nn}\\frac{Ix_{nd}|\\alpha_{nd}^{(k)}|}{nn }}{K} \\]         Average importance variable     Finally can get last importance measure proposed PPforest using `ppf_global_imp’ function.         Global importance variable Using information available PPforest object, visualization can done. include useful examples visualize data important diagnostics forest structure. describe data structure parallel plot can done, data standardized color represents class variable.     Parallel coordinate plot crab data     ternary_str auxiliary functions PPforest get data structure needed ternary plot generalized ternary plot 3 classes available. PPforest composed many tree fits subsets data, lot statistics can calculated analyze separate data set, better understand model working. diagnostics interest : variable importance, OOB error rate, vote matrix proximity matrix. decision tree can compute every pair observations proximity matrix. \\(nxn\\) matrix two cases \\(k_i\\) \\(k_j\\) terminal node increase proximity one, end normalize proximities dividing number trees. visualize proximity matrix use scatter plot information multidimensional scaling method. plot color indicates true species sex. data two dimensions enough see four groups separated quite well. crabs clearly similar different group, though, especially examining sex differences.     Multidimensional scaling plot examine similarities cases     vote matrix (\\(n \\times p\\)) contains proportion times observation classified class, whole oob. Two possible approaches visualize vote matrix information shown, side--side jittered dot plot ternary plots. side--side jittered dotplot used display, class displayed one axis proportion displayed . dotplot, ideal arrangement points observations class values bigger 0.5, observations less. data close ideal perfect, e.g. blue male crabs (orange) frequently predicted blue females (green), blue female crabs predicted another class.     Vote matrix representation jittered side--side dotplot. dotplot shows proportion times case predicted group, 1 indicating case always predicted group 0 never.     ternary plot triangular diagram shows proportion three variables sum constant done using barycentric coordinates. Compositional data lies \\((p-1)\\)-D simplex \\(p\\)-space. One advantage ternary plot good visualize compositional data proportion three variables two dimensional space can shown. tree classes ternary plot well defined. tree classes ternary plot idea need generalized.@sutherland2000orca suggest best approach visualize compositional data project data \\((p-1)-\\)D space (ternary diagram \\(2-D\\)) approach used visualize vote matrix information. ternary plot triangular diagram used display compositional data three components. generally, compositional data can number components, say \\(p\\), hence contrained \\((p-1)\\)-D simplex \\(p\\)-space. vote matrix example compositional data, \\(G\\) components.     Generalized ternary plot representation vote matrix four classes. tetrahedron shown pairwise. point corresponds one observation color true class.     see complete description visualize PPforest object read Interactive Graphics Visually Diagnosing Forest Classifiers R (Silva, Cook, Lee 2017).","code":"Tree.crab <- PPforest::PPtree_split(\"Type~.\", data = crab, PPmethod = \"LDA\", size.p = 0.6)  Tree.crab ## =============================================================  ## Projection Pursuit Classification Tree result  ## ============================================================= ##  ## 1) root ##    2)  proj1*X < cut1 ##       4)* proj2*X < cut2  ->  \"2\" ##       5)* proj2*X >= cut2  ->  \"1\" ##    3)  proj1*X >= cut1 ##       6)* proj3*X < cut3  ->  \"4\" ##       7)* proj3*X >= cut3  ->  \"3\" ##  ## Error rates of various cutoff values  ## ------------------------------------------------------------- ##            Rule1 Rule2 Rule3 Rule4 Rule5 Rule6 Rule7 Rule8 ## error.rate 0.065 0.065 0.065 0.065 0.075 0.075 0.075 0.075 pprf.crab <- PPforest::PPforest(data = crab, class = \"Type\", size.tr = .8, m = 200,                                 size.p =  .5,  PPmethod = 'LDA',  parallel =FALSE, cores = 2)  pprf.crab ##  ## Call: ##  PPforest::PPforest(data = crab, class = \"Type\", size.tr = 0.8,      m = 200, PPmethod = \"LDA\", size.p = 0.5, parallel = FALSE,      cores = 2)  ##                Type of random forest: Classification ##                      Number of trees: 200 ## No. of variables tried at each split: 2 ##  ##         OOB estimate of  error rate: 4.37% ## Confusion matrix: ##              BlueFemale BlueMale OrangeFemale OrangeMale class.error ## BlueFemale           38        2            0          0        0.05 ## BlueMale              3       37            0          0        0.07 ## OrangeFemale          0        0           39          1        0.03 ## OrangeMale            0        1            0         39        0.03 str(pprf.crab, max.level = 1 ) ## List of 21 ##  $ predicting.training: Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 2 2 1 2 2 2 1 2 ... ##  $ training.error     : num 0.0375 ##  $ prediction.test    : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 1 2 2 2 2 2 2 2 ... ##  $ error.test         : num 0.15 ##  $ oob.error.forest   : num 0.0437 ##  $ oob.error.tree     : num [1:200, 1] 0.1695 0.2679 0.0317 0.1207 0.3273 ... ##  $ boot.samp          :List of 200 ##  $ output.trees       :List of 200 ##  $ proximity          : num [1:160, 1:160] 0 0.8 0.87 0.815 0.39 0.9 0.78 0.51 0.395 0.705 ... ##  $ votes              : num [1:160, 1:4] 0.222 0.333 0.191 0.222 0.661 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##  $ prediction.oob     : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 2 2 1 2 2 2 1 2 ... ##  $ n.tree             : num 200 ##  $ n.var              : num 2 ##  $ type               : chr \"Classification\" ##  $ confusion          : num [1:4, 1:5] 38 3 0 0 2 37 0 1 0 0 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##  $ call               : language PPforest::PPforest(data = crab, class = \"Type\", size.tr = 0.8, m = 200,      PPmethod = \"LDA\", size.p = 0.5, para| __truncated__ ##  $ train              :'data.frame': 160 obs. of  6 variables: ##  $ test               :'data.frame': 40 obs. of  5 variables: ##  $ vote.mat           : num [1:200, 1:160] 1 1 2 2 1 1 2 4 4 2 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##  $ class.var          : chr \"Type\" ##  $ oob.obs            : num [1:200, 1:160] 0 1 1 0 0 0 0 1 1 1 ... ##  - attr(*, \"class\")= chr \"PPforest\" pprf.crab$prediction.test ##  [1] BlueMale     BlueMale     BlueFemale   BlueMale     BlueMale     ##  [6] BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     ## [11] BlueMale     BlueFemale   BlueFemale   BlueFemale   BlueFemale   ## [16] BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   ## [21] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   ## [26] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   ## [31] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeFemale ## [36] OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale ## Levels: BlueFemale BlueMale OrangeFemale OrangeMale trees_pred(pprf.crab, xnew = newdata, parallel = TRUE) impo1 <- permute_importance(pprf.crab) impo1 ##   nm    imp    sd.imp      imp2   sd.imp2 imp2.std  imp.std ## 1 CW 17.975  9.342418 0.3104134 0.1596670 1.944129 1.924020 ## 2 BD 18.470 10.632703 0.3199451 0.1844948 1.734169 1.737094 ## 3 CL 20.505 10.005023 0.3559586 0.1728535 2.059308 2.049471 ## 4 FL 20.805 11.036576 0.3594990 0.1874475 1.917865 1.885096 ## 5 RW 21.195  9.461213 0.3668738 0.1613988 2.273088 2.240199 impo2 <-  ppf_avg_imp(pprf.crab, \"Type\") impo2 ## # A tibble: 5 × 2 ##   variable  mean ##   <fct>    <dbl> ## 1 CL       0.462 ## 2 CW       0.452 ## 3 RW       0.385 ## 4 BD       0.313 ## 5 FL       0.279 impo3 <- ppf_global_imp(data = crab, class = \"Type\", pprf.crab) impo3 ## # A tibble: 5 × 2 ##   variable  mean ##   <fct>    <dbl> ## 1 CW       0.419 ## 2 CL       0.384 ## 3 RW       0.335 ## 4 BD       0.281 ## 5 FL       0.236"},{"path":[]},{"path":"https://github.com/natydasilva/PPforest/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Natalia da Silva. Maintainer.","code":""},{"path":"https://github.com/natydasilva/PPforest/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Silva Nd, Lee E, Cook D (2023). PPforest: Projection Pursuit Classification Forest. R package version 0.1.3, https://github.com/natydasilva/PPforest.","code":"@Manual{,   title = {PPforest: Projection Pursuit Classification Forest},   author = {Natalia da Silva and Eun-Kyung Lee and Di Cook},   year = {2023},   note = {R package version 0.1.3},   url = {https://github.com/natydasilva/PPforest}, }"},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"the-ppforest-package","dir":"","previous_headings":"","what":"Projection Pursuit Classification Forest","title":"Projection Pursuit Classification Forest","text":"N. da Silva, D. Cook & E. Lee","code":""},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Projection Pursuit Classification Forest","text":"PPforest package (projection pursuit random forest) contains functions run projection pursuit random forest classification problems. method utilize combinations variables tree construction. random forest split based single variable, chosen subset predictors. PPforest, split based linear combination randomly chosen variables. linear combination computed optimizing projection pursuit index, get projection variables best separates classes. PPforest uses PPtree algorithm, fits single tree data. Utilizing linear combinations variables separate classes takes correlation variables account, can outperform basic forest separations groups occurs combinations variables. Two projection pursuit indexes, LDA PDA, used PPforest. improve speed performance PPforest package, PPtree algorithm translated Rcpp. PPforest package utilizes number R packages included “suggests” load package start-. development version ofPPforest can installed github using:","code":"library(devtools) install_github(\"natydasilva/PPforest\") library(PPforest)"},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"overview-ppforest-package","dir":"","previous_headings":"","what":"Overview PPforest package","title":"Projection Pursuit Classification Forest","text":"PPforest package implements classification random forest using projection pursuit classification trees. following table present functions PPforest package. Also PPforest package includes data set used test predictive performance method. data sets included : crab, fishcatch, glass, image, leukemia, lymphoma NCI60, parkinson wine.","code":""},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Projection Pursuit Classification Forest","text":"Australian crab data set used example. data contains measurements rock crabs genus Leptograpsus. 200 observations two species (blue orange) specie (50 one) 50 males 50 females. Class variable 4 classes combinations specie sex (BlueMale, BlueFemale, OrangeMale OrangeFemale). data collected site Fremantle, Western Australia. specimen, five measurements made, using vernier calipers. FL size frontal lobe length, mm RW rear width, mm CL length mid line carapace, mm CW maximum width carapace, mm BD depth body; females, measured displacement abdomen, mm PPforest function runs projection pursuit random forest. arguments data frame data information, class name class variable argument. size.tr specify proportion observations using training. Using function option split data training test using size.tr directly. size.tr proportion data used training test proportion 1- size.tr. number trees forest specified using argument m. argument size.p sample proportion variables used node split, PPmethod projection pursuit index optimized, two options LDA PDA available. PPforest print summary result model confusion matrix information oob-error rate similar way randomForest packages . function returns predicted values training data, training error, test error predicted test values. Also information bag error forest also tree forest. Bootstrap samples, output trees forest , proximity matrix vote matrix, number trees grown forest, number predictor variables selected use splitting node. Confusion matrix prediction (based OOb data), training data test data vote matrix also returned. printed version PPforest object follows randomForest printed version make comparable. Based confusion matrix, can observe biggest error BlueMale class. wrong classified values BlueFemale BlueMale.","code":"pprf.crab <- PPforest::PPforest(data = crab, class = \"Type\", size.tr = 1, m = 200,                                 size.p =  .5,  PPmethod = 'LDA',  parallel =TRUE, cores = 2)  pprf.crab  Call:  PPforest::PPforest(data = crab, class = \"Type\", size.tr = 1,      m = 200, PPmethod = \"LDA\", size.p = 0.5, parallel = TRUE,      cores = 2)                 Type of random forest: Classification                      Number of trees: 200 No. of variables tried at each split: 2          OOB estimate of  error rate: 5% Confusion matrix:              BlueFemale BlueMale OrangeFemale OrangeMale class.error BlueFemale           49        1            0          0        0.02 BlueMale              6       44            0          0        0.12 OrangeFemale          0        0           47          3        0.06 OrangeMale            0        0            0         50        0.00 str(pprf.crab,max.level=1 ) List of 21  $ predicting.training: Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 1 2 2 2 2 1 2 2 1 ...  $ training.error     : num 0.045  $ prediction.test    : NULL  $ error.test         : NULL  $ oob.error.forest   : num 0.05  $ oob.error.tree     : num [1:200, 1] 0.1918 0.0597 0.12 0.1519 0.303 ...  $ boot.samp          :List of 200  $ output.trees       :List of 200  $ proximity          : num [1:200, 1:200] 0 0.72 0.835 0.85 0.78 0.865 0.32 0.875 0.765 0.29 ...  $ votes              : num [1:200, 1:4] 0.375 0.605 0.372 0.417 0.253 ...  $ prediction.oob     : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 1 2 2 2 2 1 2 2 1 ...  $ n.tree             : num 200  $ n.var              : num 2  $ type               : chr \"Classification\"  $ confusion          : num [1:4, 1:5] 49 6 0 0 1 44 0 0 0 0 ...   ..- attr(*, \"dimnames\")=List of 2  $ call               : language PPforest::PPforest(data = crab, class = \"Type\", size.tr = 1, m = 200, PPmethod = \"LDA\", size.p = 0.5,      parall| __truncated__  $ train              :Classes ‘tbl_df’, ‘tbl’ and 'data.frame':    200 obs. of  6 variables:  $ test               : NULL  $ vote.mat           : num [1:200, 1:200] 1 2 4 2 1 2 1 2 4 2 ...   ..- attr(*, \"dimnames\")=List of 2  $ class.var          : chr \"Type\"  $ oob.obs            : num [1:200, 1:200] 1 0 1 0 0 1 0 1 0 0 ...  - attr(*, \"class\")= chr \"PPforest\""},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":null,"dir":"Reference","previous_headings":"","what":"NCI60 data set — NCI60","title":"NCI60 data set — NCI60","text":"cDNA microarrays used examine variation gene expression among 60 cell lines.  cell lines derived tumors different sites origin. data set contain 61 observations 30 feature variables 8 different tissue types. Type 8 different tissue types, 9 cases breast, 5 cases central nervous system (CNS), 7 cases pf colon, 8 cases leukemia, 8 cases melanoma, 9 cases  non-small-cell lung carcinoma (NSCLC), 6 cases ovarian 9 cases renal. Gene1 Gen 30 gene expression information","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NCI60 data set — NCI60","text":"","code":"data(NCI60)"},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NCI60 data set — NCI60","text":"data frame 61 rows 31 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NCI60 data set — NCI60","text":"Dudoit, S., Fridlyand, J. Speed, T. P. (2002). Comparison Discrimination Methods Classification Tumors Using Gene Expression Data. Journal American statistical Association 97 77-87.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"Predict class test set calculate prediction error finding PPtree structure, .","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"","code":"PPclassify2( Tree.result, test.data = NULL, Rule = 1, true.class = NULL)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"Tree.result result PP.Tree test.data test dataset Rule split rule 1:mean two group means, 2:weighted mean, 3: mean max(left group) min(right group), 4: weighted mean max(left group) min(right group) true.class true class test dataset available","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"predict.class predicted class predict.error prediction error","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"Lee, YD, Cook, D., Park JW, Lee, EK(2013)  PPtree: Projection pursuit classification tree,  Electronic Journal Statistics, 7:1369-1386.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"","code":"#crab data set  Tree.crab <- PPtree_split('Type~.', data = crab, PPmethod = 'LDA', size.p = 0.5) Tree.crab #> $Tree.Struct #>      id L.node.ID R.F.node.ID Coef.ID     Index #> [1,]  1         2           3       1 0.8355102 #> [2,]  2         4           5       2 0.3146831 #> [3,]  3         6           7       3 0.6983331 #> [4,]  4         0           4       0 0.0000000 #> [5,]  5         0           3       0 0.0000000 #> [6,]  6         0           2       0 0.0000000 #> [7,]  7         0           1       0 0.0000000 #>  #> $projbest.node #>            [,1]      [,2]       [,3]     [,4]       [,5] #> [1,] -0.7569527 0.0000000 -0.3091091 0.575738  0.0000000 #> [2,]  0.8821206 0.0000000 -0.2211300 0.000000 -0.4158904 #> [3,]  0.0000000 0.9202723 -0.3734248 0.000000  0.1168454 #>  #> $splitCutoff.node #>        Rule1      Rule2      Rule3      Rule4      Rule5      Rule6      Rule7 #> 1 -0.7544874 -0.7544874 -0.6154436 -0.6154436 -0.7648766 -0.7648766 -0.5880624 #> 2  1.1036784  1.1036784  1.0526596  1.0526596  1.0890368  1.0890368  1.0697875 #> 3  1.2228713  1.2228713  1.3260548  1.3260548  1.2439543  1.2439543  1.3654261 #>        Rule8 #> 1 -0.5880624 #> 2  1.0697875 #> 3  1.3654261 #>  #> $origclass #>   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 #> [112] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 #> [149] 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [186] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  #> $origdata #>          FL   RW   CL   CW   BD #>   [1,]  8.1  6.7 16.1 19.0  7.0 #>   [2,]  8.8  7.7 18.1 20.8  7.4 #>   [3,]  9.2  7.8 19.0 22.4  7.7 #>   [4,]  9.6  7.9 20.1 23.1  8.2 #>   [5,]  9.8  8.0 20.3 23.0  8.2 #>   [6,] 10.8  9.0 23.0 26.5  9.8 #>   [7,] 11.1  9.9 23.8 27.1  9.8 #>   [8,] 11.6  9.1 24.5 28.4 10.4 #>   [9,] 11.8  9.6 24.2 27.8  9.7 #>  [10,] 11.8 10.5 25.2 29.3 10.3 #>  [11,] 12.2 10.8 27.3 31.6 10.9 #>  [12,] 12.3 11.0 26.8 31.5 11.4 #>  [13,] 12.6 10.0 27.7 31.7 11.4 #>  [14,] 12.8 10.2 27.2 31.8 10.9 #>  [15,] 12.8 10.9 27.4 31.5 11.0 #>  [16,] 12.9 11.0 26.8 30.9 11.4 #>  [17,] 13.1 10.6 28.2 32.3 11.0 #>  [18,] 13.1 10.9 28.3 32.4 11.2 #>  [19,] 13.3 11.1 27.8 32.3 11.3 #>  [20,] 13.9 11.1 29.2 33.3 12.1 #>  [21,] 14.3 11.6 31.3 35.5 12.7 #>  [22,] 14.6 11.3 31.9 36.4 13.7 #>  [23,] 15.0 10.9 31.4 36.4 13.2 #>  [24,] 15.0 11.5 32.4 37.0 13.4 #>  [25,] 15.0 11.9 32.5 37.2 13.6 #>  [26,] 15.2 12.1 32.3 36.7 13.6 #>  [27,] 15.4 11.8 33.0 37.5 13.6 #>  [28,] 15.7 12.6 35.8 40.3 14.5 #>  [29,] 15.9 12.7 34.0 38.9 14.2 #>  [30,] 16.1 11.6 33.8 39.0 14.4 #>  [31,] 16.1 12.8 34.9 40.7 15.7 #>  [32,] 16.2 13.3 36.0 41.7 15.4 #>  [33,] 16.3 12.7 35.6 40.9 14.9 #>  [34,] 16.4 13.0 35.7 41.8 15.2 #>  [35,] 16.6 13.5 38.1 43.4 14.9 #>  [36,] 16.8 12.8 36.2 41.8 14.9 #>  [37,] 16.9 13.2 37.3 42.7 15.6 #>  [38,] 17.1 12.6 36.4 42.0 15.1 #>  [39,] 17.1 12.7 36.7 41.9 15.6 #>  [40,] 17.2 13.5 37.6 43.9 16.1 #>  [41,] 17.7 13.6 38.7 44.5 16.0 #>  [42,] 17.9 14.1 39.7 44.6 16.8 #>  [43,] 18.0 13.7 39.2 44.4 16.2 #>  [44,] 18.8 15.8 42.1 49.0 17.8 #>  [45,] 19.3 13.5 41.6 47.4 17.8 #>  [46,] 19.3 13.8 40.9 46.5 16.8 #>  [47,] 19.7 15.3 41.9 48.5 17.8 #>  [48,] 19.8 14.2 43.2 49.7 18.6 #>  [49,] 19.8 14.3 42.4 48.9 18.3 #>  [50,] 21.3 15.7 47.1 54.6 20.0 #>  [51,]  7.2  6.5 14.7 17.1  6.1 #>  [52,]  9.0  8.5 19.3 22.7  7.7 #>  [53,]  9.1  8.1 18.5 21.6  7.7 #>  [54,]  9.1  8.2 19.2 22.2  7.7 #>  [55,]  9.5  8.2 19.6 22.4  7.8 #>  [56,]  9.8  8.9 20.4 23.9  8.8 #>  [57,] 10.1  9.3 20.9 24.4  8.4 #>  [58,] 10.3  9.5 21.3 24.7  8.9 #>  [59,] 10.4  9.7 21.7 25.4  8.3 #>  [60,] 10.8  9.5 22.5 26.3  9.1 #>  [61,] 11.0  9.8 22.5 25.7  8.2 #>  [62,] 11.2 10.0 22.8 26.9  9.4 #>  [63,] 11.5 11.0 24.7 29.2 10.1 #>  [64,] 11.6 11.0 24.6 28.5 10.4 #>  [65,] 11.6 11.4 23.7 27.7 10.0 #>  [66,] 11.7 10.6 24.9 28.5 10.4 #>  [67,] 11.9 11.4 26.0 30.1 10.9 #>  [68,] 12.0 10.7 24.6 28.9 10.5 #>  [69,] 12.0 11.1 25.4 29.2 11.0 #>  [70,] 12.6 12.2 26.1 31.6 11.2 #>  [71,] 12.8 11.7 27.1 31.2 11.9 #>  [72,] 12.8 12.2 26.7 31.1 11.1 #>  [73,] 12.8 12.2 27.9 31.9 11.5 #>  [74,] 13.0 11.4 27.3 31.8 11.3 #>  [75,] 13.1 11.5 27.6 32.6 11.1 #>  [76,] 13.2 12.2 27.9 32.1 11.5 #>  [77,] 13.4 11.8 28.4 32.7 11.7 #>  [78,] 13.7 12.5 28.6 33.8 11.9 #>  [79,] 13.9 13.0 30.0 34.9 13.1 #>  [80,] 14.7 12.5 30.1 34.7 12.5 #>  [81,] 14.9 13.2 30.1 35.6 12.0 #>  [82,] 15.0 13.8 31.7 36.9 14.0 #>  [83,] 15.0 14.2 32.8 37.4 14.0 #>  [84,] 15.1 13.3 31.8 36.3 13.5 #>  [85,] 15.1 13.5 31.9 37.0 13.8 #>  [86,] 15.1 13.8 31.7 36.6 13.0 #>  [87,] 15.2 14.3 33.9 38.5 14.7 #>  [88,] 15.3 14.2 32.6 38.3 13.8 #>  [89,] 15.4 13.3 32.4 37.6 13.8 #>  [90,] 15.5 13.8 33.4 38.7 14.7 #>  [91,] 15.6 13.9 32.8 37.9 13.4 #>  [92,] 15.6 14.7 33.9 39.5 14.3 #>  [93,] 15.7 13.9 33.6 38.5 14.1 #>  [94,] 15.8 15.0 34.5 40.3 15.3 #>  [95,] 16.2 15.2 34.5 40.1 13.9 #>  [96,] 16.4 14.0 34.2 39.8 15.2 #>  [97,] 16.7 16.1 36.6 41.9 15.4 #>  [98,] 17.4 16.9 38.2 44.1 16.6 #>  [99,] 17.5 16.7 38.6 44.5 17.0 #> [100,] 19.2 16.5 40.9 47.9 18.1 #> [101,]  9.1  6.9 16.7 18.6  7.4 #> [102,] 10.2  8.2 20.2 22.2  9.0 #> [103,] 10.7  8.6 20.7 22.7  9.2 #> [104,] 11.4  9.0 22.7 24.8 10.1 #> [105,] 12.5  9.4 23.2 26.0 10.8 #> [106,] 12.5  9.4 24.2 27.0 11.2 #> [107,] 12.7 10.4 26.0 28.8 12.1 #> [108,] 13.2 11.0 27.1 30.4 12.2 #> [109,] 13.4 10.1 26.6 29.6 12.0 #> [110,] 13.7 11.0 27.5 30.5 12.2 #> [111,] 14.0 11.5 29.2 32.2 13.1 #> [112,] 14.1 10.4 28.9 31.8 13.5 #> [113,] 14.1 10.5 29.1 31.6 13.1 #> [114,] 14.1 10.7 28.7 31.9 13.3 #> [115,] 14.2 10.6 28.7 31.7 12.9 #> [116,] 14.2 10.7 27.8 30.9 12.7 #> [117,] 14.2 11.3 29.2 32.2 13.5 #> [118,] 14.6 11.3 29.9 33.5 12.8 #> [119,] 14.7 11.1 29.0 32.1 13.1 #> [120,] 15.1 11.4 30.2 33.3 14.0 #> [121,] 15.1 11.5 30.9 34.0 13.9 #> [122,] 15.4 11.1 30.2 33.6 13.5 #> [123,] 15.7 12.2 31.7 34.2 14.2 #> [124,] 16.2 11.8 32.3 35.3 14.7 #> [125,] 16.3 11.6 31.6 34.2 14.5 #> [126,] 17.1 12.6 35.0 38.9 15.7 #> [127,] 17.4 12.8 36.1 39.5 16.2 #> [128,] 17.5 12.0 34.4 37.3 15.3 #> [129,] 17.5 12.7 34.6 38.4 16.1 #> [130,] 17.8 12.5 36.0 39.8 16.7 #> [131,] 17.9 12.9 36.9 40.9 16.5 #> [132,] 18.0 13.4 36.7 41.3 17.1 #> [133,] 18.2 13.7 38.8 42.7 17.2 #> [134,] 18.4 13.4 37.9 42.2 17.7 #> [135,] 18.6 13.4 37.8 41.9 17.3 #> [136,] 18.6 13.5 36.9 40.2 17.0 #> [137,] 18.8 13.4 37.2 41.1 17.5 #> [138,] 18.8 13.8 39.2 43.3 17.9 #> [139,] 19.4 14.1 39.1 43.2 17.8 #> [140,] 19.4 14.4 39.8 44.3 17.9 #> [141,] 20.1 13.7 40.6 44.5 18.0 #> [142,] 20.6 14.4 42.8 46.5 19.6 #> [143,] 21.0 15.0 42.9 47.2 19.4 #> [144,] 21.5 15.5 45.5 49.7 20.9 #> [145,] 21.6 15.4 45.7 49.7 20.6 #> [146,] 21.6 14.8 43.4 48.2 20.1 #> [147,] 21.9 15.7 45.4 51.0 21.1 #> [148,] 22.1 15.8 44.6 49.6 20.5 #> [149,] 23.0 16.8 47.2 52.1 21.5 #> [150,] 23.1 15.7 47.6 52.8 21.6 #> [151,] 10.7  9.7 21.4 24.0  9.8 #> [152,] 11.4  9.2 21.7 24.1  9.7 #> [153,] 12.5 10.0 24.1 27.0 10.9 #> [154,] 12.6 11.5 25.0 28.1 11.5 #> [155,] 12.9 11.2 25.8 29.1 11.9 #> [156,] 14.0 11.9 27.0 31.4 12.6 #> [157,] 14.0 12.8 28.8 32.4 12.7 #> [158,] 14.3 12.2 28.1 31.8 12.5 #> [159,] 14.7 13.2 29.6 33.4 12.9 #> [160,] 14.9 13.0 30.0 33.7 13.3 #> [161,] 15.0 12.3 30.1 33.3 14.0 #> [162,] 15.6 13.5 31.2 35.1 14.1 #> [163,] 15.6 14.0 31.6 35.3 13.8 #> [164,] 15.6 14.1 31.0 34.5 13.8 #> [165,] 15.7 13.6 31.0 34.8 13.8 #> [166,] 16.1 13.6 31.6 36.0 14.0 #> [167,] 16.1 13.7 31.4 36.1 13.9 #> [168,] 16.2 14.0 31.6 35.6 13.7 #> [169,] 16.7 14.3 32.3 37.0 14.7 #> [170,] 17.1 14.5 33.1 37.2 14.6 #> [171,] 17.5 14.3 34.5 39.6 15.6 #> [172,] 17.5 14.4 34.5 39.0 16.0 #> [173,] 17.5 14.7 33.3 37.6 14.6 #> [174,] 17.6 14.0 34.0 38.6 15.5 #> [175,] 18.0 14.9 34.7 39.5 15.7 #> [176,] 18.0 16.3 37.9 43.0 17.2 #> [177,] 18.3 15.7 35.1 40.5 16.1 #> [178,] 18.4 15.5 35.6 40.0 15.9 #> [179,] 18.4 15.7 36.5 41.6 16.4 #> [180,] 18.5 14.6 37.0 42.0 16.6 #> [181,] 18.6 14.5 34.7 39.4 15.0 #> [182,] 18.8 15.2 35.8 40.5 16.6 #> [183,] 18.9 16.7 36.3 41.7 15.3 #> [184,] 19.1 16.0 37.8 42.3 16.8 #> [185,] 19.1 16.3 37.9 42.6 17.2 #> [186,] 19.7 16.7 39.9 43.6 18.2 #> [187,] 19.9 16.6 39.4 43.9 17.9 #> [188,] 19.9 17.9 40.1 46.4 17.9 #> [189,] 20.0 16.7 40.4 45.1 17.7 #> [190,] 20.1 17.2 39.8 44.1 18.6 #> [191,] 20.3 16.0 39.4 44.1 18.0 #> [192,] 20.5 17.5 40.0 45.5 19.2 #> [193,] 20.6 17.5 41.5 46.2 19.2 #> [194,] 20.9 16.5 39.9 44.7 17.5 #> [195,] 21.3 18.4 43.8 48.4 20.0 #> [196,] 21.4 18.0 41.2 46.2 18.7 #> [197,] 21.7 17.1 41.7 47.2 19.6 #> [198,] 21.9 17.2 42.6 47.4 19.5 #> [199,] 22.5 17.2 43.0 48.7 19.8 #> [200,] 23.1 20.2 46.2 52.5 21.1 #>  #> attr(,\"class\") #> [1] \"list\"        \"PPtreeclass\"  PPclassify2(Tree.crab) #> $predict.error #> [1] NA #>  #> $predict.class #>        [,1] #>   [1,]    2 #>   [2,]    2 #>   [3,]    2 #>   [4,]    2 #>   [5,]    2 #>   [6,]    2 #>   [7,]    1 #>   [8,]    2 #>   [9,]    2 #>  [10,]    1 #>  [11,]    2 #>  [12,]    1 #>  [13,]    2 #>  [14,]    2 #>  [15,]    2 #>  [16,]    1 #>  [17,]    2 #>  [18,]    2 #>  [19,]    2 #>  [20,]    2 #>  [21,]    2 #>  [22,]    2 #>  [23,]    2 #>  [24,]    2 #>  [25,]    2 #>  [26,]    2 #>  [27,]    2 #>  [28,]    2 #>  [29,]    2 #>  [30,]    2 #>  [31,]    2 #>  [32,]    2 #>  [33,]    2 #>  [34,]    2 #>  [35,]    2 #>  [36,]    2 #>  [37,]    2 #>  [38,]    2 #>  [39,]    2 #>  [40,]    2 #>  [41,]    2 #>  [42,]    2 #>  [43,]    2 #>  [44,]    2 #>  [45,]    2 #>  [46,]    2 #>  [47,]    2 #>  [48,]    2 #>  [49,]    2 #>  [50,]    2 #>  [51,]    2 #>  [52,]    1 #>  [53,]    1 #>  [54,]    1 #>  [55,]    2 #>  [56,]    1 #>  [57,]    1 #>  [58,]    1 #>  [59,]    1 #>  [60,]    1 #>  [61,]    1 #>  [62,]    1 #>  [63,]    1 #>  [64,]    1 #>  [65,]    1 #>  [66,]    1 #>  [67,]    1 #>  [68,]    1 #>  [69,]    1 #>  [70,]    1 #>  [71,]    1 #>  [72,]    1 #>  [73,]    1 #>  [74,]    1 #>  [75,]    1 #>  [76,]    1 #>  [77,]    1 #>  [78,]    1 #>  [79,]    1 #>  [80,]    1 #>  [81,]    1 #>  [82,]    1 #>  [83,]    1 #>  [84,]    1 #>  [85,]    1 #>  [86,]    1 #>  [87,]    1 #>  [88,]    1 #>  [89,]    1 #>  [90,]    1 #>  [91,]    1 #>  [92,]    1 #>  [93,]    1 #>  [94,]    1 #>  [95,]    1 #>  [96,]    1 #>  [97,]    1 #>  [98,]    1 #>  [99,]    1 #> [100,]    1 #> [101,]    3 #> [102,]    4 #> [103,]    4 #> [104,]    4 #> [105,]    3 #> [106,]    4 #> [107,]    4 #> [108,]    4 #> [109,]    4 #> [110,]    4 #> [111,]    4 #> [112,]    4 #> [113,]    4 #> [114,]    4 #> [115,]    4 #> [116,]    4 #> [117,]    4 #> [118,]    4 #> [119,]    3 #> [120,]    4 #> [121,]    4 #> [122,]    3 #> [123,]    4 #> [124,]    4 #> [125,]    3 #> [126,]    4 #> [127,]    4 #> [128,]    3 #> [129,]    4 #> [130,]    4 #> [131,]    4 #> [132,]    4 #> [133,]    4 #> [134,]    4 #> [135,]    4 #> [136,]    3 #> [137,]    4 #> [138,]    4 #> [139,]    4 #> [140,]    4 #> [141,]    3 #> [142,]    4 #> [143,]    4 #> [144,]    4 #> [145,]    4 #> [146,]    4 #> [147,]    4 #> [148,]    3 #> [149,]    4 #> [150,]    4 #> [151,]    4 #> [152,]    3 #> [153,]    3 #> [154,]    4 #> [155,]    4 #> [156,]    3 #> [157,]    4 #> [158,]    3 #> [159,]    4 #> [160,]    4 #> [161,]    4 #> [162,]    4 #> [163,]    4 #> [164,]    3 #> [165,]    3 #> [166,]    3 #> [167,]    3 #> [168,]    3 #> [169,]    3 #> [170,]    3 #> [171,]    3 #> [172,]    3 #> [173,]    3 #> [174,]    3 #> [175,]    3 #> [176,]    1 #> [177,]    3 #> [178,]    3 #> [179,]    3 #> [180,]    3 #> [181,]    3 #> [182,]    3 #> [183,]    3 #> [184,]    3 #> [185,]    3 #> [186,]    4 #> [187,]    3 #> [188,]    1 #> [189,]    3 #> [190,]    3 #> [191,]    3 #> [192,]    3 #> [193,]    4 #> [194,]    3 #> [195,]    4 #> [196,]    3 #> [197,]    3 #> [198,]    3 #> [199,]    3 #> [200,]    3 #>"},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":null,"dir":"Reference","previous_headings":"","what":"Projection Pursuit Random Forest — PPforest","title":"Projection Pursuit Random Forest — PPforest","text":"PPforest implements random forest using projection pursuit trees algorithm (based PPtreeViz package).","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Projection Pursuit Random Forest — PPforest","text":"","code":"PPforest(data, class, std = TRUE, size.tr, m, PPmethod, size.p,  lambda = .1, parallel = FALSE, cores = 2, rule = 1)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Projection Pursuit Random Forest — PPforest","text":"data Data frame complete data set. class character name class variable. std TRUE standardize data set, needed compute global importance measure. size.tr size proportion training want split data training test. m number bootstrap replicates, corresponds number trees grow. ensure observation predicted times select number small. m = 500 default. PPmethod projection pursuit index optimize classification tree. options LDA PDA, linear discriminant penalized linear discriminant. default LDA. size.p proportion variables randomly sampled split. lambda penalty parameter PDA index 0 1 . lambda = 0, penalty parameter added PDA index LDA index. lambda = 1 variables treated uncorrelated. default value lambda = 0.1. parallel logical condition, TRUE  parallelize function cores number cores used parallelization rule split rule 1: mean two group means 2: weighted mean two group means - weight group size 3: weighted mean two group means - weight group sd 4: weighted mean two group means - weight group se 5: mean two group medians 6: weighted mean two group medians - weight group size 7: weighted mean two group median - weight group IQR 8: weighted mean two group median - weight group IQR size","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Projection Pursuit Random Forest — PPforest","text":"object class PPforest components. prediction.training predicted values training data set. training.error error training data set. prediction.test predicted values test data set testap = TRUE(default). error.test error test data set testap = TRUE(default). oob.error.forest bag error forest. oob.error.tree bag error tree forest. boot.samp information bootrap samples. output.trees output trees_pp bootrap sample. proximity Proximity matrix, two cases classified terminal node proximity matrix increased one PPforest one terminal node per class. votes matrix one row input data point one column class, giving fraction (OOB) votes PPforest. n.tree number trees grown PPforest. n.var number predictor variables selected use spliting node. type classification. confusion confusion matrix prediction (based OOB data). call original call PPforest. train training data based size.tr sample proportion test test data based 1-size.tr sample proportion","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Projection Pursuit Random Forest — PPforest","text":"Natalia da Silva, Dianne Cook & Eun-Kyung Lee (2021)  Projection Pursuit Forest Algorithm Supervised Classification,  Journal Computational Graphical Statistics, DOI: 10.1080/10618600.2020.1870480","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Projection Pursuit Random Forest — PPforest","text":"","code":"#crab example with all the observations used as training  pprf.crab <- PPforest(data = crab, class = 'Type',  std = FALSE, size.tr = 1, m = 200, size.p = .5,   PPmethod = 'LDA' , parallel = TRUE, cores = 2, rule=1) pprf.crab #>  #> Call: #>  PPforest(data = crab, class = \"Type\", std = FALSE, size.tr = 1,      m = 200, PPmethod = \"LDA\", size.p = 0.5, parallel = TRUE,      cores = 2, rule = 1)  #>                Type of random forest: Classification #>                      Number of trees: 200 #> No. of variables tried at each split: 2 #>  #>         OOB estimate of  error rate: 6.5% #> Confusion matrix: #>              BlueFemale BlueMale OrangeFemale OrangeMale class.error #> BlueFemale           48        2            0          0        0.04 #> BlueMale              6       44            0          0        0.12 #> OrangeFemale          0        0           46          4        0.08 #> OrangeMale            0        1            0         49        0.02"},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"Find tree structure using various projection pursuit indices classification split.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"","code":"PPtree_split(form, data, PPmethod='LDA',  size.p=1,  lambda = 0.1,...)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"form character name class variable. data Data frame complete data set. PPmethod index use projection pursuit: 'LDA', 'PDA' size.p proportion variables randomly sampled split, default 1, returns PPtree. lambda penalty parameter PDA index 0 1 . lambda = 0, penalty parameter added PDA index LDA index. lambda = 1 variables treated uncorrelated. default value lambda = 0.1. ... arguments passed methods","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"object class PPtreeclass components Tree.Struct Tree structure projection pursuit classification tree projbest.node 1-dim optimal projections split node splitCutoff.node cutoff values split node origclass original class origdata original data","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"Lee, YD, Cook, D., Park JW, Lee, EK (2013)  PPtree: Projection pursuit classification tree,  Electronic Journal Statistics, 7:1369-1386.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"","code":"#crab data set  Tree.crab <- PPtree_split('Type~.', data = crab, PPmethod = 'LDA', size.p = 0.5) Tree.crab #> $Tree.Struct #>      id L.node.ID R.F.node.ID Coef.ID     Index #> [1,]  1         2           3       1 0.6685796 #> [2,]  2         4           5       2 0.5969233 #> [3,]  3         6           7       3 0.4159129 #> [4,]  4         0           1       0 0.0000000 #> [5,]  5         0           3       0 0.0000000 #> [6,]  6         0           4       0 0.0000000 #> [7,]  7         0           2       0 0.0000000 #>  #> $projbest.node #>            [,1]       [,2]       [,3] [,4]       [,5] #> [1,] 0.09731385 -0.8568609  0.0000000    0  0.5062800 #> [2,] 0.00000000  0.1873549 -0.4504176    0  0.8729388 #> [3,] 0.10154143  0.7742781  0.0000000    0 -0.6246461 #>  #> $splitCutoff.node #>        Rule1      Rule2      Rule3      Rule4      Rule5      Rule6      Rule7 #> 1 -2.2953203 -2.2953203 -2.2784329 -2.2784329 -2.2907909 -2.2907909 -2.3239110 #> 2  0.3819728  0.3819728  0.3807714  0.3807714  0.3854046  0.3854046  0.3923312 #> 3  1.9256963  1.9256963  1.8847336  1.8847336  1.9301351  1.9301351  1.8508816 #>        Rule8 #> 1 -2.3239110 #> 2  0.3923312 #> 3  1.8508816 #>  #> $origclass #>   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 #> [112] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 #> [149] 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [186] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  #> $origdata #>          FL   RW   CL   CW   BD #>   [1,]  8.1  6.7 16.1 19.0  7.0 #>   [2,]  8.8  7.7 18.1 20.8  7.4 #>   [3,]  9.2  7.8 19.0 22.4  7.7 #>   [4,]  9.6  7.9 20.1 23.1  8.2 #>   [5,]  9.8  8.0 20.3 23.0  8.2 #>   [6,] 10.8  9.0 23.0 26.5  9.8 #>   [7,] 11.1  9.9 23.8 27.1  9.8 #>   [8,] 11.6  9.1 24.5 28.4 10.4 #>   [9,] 11.8  9.6 24.2 27.8  9.7 #>  [10,] 11.8 10.5 25.2 29.3 10.3 #>  [11,] 12.2 10.8 27.3 31.6 10.9 #>  [12,] 12.3 11.0 26.8 31.5 11.4 #>  [13,] 12.6 10.0 27.7 31.7 11.4 #>  [14,] 12.8 10.2 27.2 31.8 10.9 #>  [15,] 12.8 10.9 27.4 31.5 11.0 #>  [16,] 12.9 11.0 26.8 30.9 11.4 #>  [17,] 13.1 10.6 28.2 32.3 11.0 #>  [18,] 13.1 10.9 28.3 32.4 11.2 #>  [19,] 13.3 11.1 27.8 32.3 11.3 #>  [20,] 13.9 11.1 29.2 33.3 12.1 #>  [21,] 14.3 11.6 31.3 35.5 12.7 #>  [22,] 14.6 11.3 31.9 36.4 13.7 #>  [23,] 15.0 10.9 31.4 36.4 13.2 #>  [24,] 15.0 11.5 32.4 37.0 13.4 #>  [25,] 15.0 11.9 32.5 37.2 13.6 #>  [26,] 15.2 12.1 32.3 36.7 13.6 #>  [27,] 15.4 11.8 33.0 37.5 13.6 #>  [28,] 15.7 12.6 35.8 40.3 14.5 #>  [29,] 15.9 12.7 34.0 38.9 14.2 #>  [30,] 16.1 11.6 33.8 39.0 14.4 #>  [31,] 16.1 12.8 34.9 40.7 15.7 #>  [32,] 16.2 13.3 36.0 41.7 15.4 #>  [33,] 16.3 12.7 35.6 40.9 14.9 #>  [34,] 16.4 13.0 35.7 41.8 15.2 #>  [35,] 16.6 13.5 38.1 43.4 14.9 #>  [36,] 16.8 12.8 36.2 41.8 14.9 #>  [37,] 16.9 13.2 37.3 42.7 15.6 #>  [38,] 17.1 12.6 36.4 42.0 15.1 #>  [39,] 17.1 12.7 36.7 41.9 15.6 #>  [40,] 17.2 13.5 37.6 43.9 16.1 #>  [41,] 17.7 13.6 38.7 44.5 16.0 #>  [42,] 17.9 14.1 39.7 44.6 16.8 #>  [43,] 18.0 13.7 39.2 44.4 16.2 #>  [44,] 18.8 15.8 42.1 49.0 17.8 #>  [45,] 19.3 13.5 41.6 47.4 17.8 #>  [46,] 19.3 13.8 40.9 46.5 16.8 #>  [47,] 19.7 15.3 41.9 48.5 17.8 #>  [48,] 19.8 14.2 43.2 49.7 18.6 #>  [49,] 19.8 14.3 42.4 48.9 18.3 #>  [50,] 21.3 15.7 47.1 54.6 20.0 #>  [51,]  7.2  6.5 14.7 17.1  6.1 #>  [52,]  9.0  8.5 19.3 22.7  7.7 #>  [53,]  9.1  8.1 18.5 21.6  7.7 #>  [54,]  9.1  8.2 19.2 22.2  7.7 #>  [55,]  9.5  8.2 19.6 22.4  7.8 #>  [56,]  9.8  8.9 20.4 23.9  8.8 #>  [57,] 10.1  9.3 20.9 24.4  8.4 #>  [58,] 10.3  9.5 21.3 24.7  8.9 #>  [59,] 10.4  9.7 21.7 25.4  8.3 #>  [60,] 10.8  9.5 22.5 26.3  9.1 #>  [61,] 11.0  9.8 22.5 25.7  8.2 #>  [62,] 11.2 10.0 22.8 26.9  9.4 #>  [63,] 11.5 11.0 24.7 29.2 10.1 #>  [64,] 11.6 11.0 24.6 28.5 10.4 #>  [65,] 11.6 11.4 23.7 27.7 10.0 #>  [66,] 11.7 10.6 24.9 28.5 10.4 #>  [67,] 11.9 11.4 26.0 30.1 10.9 #>  [68,] 12.0 10.7 24.6 28.9 10.5 #>  [69,] 12.0 11.1 25.4 29.2 11.0 #>  [70,] 12.6 12.2 26.1 31.6 11.2 #>  [71,] 12.8 11.7 27.1 31.2 11.9 #>  [72,] 12.8 12.2 26.7 31.1 11.1 #>  [73,] 12.8 12.2 27.9 31.9 11.5 #>  [74,] 13.0 11.4 27.3 31.8 11.3 #>  [75,] 13.1 11.5 27.6 32.6 11.1 #>  [76,] 13.2 12.2 27.9 32.1 11.5 #>  [77,] 13.4 11.8 28.4 32.7 11.7 #>  [78,] 13.7 12.5 28.6 33.8 11.9 #>  [79,] 13.9 13.0 30.0 34.9 13.1 #>  [80,] 14.7 12.5 30.1 34.7 12.5 #>  [81,] 14.9 13.2 30.1 35.6 12.0 #>  [82,] 15.0 13.8 31.7 36.9 14.0 #>  [83,] 15.0 14.2 32.8 37.4 14.0 #>  [84,] 15.1 13.3 31.8 36.3 13.5 #>  [85,] 15.1 13.5 31.9 37.0 13.8 #>  [86,] 15.1 13.8 31.7 36.6 13.0 #>  [87,] 15.2 14.3 33.9 38.5 14.7 #>  [88,] 15.3 14.2 32.6 38.3 13.8 #>  [89,] 15.4 13.3 32.4 37.6 13.8 #>  [90,] 15.5 13.8 33.4 38.7 14.7 #>  [91,] 15.6 13.9 32.8 37.9 13.4 #>  [92,] 15.6 14.7 33.9 39.5 14.3 #>  [93,] 15.7 13.9 33.6 38.5 14.1 #>  [94,] 15.8 15.0 34.5 40.3 15.3 #>  [95,] 16.2 15.2 34.5 40.1 13.9 #>  [96,] 16.4 14.0 34.2 39.8 15.2 #>  [97,] 16.7 16.1 36.6 41.9 15.4 #>  [98,] 17.4 16.9 38.2 44.1 16.6 #>  [99,] 17.5 16.7 38.6 44.5 17.0 #> [100,] 19.2 16.5 40.9 47.9 18.1 #> [101,]  9.1  6.9 16.7 18.6  7.4 #> [102,] 10.2  8.2 20.2 22.2  9.0 #> [103,] 10.7  8.6 20.7 22.7  9.2 #> [104,] 11.4  9.0 22.7 24.8 10.1 #> [105,] 12.5  9.4 23.2 26.0 10.8 #> [106,] 12.5  9.4 24.2 27.0 11.2 #> [107,] 12.7 10.4 26.0 28.8 12.1 #> [108,] 13.2 11.0 27.1 30.4 12.2 #> [109,] 13.4 10.1 26.6 29.6 12.0 #> [110,] 13.7 11.0 27.5 30.5 12.2 #> [111,] 14.0 11.5 29.2 32.2 13.1 #> [112,] 14.1 10.4 28.9 31.8 13.5 #> [113,] 14.1 10.5 29.1 31.6 13.1 #> [114,] 14.1 10.7 28.7 31.9 13.3 #> [115,] 14.2 10.6 28.7 31.7 12.9 #> [116,] 14.2 10.7 27.8 30.9 12.7 #> [117,] 14.2 11.3 29.2 32.2 13.5 #> [118,] 14.6 11.3 29.9 33.5 12.8 #> [119,] 14.7 11.1 29.0 32.1 13.1 #> [120,] 15.1 11.4 30.2 33.3 14.0 #> [121,] 15.1 11.5 30.9 34.0 13.9 #> [122,] 15.4 11.1 30.2 33.6 13.5 #> [123,] 15.7 12.2 31.7 34.2 14.2 #> [124,] 16.2 11.8 32.3 35.3 14.7 #> [125,] 16.3 11.6 31.6 34.2 14.5 #> [126,] 17.1 12.6 35.0 38.9 15.7 #> [127,] 17.4 12.8 36.1 39.5 16.2 #> [128,] 17.5 12.0 34.4 37.3 15.3 #> [129,] 17.5 12.7 34.6 38.4 16.1 #> [130,] 17.8 12.5 36.0 39.8 16.7 #> [131,] 17.9 12.9 36.9 40.9 16.5 #> [132,] 18.0 13.4 36.7 41.3 17.1 #> [133,] 18.2 13.7 38.8 42.7 17.2 #> [134,] 18.4 13.4 37.9 42.2 17.7 #> [135,] 18.6 13.4 37.8 41.9 17.3 #> [136,] 18.6 13.5 36.9 40.2 17.0 #> [137,] 18.8 13.4 37.2 41.1 17.5 #> [138,] 18.8 13.8 39.2 43.3 17.9 #> [139,] 19.4 14.1 39.1 43.2 17.8 #> [140,] 19.4 14.4 39.8 44.3 17.9 #> [141,] 20.1 13.7 40.6 44.5 18.0 #> [142,] 20.6 14.4 42.8 46.5 19.6 #> [143,] 21.0 15.0 42.9 47.2 19.4 #> [144,] 21.5 15.5 45.5 49.7 20.9 #> [145,] 21.6 15.4 45.7 49.7 20.6 #> [146,] 21.6 14.8 43.4 48.2 20.1 #> [147,] 21.9 15.7 45.4 51.0 21.1 #> [148,] 22.1 15.8 44.6 49.6 20.5 #> [149,] 23.0 16.8 47.2 52.1 21.5 #> [150,] 23.1 15.7 47.6 52.8 21.6 #> [151,] 10.7  9.7 21.4 24.0  9.8 #> [152,] 11.4  9.2 21.7 24.1  9.7 #> [153,] 12.5 10.0 24.1 27.0 10.9 #> [154,] 12.6 11.5 25.0 28.1 11.5 #> [155,] 12.9 11.2 25.8 29.1 11.9 #> [156,] 14.0 11.9 27.0 31.4 12.6 #> [157,] 14.0 12.8 28.8 32.4 12.7 #> [158,] 14.3 12.2 28.1 31.8 12.5 #> [159,] 14.7 13.2 29.6 33.4 12.9 #> [160,] 14.9 13.0 30.0 33.7 13.3 #> [161,] 15.0 12.3 30.1 33.3 14.0 #> [162,] 15.6 13.5 31.2 35.1 14.1 #> [163,] 15.6 14.0 31.6 35.3 13.8 #> [164,] 15.6 14.1 31.0 34.5 13.8 #> [165,] 15.7 13.6 31.0 34.8 13.8 #> [166,] 16.1 13.6 31.6 36.0 14.0 #> [167,] 16.1 13.7 31.4 36.1 13.9 #> [168,] 16.2 14.0 31.6 35.6 13.7 #> [169,] 16.7 14.3 32.3 37.0 14.7 #> [170,] 17.1 14.5 33.1 37.2 14.6 #> [171,] 17.5 14.3 34.5 39.6 15.6 #> [172,] 17.5 14.4 34.5 39.0 16.0 #> [173,] 17.5 14.7 33.3 37.6 14.6 #> [174,] 17.6 14.0 34.0 38.6 15.5 #> [175,] 18.0 14.9 34.7 39.5 15.7 #> [176,] 18.0 16.3 37.9 43.0 17.2 #> [177,] 18.3 15.7 35.1 40.5 16.1 #> [178,] 18.4 15.5 35.6 40.0 15.9 #> [179,] 18.4 15.7 36.5 41.6 16.4 #> [180,] 18.5 14.6 37.0 42.0 16.6 #> [181,] 18.6 14.5 34.7 39.4 15.0 #> [182,] 18.8 15.2 35.8 40.5 16.6 #> [183,] 18.9 16.7 36.3 41.7 15.3 #> [184,] 19.1 16.0 37.8 42.3 16.8 #> [185,] 19.1 16.3 37.9 42.6 17.2 #> [186,] 19.7 16.7 39.9 43.6 18.2 #> [187,] 19.9 16.6 39.4 43.9 17.9 #> [188,] 19.9 17.9 40.1 46.4 17.9 #> [189,] 20.0 16.7 40.4 45.1 17.7 #> [190,] 20.1 17.2 39.8 44.1 18.6 #> [191,] 20.3 16.0 39.4 44.1 18.0 #> [192,] 20.5 17.5 40.0 45.5 19.2 #> [193,] 20.6 17.5 41.5 46.2 19.2 #> [194,] 20.9 16.5 39.9 44.7 17.5 #> [195,] 21.3 18.4 43.8 48.4 20.0 #> [196,] 21.4 18.0 41.2 46.2 18.7 #> [197,] 21.7 17.1 41.7 47.2 19.6 #> [198,] 21.9 17.2 42.6 47.4 19.5 #> [199,] 22.5 17.2 43.0 48.7 19.8 #> [200,] 23.1 20.2 46.2 52.5 21.1 #>  #> attr(,\"class\") #> [1] \"list\"        \"PPtreeclass\""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":null,"dir":"Reference","previous_headings":"","what":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"bootstrap sample grow projection pursuit tree (PPtree object).","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"","code":"baggtree(   data,   class,   m = 500,   PPmethod = \"LDA\",   lambda = 0.1,   size.p = 1,   parallel = FALSE,   cores = 2 )"},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"data Data frame complete data set. class character name class variable. m number bootstrap replicates, corresponds number trees grow. ensure observation predicted times select number small. m = 500 default. PPmethod projection pursuit index optimized, options LDA PDA, default LDA. lambda parameter PDA index size.p proportion random sample variables split. parallel logical condition, TRUE  parallelize function cores number cores used parallelization","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"data frame trees_pp output bootstraps samples.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"","code":"#crab data set crab.trees <- baggtree(data = crab, class = 'Type', m =  200, PPmethod = 'LDA', lambda = .1, size.p = 0.5 , parallel = TRUE, cores = 2) str(crab.trees, max.level = 1) #> List of 200 #>  $ 1  :List of 2 #>  $ 2  :List of 2 #>  $ 3  :List of 2 #>  $ 4  :List of 2 #>  $ 5  :List of 2 #>  $ 6  :List of 2 #>  $ 7  :List of 2 #>  $ 8  :List of 2 #>  $ 9  :List of 2 #>  $ 10 :List of 2 #>  $ 11 :List of 2 #>  $ 12 :List of 2 #>  $ 13 :List of 2 #>  $ 14 :List of 2 #>  $ 15 :List of 2 #>  $ 16 :List of 2 #>  $ 17 :List of 2 #>  $ 18 :List of 2 #>  $ 19 :List of 2 #>  $ 20 :List of 2 #>  $ 21 :List of 2 #>  $ 22 :List of 2 #>  $ 23 :List of 2 #>  $ 24 :List of 2 #>  $ 25 :List of 2 #>  $ 26 :List of 2 #>  $ 27 :List of 2 #>  $ 28 :List of 2 #>  $ 29 :List of 2 #>  $ 30 :List of 2 #>  $ 31 :List of 2 #>  $ 32 :List of 2 #>  $ 33 :List of 2 #>  $ 34 :List of 2 #>  $ 35 :List of 2 #>  $ 36 :List of 2 #>  $ 37 :List of 2 #>  $ 38 :List of 2 #>  $ 39 :List of 2 #>  $ 40 :List of 2 #>  $ 41 :List of 2 #>  $ 42 :List of 2 #>  $ 43 :List of 2 #>  $ 44 :List of 2 #>  $ 45 :List of 2 #>  $ 46 :List of 2 #>  $ 47 :List of 2 #>  $ 48 :List of 2 #>  $ 49 :List of 2 #>  $ 50 :List of 2 #>  $ 51 :List of 2 #>  $ 52 :List of 2 #>  $ 53 :List of 2 #>  $ 54 :List of 2 #>  $ 55 :List of 2 #>  $ 56 :List of 2 #>  $ 57 :List of 2 #>  $ 58 :List of 2 #>  $ 59 :List of 2 #>  $ 60 :List of 2 #>  $ 61 :List of 2 #>  $ 62 :List of 2 #>  $ 63 :List of 2 #>  $ 64 :List of 2 #>  $ 65 :List of 2 #>  $ 66 :List of 2 #>  $ 67 :List of 2 #>  $ 68 :List of 2 #>  $ 69 :List of 2 #>  $ 70 :List of 2 #>  $ 71 :List of 2 #>  $ 72 :List of 2 #>  $ 73 :List of 2 #>  $ 74 :List of 2 #>  $ 75 :List of 2 #>  $ 76 :List of 2 #>  $ 77 :List of 2 #>  $ 78 :List of 2 #>  $ 79 :List of 2 #>  $ 80 :List of 2 #>  $ 81 :List of 2 #>  $ 82 :List of 2 #>  $ 83 :List of 2 #>  $ 84 :List of 2 #>  $ 85 :List of 2 #>  $ 86 :List of 2 #>  $ 87 :List of 2 #>  $ 88 :List of 2 #>  $ 89 :List of 2 #>  $ 90 :List of 2 #>  $ 91 :List of 2 #>  $ 92 :List of 2 #>  $ 93 :List of 2 #>  $ 94 :List of 2 #>  $ 95 :List of 2 #>  $ 96 :List of 2 #>  $ 97 :List of 2 #>  $ 98 :List of 2 #>  $ 99 :List of 2 #>   [list output truncated] #>  - attr(*, \"split_type\")= chr \"data.frame\" #>  - attr(*, \"split_labels\")='data.frame':\t200 obs. of  1 variable:"},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":null,"dir":"Reference","previous_headings":"","what":"Astralian crabs — crab","title":"Astralian crabs — crab","text":"Measurements rock crabs genus Leptograpsus. data set contains 200 observations  two species crab (blue orange), 50 specimens sex species,   collected site Fremantle, Western Australia. Type class variable 4 classes combinations specie sex (BlueMale, BlueFemale, OrangeMale OrangeFemale). FLthe size frontal lobe length, mm RWrear width, mm CLlength midline carapace, mm CWmaximum width carapace, mm BDdepth body; females, measured displacement abdomen, mm","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Astralian crabs — crab","text":"","code":"data(crab)"},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Astralian crabs — crab","text":"data frame 200 rows 6 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Astralian crabs — crab","text":"Campbell, N. . & Mahon, R. J. (1974), Multivariate Study Variation Two Species Rock Crab genus Leptograpsus, Australian Journal Zoology 22(3), 417 - 425.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Fish catch data set — fishcatch","title":"Fish catch data set — fishcatch","text":"159 fishes 7 species caught measured. Altogether   7 variables.  fishes caught lake(Laengelmavesi) near Tampere Finland. Type 7 fish classes, 35 cases Bream, 11 cases Parkki, 56 cases Perch 17 cases Pike, 20 cases Roach, 14 cases Smelt 6 cases Whitewish. weight Weight fish (grams) length1 Length nose beginning tail (cm) length2 Length nose notch tail (cm) length3 Length nose end tail (cm) height Maximal height % Length3 width Maximal width % Length3","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fish catch data set — fishcatch","text":"","code":"data(fishcatch)"},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Fish catch data set — fishcatch","text":"data frame 159 rows 7 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Fish catch data set — fishcatch","text":"urlhttp://www.amstat.org/publications/jse/jse_data_archive.htm","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/glass.html","id":null,"dir":"Reference","previous_headings":"","what":"Glass data set — glass","title":"Glass data set — glass","text":"Contains measurements 214 observations 6 types glass; defined terms oxide content. Type 6 types glasses X1 refractive index X2 Sodium (unit measurement: weight percent corresponding oxide). X3 Magnesium X4 Aluminum X5 Silicon X6 Potassium X7 Calcium X8 Barium X9 Iron","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/glass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Glass data set — glass","text":"","code":"data(glass)"},{"path":"https://github.com/natydasilva/PPforest/reference/glass.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Glass data set — glass","text":"data frame 214 rows 10 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/image.html","id":null,"dir":"Reference","previous_headings":"","what":"The image data set — image","title":"The image data set — image","text":"contains  2310 observations instances 7 outdoor images Type 7 types outdoor images, brickface, cement,  foliage, grass, path, sky, window. X1 column center pixel region X2 row center pixel region. X3 number pixels region = 9. X4 results line extraction algorithm counts many lines length 5 (orientation) low contrast, less equal 5, go region. X5 measure contrast horizontally adjacent pixels region. 6, mean standard deviation given. attribute used vertical edge detector. X6 X5 sd X7 measures contrast vertically adjacent pixels. Used horizontal line detection. X8 sd X7 X9 average region (R + G + B)/3 X10 average region R value. X11 average region B value. X12 average region G value. X13 measure excess red: (2R - (G + B)) X14 measure excess blue: (2B - (G + R)) X15 measure excess green: (2G - (R + B)) X16 3-d nonlinear transformation RGB. (Algorithm can found Foley VanDam, Fundamentals Interactive Computer Graphics) X17 mean X16 X18 hue  mean","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/image.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The image data set — image","text":"","code":"data(image)"},{"path":"https://github.com/natydasilva/PPforest/reference/image.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The image data set — image","text":"data frame contains 2310 observations 19 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":null,"dir":"Reference","previous_headings":"","what":"Leukemia data set — leukemia","title":"Leukemia data set — leukemia","text":"dataset comes study gene expression two types acute leukemias, acute lymphoblastic leukemia () acute myeloid leukemia (AML). Gene expression levels measured using Affymetrix high density oligonucleotide arrays containing 6817 human genes. data set containing 72 observations 3 leukemia types classes. Type 3 classes 38 cases B-cell , 25 cases AML 9 cases T-cell . Gene1 Gen 40 gene expression levels","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leukemia data set — leukemia","text":"","code":"data(leukemia)"},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Leukemia data set — leukemia","text":"data frame 72 rows 41 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Leukemia data set — leukemia","text":"Dudoit, S., Fridlyand, J. Speed, T. P. (2002). Comparison Discrimination Methods Classification Tumors Using Gene Expression Data. Journal American statistical Association 97 77-87.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":null,"dir":"Reference","previous_headings":"","what":"Lymphoma data set — lymphoma","title":"Lymphoma data set — lymphoma","text":"Gene expression three prevalent adult lymphoid malignancies: B-cell chronic lymphocytic leukemia (B-CLL), follicular lymphoma (FL), diffuse large B-cell lym- phoma (DLBCL). Gene expression levels measured using specialized cDNA microarray, Lymphochip, containing genes preferentially expressed lymphoid cells known immunologic oncologic importance. data set contain 80 observations 3 lymphoma types. Type Class variable 3 classes 29 cases B-cell (B-CLL), 42 cases diffuse large B-cell lymphoma (DLBCL) 9 cases follicular lymphoma (FL). Gene1 Gen 50gene expression","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lymphoma data set — lymphoma","text":"","code":"data(lymphoma)"},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Lymphoma data set — lymphoma","text":"data frame 80 rows 51 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Lymphoma data set — lymphoma","text":"Dudoit, S., Fridlyand, J. Speed, T. P. (2002). Comparison Discrimination Methods Classification Tumors Using Gene Ex- pression Data. Journal American statistical Association 97 77-87.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Data structure with the  projected and boundary by node and class. — node_data","title":"Data structure with the  projected and boundary by node and class. — node_data","text":"Data structure  projected boundary node class.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data structure with the  projected and boundary by node and class. — node_data","text":"","code":"node_data(ppf, tr, Rule = 1)"},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data structure with the  projected and boundary by node and class. — node_data","text":"ppf PPforest object tr numerical value  identify tree Rule split rule 1:mean two group means, 2:weighted mean, 3: mean max(left group) min(right group), 4: weighted mean max(left group) min(right group)","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data structure with the  projected and boundary by node and class. — node_data","text":"Data frame projected data class node id boundaries","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data structure with the  projected and boundary by node and class. — node_data","text":"","code":"#crab data set with all the observations used as training  pprf.crab <- PPforest(data = crab, std =TRUE, class = 'Type',  size.tr = 1, m = 200, size.p = .5, PPmethod = 'LDA') node_data(ppf = pprf.crab, tr = 1)  #>         proj.data Class         cut node.id LR.class   Dir #> 1   -0.0495768213     1  0.03547448       1        L FALSE #> 2   -0.0359435011     1  0.03547448       1        L FALSE #> 3   -0.1100147873     1  0.03547448       1        L FALSE #> 4   -0.0495768213     1  0.03547448       1        L FALSE #> 5   -0.0543366596     1  0.03547448       1        L FALSE #> 6   -0.0873789996     1  0.03547448       1        L FALSE #> 7   -0.0309852962     1  0.03547448       1        L FALSE #> 8   -0.0955751011     1  0.03547448       1        L FALSE #> 9   -0.0372703473     1  0.03547448       1        L FALSE #> 10  -0.0556364394     1  0.03547448       1        L FALSE #> 11  -0.0628172205     1  0.03547448       1        L FALSE #> 12  -0.0114046316     1  0.03547448       1        L FALSE #> 13  -0.0372703473     1  0.03547448       1        L FALSE #> 14  -0.1085933387     1  0.03547448       1        L FALSE #> 15  -0.0395493308     1  0.03547448       1        L FALSE #> 16  -0.0862343861     1  0.03547448       1        L FALSE #> 17  -0.0516803480     1  0.03547448       1        L FALSE #> 18  -0.0934045792     1  0.03547448       1        L FALSE #> 19  -0.1281070080     1  0.03547448       1        L FALSE #> 20  -0.1281070080     1  0.03547448       1        L FALSE #> 21  -0.0309852962     1  0.03547448       1        L FALSE #> 22  -0.0395493308     1  0.03547448       1        L FALSE #> 23  -0.1157708485     1  0.03547448       1        L FALSE #> 24  -0.0873789996     1  0.03547448       1        L FALSE #> 25  -0.1085933387     1  0.03547448       1        L FALSE #> 26  -0.1461839432     1  0.03547448       1        L FALSE #> 27  -0.0844153189     1  0.03547448       1        L FALSE #> 28  -0.0934045792     1  0.03547448       1        L FALSE #> 29  -0.0873789996     1  0.03547448       1        L FALSE #> 30  -0.0309852962     1  0.03547448       1        L FALSE #> 31  -0.0302709136     1  0.03547448       1        L FALSE #> 32  -0.0512072245     1  0.03547448       1        L FALSE #> 33  -0.0556364394     1  0.03547448       1        L FALSE #> 34  -0.0436978985     1  0.03547448       1        L FALSE #> 35  -0.0838146362     1  0.03547448       1        L FALSE #> 36  -0.0903112610     1  0.03547448       1        L FALSE #> 37  -0.0385281199     1  0.03547448       1        L FALSE #> 38  -0.1100147873     1  0.03547448       1        L FALSE #> 39  -0.1100147873     1  0.03547448       1        L FALSE #> 40  -0.0495768213     1  0.03547448       1        L FALSE #> 41  -0.0934045792     1  0.03547448       1        L FALSE #> 42  -0.1281070080     1  0.03547448       1        L FALSE #> 43  -0.0903112610     1  0.03547448       1        L FALSE #> 44   0.0129955498     1  0.03547448       1        L FALSE #> 45  -0.1085933387     1  0.03547448       1        L FALSE #> 46  -0.0858570581     1  0.03547448       1        L FALSE #> 47  -0.1343373855     1  0.03547448       1        L FALSE #> 48  -0.0709277701     1  0.03547448       1        L FALSE #> 49  -0.0543366596     1  0.03547448       1        L FALSE #> 50  -0.1105942941     1  0.03547448       1        L FALSE #> 51  -0.0279607071     2  0.03547448       1        L FALSE #> 52  -0.0051595095     2  0.03547448       1        L FALSE #> 53   0.0230080993     2  0.03547448       1        L FALSE #> 54   0.0278029726     2  0.03547448       1        L FALSE #> 55   0.0393652673     2  0.03547448       1        L  TRUE #> 56  -0.0164867799     2  0.03547448       1        L FALSE #> 57  -0.0201016602     2  0.03547448       1        L FALSE #> 58  -0.0542569980     2  0.03547448       1        L FALSE #> 59   0.0055441685     2  0.03547448       1        L FALSE #> 60  -0.0372705436     2  0.03547448       1        L FALSE #> 61  -0.0259156661     2  0.03547448       1        L FALSE #> 62   0.0547586283     2  0.03547448       1        L  TRUE #> 63  -0.0221917833     2  0.03547448       1        L FALSE #> 64   0.0117707339     2  0.03547448       1        L FALSE #> 65  -0.0259156661     2  0.03547448       1        L FALSE #> 66  -0.0002847784     2  0.03547448       1        L FALSE #> 67   0.0245315783     2  0.03547448       1        L FALSE #> 68   0.0048159266     2  0.03547448       1        L FALSE #> 69  -0.0527876517     2  0.03547448       1        L FALSE #> 70  -0.0224559522     2  0.03547448       1        L FALSE #> 71  -0.0278687238     2  0.03547448       1        L FALSE #> 72  -0.0542569980     2  0.03547448       1        L FALSE #> 73  -0.0195301221     2  0.03547448       1        L FALSE #> 74   0.0299964042     2  0.03547448       1        L FALSE #> 75  -0.0201016602     2  0.03547448       1        L FALSE #> 76  -0.0059547467     2  0.03547448       1        L FALSE #> 77   0.0245315783     2  0.03547448       1        L FALSE #> 78  -0.0147329742     2  0.03547448       1        L FALSE #> 79  -0.0714451754     2  0.03547448       1        L FALSE #> 80   0.0140879126     2  0.03547448       1        L FALSE #> 81  -0.0512806511     2  0.03547448       1        L FALSE #> 82  -0.0224559522     2  0.03547448       1        L FALSE #> 83   0.0549032067     2  0.03547448       1        L  TRUE #> 84  -0.0372705436     2  0.03547448       1        L FALSE #> 85  -0.0221917833     2  0.03547448       1        L FALSE #> 86   0.0159128702     2  0.03547448       1        L FALSE #> 87  -0.0934653395     2  0.03547448       1        L FALSE #> 88  -0.0527876517     2  0.03547448       1        L FALSE #> 89   0.0055441685     2  0.03547448       1        L FALSE #> 90  -0.0224559522     2  0.03547448       1        L FALSE #> 91  -0.0147329742     2  0.03547448       1        L FALSE #> 92  -0.0278687238     2  0.03547448       1        L FALSE #> 93  -0.0201016602     2  0.03547448       1        L FALSE #> 94   0.0140879126     2  0.03547448       1        L FALSE #> 95  -0.0044078171     2  0.03547448       1        L FALSE #> 96   0.0140879126     2  0.03547448       1        L FALSE #> 97  -0.0094000604     2  0.03547448       1        L FALSE #> 98  -0.0512806511     2  0.03547448       1        L FALSE #> 99  -0.0221917833     2  0.03547448       1        L FALSE #> 100 -0.0044078171     2  0.03547448       1        L FALSE #> 101  0.0038655231     3  0.03547448       1        L FALSE #> 102 -0.0483907414     3  0.03547448       1        L FALSE #> 103 -0.0298530045     3  0.03547448       1        L FALSE #> 104 -0.0016433884     3  0.03547448       1        L FALSE #> 105 -0.0139524816     3  0.03547448       1        L FALSE #> 106  0.0389268344     3  0.03547448       1        L  TRUE #> 107  0.0188027799     3  0.03547448       1        L FALSE #> 108 -0.0759788435     3  0.03547448       1        L FALSE #> 109 -0.0804007418     3  0.03547448       1        L FALSE #> 110  0.0068227725     3  0.03547448       1        L FALSE #> 111  0.0069312341     3  0.03547448       1        L FALSE #> 112  0.0038655231     3  0.03547448       1        L FALSE #> 113 -0.0162026650     3  0.03547448       1        L FALSE #> 114  0.0479810117     3  0.03547448       1        L  TRUE #> 115  0.0016174180     3  0.03547448       1        L FALSE #> 116 -0.0016433884     3  0.03547448       1        L FALSE #> 117 -0.0157838706     3  0.03547448       1        L FALSE #> 118  0.0065336156     3  0.03547448       1        L FALSE #> 119  0.0255470951     3  0.03547448       1        L FALSE #> 120  0.0188027799     3  0.03547448       1        L FALSE #> 121  0.0089703847     3  0.03547448       1        L FALSE #> 122 -0.0759788435     3  0.03547448       1        L FALSE #> 123  0.0479810117     3  0.03547448       1        L  TRUE #> 124  0.0208622209     3  0.03547448       1        L FALSE #> 125 -0.0079895442     3  0.03547448       1        L FALSE #> 126 -0.0981000414     3  0.03547448       1        L FALSE #> 127 -0.1152748153     3  0.03547448       1        L FALSE #> 128 -0.0139524816     3  0.03547448       1        L FALSE #> 129  0.0038655231     3  0.03547448       1        L FALSE #> 130 -0.0216483934     3  0.03547448       1        L FALSE #> 131  0.0197884148     3  0.03547448       1        L FALSE #> 132 -0.0016433884     3  0.03547448       1        L FALSE #> 133 -0.0609969603     3  0.03547448       1        L FALSE #> 134 -0.0503352896     3  0.03547448       1        L FALSE #> 135  0.0038655231     3  0.03547448       1        L FALSE #> 136 -0.0016433884     3  0.03547448       1        L FALSE #> 137 -0.0263912123     3  0.03547448       1        L FALSE #> 138 -0.0804007418     3  0.03547448       1        L FALSE #> 139  0.0196294363     3  0.03547448       1        L FALSE #> 140 -0.0298530045     3  0.03547448       1        L FALSE #> 141  0.0606195353     3  0.03547448       1        L  TRUE #> 142  0.0068227725     3  0.03547448       1        L FALSE #> 143  0.0089703847     3  0.03547448       1        L FALSE #> 144 -0.0503352896     3  0.03547448       1        L FALSE #> 145 -0.0157838706     3  0.03547448       1        L FALSE #> 146 -0.0079895442     3  0.03547448       1        L FALSE #> 147  0.0068227725     3  0.03547448       1        L FALSE #> 148  0.0688300369     3  0.03547448       1        L  TRUE #> 149 -0.0981000414     3  0.03547448       1        L FALSE #> 150 -0.0348053189     3  0.03547448       1        L FALSE #> 151  0.1650389993     4  0.03547448       1        R  TRUE #> 152  0.1807720341     4  0.03547448       1        R  TRUE #> 153  0.0595158473     4  0.03547448       1        R  TRUE #> 154  0.1858157909     4  0.03547448       1        R  TRUE #> 155  0.0832212845     4  0.03547448       1        R  TRUE #> 156  0.0914344052     4  0.03547448       1        R  TRUE #> 157  0.0378077498     4  0.03547448       1        R  TRUE #> 158  0.1339847521     4  0.03547448       1        R  TRUE #> 159  0.0872087953     4  0.03547448       1        R  TRUE #> 160  0.0691382913     4  0.03547448       1        R  TRUE #> 161  0.1552480706     4  0.03547448       1        R  TRUE #> 162  0.0901325470     4  0.03547448       1        R  TRUE #> 163  0.0560419298     4  0.03547448       1        R  TRUE #> 164  0.1492660357     4  0.03547448       1        R  TRUE #> 165  0.0914344052     4  0.03547448       1        R  TRUE #> 166  0.0595158473     4  0.03547448       1        R  TRUE #> 167  0.0595158473     4  0.03547448       1        R  TRUE #> 168  0.0707410873     4  0.03547448       1        R  TRUE #> 169  0.1665959760     4  0.03547448       1        R  TRUE #> 170  0.0904631703     4  0.03547448       1        R  TRUE #> 171  0.1492660357     4  0.03547448       1        R  TRUE #> 172  0.1102336919     4  0.03547448       1        R  TRUE #> 173  0.0753122615     4  0.03547448       1        R  TRUE #> 174  0.0944065956     4  0.03547448       1        R  TRUE #> 175  0.1213599765     4  0.03547448       1        R  TRUE #> 176  0.1552480706     4  0.03547448       1        R  TRUE #> 177  0.0753122615     4  0.03547448       1        R  TRUE #> 178  0.0872087953     4  0.03547448       1        R  TRUE #> 179  0.0894043052     4  0.03547448       1        R  TRUE #> 180  0.1120230736     4  0.03547448       1        R  TRUE #> 181  0.1335935648     4  0.03547448       1        R  TRUE #> 182  0.0378077498     4  0.03547448       1        R  TRUE #> 183  0.1027472756     4  0.03547448       1        R  TRUE #> 184  0.1056960153     4  0.03547448       1        R  TRUE #> 185  0.1492660357     4  0.03547448       1        R  TRUE #> 186  0.0914243582     4  0.03547448       1        R  TRUE #> 187  0.0753122615     4  0.03547448       1        R  TRUE #> 188  0.0752117687     4  0.03547448       1        R  TRUE #> 189  0.1335935648     4  0.03547448       1        R  TRUE #> 190  0.1603987516     4  0.03547448       1        R  TRUE #> 191  0.0560419298     4  0.03547448       1        R  TRUE #> 192  0.1603987516     4  0.03547448       1        R  TRUE #> 193  0.1120400929     4  0.03547448       1        R  TRUE #> 194  0.1102336919     4  0.03547448       1        R  TRUE #> 195  0.1335935648     4  0.03547448       1        R  TRUE #> 196  0.0872087953     4  0.03547448       1        R  TRUE #> 197  0.0831798181     4  0.03547448       1        R  TRUE #> 198  0.0378077498     4  0.03547448       1        R  TRUE #> 199  0.1120230736     4  0.03547448       1        R  TRUE #> 200  0.0836109343     4  0.03547448       1        R  TRUE #> 201  0.0794275610     1 -0.01348186       2        R  TRUE #> 202  0.1918300893     1 -0.01348186       2        R  TRUE #> 203  0.3411855883     1 -0.01348186       2        R  TRUE #> 204  0.0794275610     1 -0.01348186       2        R  TRUE #> 205  0.2702726227     1 -0.01348186       2        R  TRUE #> 206  0.1685408373     1 -0.01348186       2        R  TRUE #> 207  0.2679864667     1 -0.01348186       2        R  TRUE #> 208  0.2839722440     1 -0.01348186       2        R  TRUE #> 209  0.2718086942     1 -0.01348186       2        R  TRUE #> 210  0.1315446020     1 -0.01348186       2        R  TRUE #> 211  0.1778505211     1 -0.01348186       2        R  TRUE #> 212  0.0021225840     1 -0.01348186       2        R  TRUE #> 213  0.2718086942     1 -0.01348186       2        R  TRUE #> 214  0.2444099058     1 -0.01348186       2        R  TRUE #> 215  0.1627476667     1 -0.01348186       2        R  TRUE #> 216  0.5102664264     1 -0.01348186       2        R  TRUE #> 217  0.0383507836     1 -0.01348186       2        R  TRUE #> 218  0.3900612914     1 -0.01348186       2        R  TRUE #> 219  0.5752860585     1 -0.01348186       2        R  TRUE #> 220  0.5752860585     1 -0.01348186       2        R  TRUE #> 221  0.2679864667     1 -0.01348186       2        R  TRUE #> 222  0.1627476667     1 -0.01348186       2        R  TRUE #> 223  0.4769959367     1 -0.01348186       2        R  TRUE #> 224  0.1685408373     1 -0.01348186       2        R  TRUE #> 225  0.2444099058     1 -0.01348186       2        R  TRUE #> 226  0.3620489378     1 -0.01348186       2        R  TRUE #> 227  0.3434896956     1 -0.01348186       2        R  TRUE #> 228  0.3900612914     1 -0.01348186       2        R  TRUE #> 229  0.1685408373     1 -0.01348186       2        R  TRUE #> 230  0.2679864667     1 -0.01348186       2        R  TRUE #> 231  0.0432030425     1 -0.01348186       2        R  TRUE #> 232  0.0757128585     1 -0.01348186       2        R  TRUE #> 233  0.1315446020     1 -0.01348186       2        R  TRUE #> 234  0.1032555285     1 -0.01348186       2        R  TRUE #> 235  0.2596635498     1 -0.01348186       2        R  TRUE #> 236  0.2349600215     1 -0.01348186       2        R  TRUE #> 237  0.2079376618     1 -0.01348186       2        R  TRUE #> 238  0.3411855883     1 -0.01348186       2        R  TRUE #> 239  0.3411855883     1 -0.01348186       2        R  TRUE #> 240  0.0794275610     1 -0.01348186       2        R  TRUE #> 241  0.3900612914     1 -0.01348186       2        R  TRUE #> 242  0.5752860585     1 -0.01348186       2        R  TRUE #> 243  0.2349600215     1 -0.01348186       2        R  TRUE #> 244 -0.0367829246     1 -0.01348186       2        R FALSE #> 245  0.2444099058     1 -0.01348186       2        R  TRUE #> 246  0.1692835597     1 -0.01348186       2        R  TRUE #> 247  0.2785923127     1 -0.01348186       2        R  TRUE #> 248  0.0972367188     1 -0.01348186       2        R  TRUE #> 249  0.2702726227     1 -0.01348186       2        R  TRUE #> 250  0.0919896259     1 -0.01348186       2        R  TRUE #> 251 -0.4841663705     2 -0.01348186       2        L FALSE #> 252 -0.2854185391     2 -0.01348186       2        L FALSE #> 253 -0.2470264328     2 -0.01348186       2        L FALSE #> 254 -0.7511245450     2 -0.01348186       2        L FALSE #> 255 -0.1646361956     2 -0.01348186       2        L FALSE #> 256 -0.5074666656     2 -0.01348186       2        L FALSE #> 257 -0.7157972196     2 -0.01348186       2        L FALSE #> 258 -0.0400880688     2 -0.01348186       2        L FALSE #> 259 -0.1785614560     2 -0.01348186       2        L FALSE #> 260 -0.6059897886     2 -0.01348186       2        L FALSE #> 261 -0.4657510097     2 -0.01348186       2        L FALSE #> 262 -0.3785690930     2 -0.01348186       2        L FALSE #> 263 -0.1175511975     2 -0.01348186       2        L FALSE #> 264 -0.2050451002     2 -0.01348186       2        L FALSE #> 265 -0.4657510097     2 -0.01348186       2        L FALSE #> 266 -0.2220788601     2 -0.01348186       2        L FALSE #> 267 -0.5920428959     2 -0.01348186       2        L FALSE #> 268  0.0264529105     2 -0.01348186       2        L  TRUE #> 269  0.0523087195     2 -0.01348186       2        L  TRUE #> 270 -0.0544228875     2 -0.01348186       2        L FALSE #> 271 -0.4289988188     2 -0.01348186       2        L FALSE #> 272 -0.0400880688     2 -0.01348186       2        L FALSE #> 273 -0.3720548323     2 -0.01348186       2        L FALSE #> 274 -0.4460183085     2 -0.01348186       2        L FALSE #> 275 -0.7157972196     2 -0.01348186       2        L FALSE #> 276 -0.1454164426     2 -0.01348186       2        L FALSE #> 277 -0.5920428959     2 -0.01348186       2        L FALSE #> 278 -0.2072163691     2 -0.01348186       2        L FALSE #> 279 -0.6839189198     2 -0.01348186       2        L FALSE #> 280 -0.3443044744     2 -0.01348186       2        L FALSE #> 281 -0.2405121721     2 -0.01348186       2        L FALSE #> 282 -0.0544228875     2 -0.01348186       2        L FALSE #> 283 -0.4150556072     2 -0.01348186       2        L FALSE #> 284 -0.6059897886     2 -0.01348186       2        L FALSE #> 285 -0.1175511975     2 -0.01348186       2        L FALSE #> 286 -0.3967657227     2 -0.01348186       2        L FALSE #> 287 -0.3015367007     2 -0.01348186       2        L FALSE #> 288  0.0523087195     2 -0.01348186       2        L  TRUE #> 289 -0.1785614560     2 -0.01348186       2        L FALSE #> 290 -0.0544228875     2 -0.01348186       2        L FALSE #> 291 -0.2072163691     2 -0.01348186       2        L FALSE #> 292 -0.4289988188     2 -0.01348186       2        L FALSE #> 293 -0.7157972196     2 -0.01348186       2        L FALSE #> 294 -0.3443044744     2 -0.01348186       2        L FALSE #> 295 -0.1545184385     2 -0.01348186       2        L FALSE #> 296 -0.3443044744     2 -0.01348186       2        L FALSE #> 297 -0.4000782290     2 -0.01348186       2        L FALSE #> 298 -0.2405121721     2 -0.01348186       2        L FALSE #> 299 -0.1175511975     2 -0.01348186       2        L FALSE #> 300 -0.1545184385     2 -0.01348186       2        L FALSE #> 301  0.3694525754     3 -0.01348186       2        R  TRUE #> 302  0.3591128602     3 -0.01348186       2        R  TRUE #> 303  0.2441838126     3 -0.01348186       2        R  TRUE #> 304  0.3574329072     3 -0.01348186       2        R  TRUE #> 305  0.2370164032     3 -0.01348186       2        R  TRUE #> 306  0.2256498836     3 -0.01348186       2        R  TRUE #> 307  0.2028593096     3 -0.01348186       2        R  TRUE #> 308  0.5699167163     3 -0.01348186       2        R  TRUE #> 309  0.2729572938     3 -0.01348186       2        R  TRUE #> 310  0.2931886730     3 -0.01348186       2        R  TRUE #> 311  0.2961606531     3 -0.01348186       2        R  TRUE #> 312  0.3694525754     3 -0.01348186       2        R  TRUE #> 313  0.4412880474     3 -0.01348186       2        R  TRUE #> 314  0.4529524651     3 -0.01348186       2        R  TRUE #> 315  0.3648623122     3 -0.01348186       2        R  TRUE #> 316  0.3574329072     3 -0.01348186       2        R  TRUE #> 317  0.0382648909     3 -0.01348186       2        R  TRUE #> 318  0.3661617014     3 -0.01348186       2        R  TRUE #> 319  0.2166300994     3 -0.01348186       2        R  TRUE #> 320  0.2028593096     3 -0.01348186       2        R  TRUE #> 321  0.2002605313     3 -0.01348186       2        R  TRUE #> 322  0.5699167163     3 -0.01348186       2        R  TRUE #> 323  0.4529524651     3 -0.01348186       2        R  TRUE #> 324  0.3779410062     3 -0.01348186       2        R  TRUE #> 325  0.4105583473     3 -0.01348186       2        R  TRUE #> 326  0.7178832523     3 -0.01348186       2        R  TRUE #> 327  0.7133752008     3 -0.01348186       2        R  TRUE #> 328  0.2370164032     3 -0.01348186       2        R  TRUE #> 329  0.3694525754     3 -0.01348186       2        R  TRUE #> 330  0.1711032592     3 -0.01348186       2        R  TRUE #> 331  0.4244050771     3 -0.01348186       2        R  TRUE #> 332  0.3574329072     3 -0.01348186       2        R  TRUE #> 333  0.4062158095     3 -0.01348186       2        R  TRUE #> 334  0.4382159044     3 -0.01348186       2        R  TRUE #> 335  0.3694525754     3 -0.01348186       2        R  TRUE #> 336  0.3574329072     3 -0.01348186       2        R  TRUE #> 337  0.4466500274     3 -0.01348186       2        R  TRUE #> 338  0.2729572938     3 -0.01348186       2        R  TRUE #> 339  0.3042252554     3 -0.01348186       2        R  TRUE #> 340  0.2441838126     3 -0.01348186       2        R  TRUE #> 341  0.0432136316     3 -0.01348186       2        R  TRUE #> 342  0.2931886730     3 -0.01348186       2        R  TRUE #> 343  0.2002605313     3 -0.01348186       2        R  TRUE #> 344  0.4382159044     3 -0.01348186       2        R  TRUE #> 345  0.0382648909     3 -0.01348186       2        R  TRUE #> 346  0.4105583473     3 -0.01348186       2        R  TRUE #> 347  0.2931886730     3 -0.01348186       2        R  TRUE #> 348  0.0844485608     3 -0.01348186       2        R  TRUE #> 349  0.7178832523     3 -0.01348186       2        R  TRUE #> 350  0.2823429177     3 -0.01348186       2        R  TRUE #> 351 -0.0760430765     1 -0.01665642       5        L FALSE #> 352 -0.0585741182     1 -0.01665642       5        L FALSE #> 353 -0.0816491639     1 -0.01665642       5        L FALSE #> 354 -0.0760430765     1 -0.01665642       5        L FALSE #> 355 -0.1038609232     1 -0.01665642       5        L FALSE #> 356 -0.0741787031     1 -0.01665642       5        L FALSE #> 357 -0.0169864945     1 -0.01665642       5        L FALSE #> 358 -0.0868804330     1 -0.01665642       5        L FALSE #> 359 -0.0837321729     1 -0.01665642       5        L FALSE #> 360 -0.1130076674     1 -0.01665642       5        L FALSE #> 361 -0.1753676097     1 -0.01665642       5        L FALSE #> 362 -0.0922935718     1 -0.01665642       5        L FALSE #> 363 -0.0837321729     1 -0.01665642       5        L FALSE #> 364 -0.1744270876     1 -0.01665642       5        L FALSE #> 365 -0.0808990737     1 -0.01665642       5        L FALSE #> 366 -0.0964191201     1 -0.01665642       5        L FALSE #> 367 -0.1350872179     1 -0.01665642       5        L FALSE #> 368 -0.1279485889     1 -0.01665642       5        L FALSE #> 369 -0.0918949547     1 -0.01665642       5        L FALSE #> 370 -0.0918949547     1 -0.01665642       5        L FALSE #> 371 -0.0169864945     1 -0.01665642       5        L FALSE #> 372 -0.0808990737     1 -0.01665642       5        L FALSE #> 373 -0.0667225712     1 -0.01665642       5        L FALSE #> 374 -0.0741787031     1 -0.01665642       5        L FALSE #> 375 -0.1744270876     1 -0.01665642       5        L FALSE #> 376 -0.1737257503     1 -0.01665642       5        L FALSE #> 377 -0.1409038324     1 -0.01665642       5        L FALSE #> 378 -0.1279485889     1 -0.01665642       5        L FALSE #> 379 -0.0741787031     1 -0.01665642       5        L FALSE #> 380 -0.0169864945     1 -0.01665642       5        L FALSE #> 381 -0.0837961623     1 -0.01665642       5        L FALSE #> 382 -0.1352027560     1 -0.01665642       5        L FALSE #> 383 -0.1130076674     1 -0.01665642       5        L FALSE #> 384 -0.1092941572     1 -0.01665642       5        L FALSE #> 385 -0.1544219839     1 -0.01665642       5        L FALSE #> 386 -0.0947777145     1 -0.01665642       5        L FALSE #> 387 -0.0420352314     1 -0.01665642       5        L FALSE #> 388 -0.0816491639     1 -0.01665642       5        L FALSE #> 389 -0.0816491639     1 -0.01665642       5        L FALSE #> 390 -0.0760430765     1 -0.01665642       5        L FALSE #> 391 -0.1279485889     1 -0.01665642       5        L FALSE #> 392 -0.0918949547     1 -0.01665642       5        L FALSE #> 393 -0.0947777145     1 -0.01665642       5        L FALSE #> 394 -0.0738267761     1 -0.01665642       5        L FALSE #> 395 -0.1744270876     1 -0.01665642       5        L FALSE #> 396 -0.1158675361     1 -0.01665642       5        L FALSE #> 397 -0.1872873421     1 -0.01665642       5        L FALSE #> 398 -0.1360335064     1 -0.01665642       5        L FALSE #> 399 -0.1038609232     1 -0.01665642       5        L FALSE #> 400 -0.2121999917     1 -0.01665642       5        L FALSE #> 401  0.0837460259     3 -0.01665642       5        R  TRUE #> 402  0.0311190810     3 -0.01665642       5        R  TRUE #> 403 -0.0214299997     3 -0.01665642       5        R FALSE #> 404  0.0399975290     3 -0.01665642       5        R  TRUE #> 405  0.0934499118     3 -0.01665642       5        R  TRUE #> 406  0.1615376998     3 -0.01665642       5        R  TRUE #> 407  0.1222842568     3 -0.01665642       5        R  TRUE #> 408  0.1331965070     3 -0.01665642       5        R  TRUE #> 409 -0.0017319484     3 -0.01665642       5        R  TRUE #> 410  0.0517816279     3 -0.01665642       5        R  TRUE #> 411  0.0542375669     3 -0.01665642       5        R  TRUE #> 412  0.0837460259     3 -0.01665642       5        R  TRUE #> 413  0.0905012744     3 -0.01665642       5        R  TRUE #> 414  0.1945701449     3 -0.01665642       5        R  TRUE #> 415  0.0599243145     3 -0.01665642       5        R  TRUE #> 416  0.0399975290     3 -0.01665642       5        R  TRUE #> 417  0.0305046242     3 -0.01665642       5        R  TRUE #> 418  0.0775025907     3 -0.01665642       5        R  TRUE #> 419  0.0774672589     3 -0.01665642       5        R  TRUE #> 420  0.1222842568     3 -0.01665642       5        R  TRUE #> 421  0.0781829250     3 -0.01665642       5        R  TRUE #> 422  0.1331965070     3 -0.01665642       5        R  TRUE #> 423  0.1945701449     3 -0.01665642       5        R  TRUE #> 424  0.1334682277     3 -0.01665642       5        R  TRUE #> 425  0.0456040702     3 -0.01665642       5        R  TRUE #> 426  0.0582279357     3 -0.01665642       5        R  TRUE #> 427 -0.1074732241     3 -0.01665642       5        R FALSE #> 428  0.0934499118     3 -0.01665642       5        R  TRUE #> 429  0.0837460259     3 -0.01665642       5        R  TRUE #> 430  0.0519200572     3 -0.01665642       5        R  TRUE #> 431  0.1739362556     3 -0.01665642       5        R  TRUE #> 432  0.0399975290     3 -0.01665642       5        R  TRUE #> 433  0.0158091078     3 -0.01665642       5        R  TRUE #> 434  0.0502437737     3 -0.01665642       5        R  TRUE #> 435  0.0837460259     3 -0.01665642       5        R  TRUE #> 436  0.0399975290     3 -0.01665642       5        R  TRUE #> 437  0.0201719528     3 -0.01665642       5        R  TRUE #> 438 -0.0017319484     3 -0.01665642       5        R  TRUE #> 439  0.0689330833     3 -0.01665642       5        R  TRUE #> 440 -0.0214299997     3 -0.01665642       5        R FALSE #> 441  0.0806961793     3 -0.01665642       5        R  TRUE #> 442  0.0517816279     3 -0.01665642       5        R  TRUE #> 443  0.0781829250     3 -0.01665642       5        R  TRUE #> 444  0.0502437737     3 -0.01665642       5        R  TRUE #> 445  0.0305046242     3 -0.01665642       5        R  TRUE #> 446  0.0456040702     3 -0.01665642       5        R  TRUE #> 447  0.0517816279     3 -0.01665642       5        R  TRUE #> 448  0.1620652761     3 -0.01665642       5        R  TRUE #> 449  0.0582279357     3 -0.01665642       5        R  TRUE #> 450  0.1238970047     3 -0.01665642       5        R  TRUE"},{"path":"https://github.com/natydasilva/PPforest/reference/olive.html","id":null,"dir":"Reference","previous_headings":"","what":"The olive data set — olive","title":"The olive data set — olive","text":"contains  572 observations 10 variables RegionThree super-classes Italy: North, South island Sardinia area Nine collection areas: three North, four South 2 Sardinia palmitic fatty acids percent x 100 palmitoleic fatty acids percent x 100 stearicfatty acids percent x 100 oleicfatty acids percent x 100 linoleicfatty acids percent x 100 linolenicfatty acids percent x 100 arachidic fatty acids percent x 100 eicosenoic fatty acids percent x 100","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/olive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The olive data set — olive","text":"","code":"data(olive)"},{"path":"https://github.com/natydasilva/PPforest/reference/olive.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The olive data set — olive","text":"data frame contains 573 observations 10 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":null,"dir":"Reference","previous_headings":"","what":"Parkinson data set — parkinson","title":"Parkinson data set — parkinson","text":"data set containing 195 observations 2 parkinson types. Type Class variable 2 classes, 48 cases healthy people 147 cases Parkinson. feature variables biomedical voice measures. X1 Average vocal fundamental frequency X2 Maximum vocal fundamental frequency X3 Minimum vocal fundamental frequency X4 MDVP:Jitter(%) measures variation fundamental frequency X5 MDVP:Jitter(Abs) measures variation fundamental frequency X6 MDVP:RAP measures variation fundamental frequency X7 MDVP:PPQ measures variation fundamental frequency X8 Jitter:DDP measures variation fundamental frequency X9 MDVP:Shimmer measures variation amplitude X10 MDVP:Shimmer(dB) measures variation amplitude X11 Shimmer:APQ3 measures variation amplitude X12 Shimmer:APQ5 measures variation amplitude X13 MDVP:APQ measures variation amplitude X14 Shimmer:DDA measures variation amplitude X15 NHR measures ratio noise tonal components voice X16 HNR measures ratio noise tonal components voice X17 RPDE nonlinear dynamical complexity measures X18 D2 nonlinear dynamical complexity measures X19 DFA - Signal fractal scaling exponent X20 spread1 Nonlinear measures fundamental frequency variation X21 spread2 Nonlinear measures fundamental frequency variation X22 PPE Nonlinear measures fundamental frequency variation","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parkinson data set — parkinson","text":"","code":"data(parkinson)"},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Parkinson data set — parkinson","text":"data frame 195 rows 23 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Parkinson data set — parkinson","text":"urlhttps://archive.ics.uci.edu/ml/datasets/Parkinsons","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain the permuted importance variable measure — permute_importance","title":"Obtain the permuted importance variable measure — permute_importance","text":"Obtain permuted importance variable measure","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain the permuted importance variable measure — permute_importance","text":"","code":"permute_importance(ppf)"},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain the permuted importance variable measure — permute_importance","text":"ppf PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain the permuted importance variable measure — permute_importance","text":"data frame permuted importance measures, imp permuted importance measure defined Brieman paper, imp2 permuted importance measure defined randomForest package, standard deviation (sd.im sd.imp2) measure computed  also standardized mesure.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain the permuted importance variable measure — permute_importance","text":"","code":"pprf.crab <- PPforest(data = crab, class = 'Type', std = TRUE, size.tr = 1, m = 100, size.p = .4, PPmethod = 'LDA', parallel = TRUE, core = 2) permute_importance(ppf = pprf.crab)  #>   nm   imp    sd.imp      imp2   sd.imp2 imp2.std  imp.std #> 1 CW 12.27 11.128138 0.1669751 0.1501726 1.111888 1.102610 #> 2 CL 14.00  9.982814 0.1936907 0.1380000 1.403555 1.402410 #> 3 BD 14.82 13.674706 0.2036439 0.1870608 1.088651 1.083753 #> 4 RW 15.41 11.684484 0.2120529 0.1599439 1.325796 1.318843 #> 5 FL 16.24 12.917860 0.2248441 0.1807173 1.244175 1.257174"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees \nin the forest — ppf_avg_imp","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees \nin the forest — ppf_avg_imp","text":"Global importance measure PPforest object average IMP PPtree measure trees  forest","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees \nin the forest — ppf_avg_imp","text":"","code":"ppf_avg_imp(ppf, class)"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees \nin the forest — ppf_avg_imp","text":"ppf PPforest object class character name class variable.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees \nin the forest — ppf_avg_imp","text":"Data frame global importance measure","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees \nin the forest — ppf_avg_imp","text":"","code":"#crab data set with all the observations used as training  pprf.crab <- PPforest(data = crab, std =TRUE, class = 'Type',  size.tr = 1, m = 100, size.p = .5, PPmethod = 'LDA')  ppf_avg_imp(pprf.crab, 'Type')  #> # A tibble: 5 × 2 #>   variable  mean #>   <fct>    <dbl> #> 1 CW       0.503 #> 2 CL       0.441 #> 3 RW       0.359 #> 4 BD       0.330 #> 5 FL       0.274"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Global importance measure for a PPforest object — ppf_global_imp","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"Global importance measure PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"","code":"ppf_global_imp(data, class, ppf)"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"data Data frame complete data set. class character name class variable. ppf PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"Data frame global importance measure","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"","code":"#crab data set with all the observations used as training  pprf.crab <- PPforest(data = crab, std = TRUE, class = 'Type',  size.tr = 1, m = 200, size.p = .5, PPmethod = 'LDA', parallel = TRUE, cores = 2)   ppf_global_imp(data = crab, class = 'Type', pprf.crab)  #> # A tibble: 5 × 2 #>   variable  mean #>   <fct>    <dbl> #> 1 CW       0.383 #> 2 CL       0.356 #> 3 RW       0.305 #> 4 BD       0.257 #> 5 FL       0.224"},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":null,"dir":"Reference","previous_headings":"","what":"Print PPforest object — print.PPforest","title":"Print PPforest object — print.PPforest","text":"Print PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print PPforest object — print.PPforest","text":"","code":"# S3 method for PPforest print(x, ...)"},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print PPforest object — print.PPforest","text":"x PPforest class object ... additional parameter","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print PPforest object — print.PPforest","text":"printed results PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":null,"dir":"Reference","previous_headings":"","what":"Data structure with the  projected and boundary by node and class. — ternary_str","title":"Data structure with the  projected and boundary by node and class. — ternary_str","text":"Data structure  projected boundary node class.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data structure with the  projected and boundary by node and class. — ternary_str","text":"","code":"ternary_str(ppf, id, sp, dx, dy)"},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data structure with the  projected and boundary by node and class. — ternary_str","text":"ppf PPforest object id vector selected projection directions sp simplex dimensions, k number classes sp = k - 1 dx first direction included id dy second direction included id","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data structure with the  projected and boundary by node and class. — ternary_str","text":"Data frame needed visualize ternary plot","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data structure with the  projected and boundary by node and class. — ternary_str","text":"","code":"#crab data set with all the observations used as training pprf.crab <- PPforest(data = crab, std =TRUE, class = \"Type\",  size.tr = 1, m = 100, size.p = .5, PPmethod = 'LDA')  require(dplyr) #> Loading required package: dplyr #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union pl_ter <- function(dat, dx, dy ){   p1  <- dat[[1]] %>% dplyr::filter(pair %in% paste(dx, dy, sep = \"-\") ) %>%     dplyr::select(Class, x, y) %>%     ggplot2::ggplot(ggplot2::aes(x, y, color = Class)) +     ggplot2::geom_segment(data = dat[[2]], ggplot2::aes(x = x1, xend = x2,                                                y = y1, yend = y2), color = \"black\" ) +     ggplot2::geom_point(size = I(3), alpha = .5) +     ggplot2::labs(y = \" \",  x = \" \") +     ggplot2::theme(legend.position = \"none\", aspect.ratio = 1) +     ggplot2::scale_colour_brewer(type = \"qual\", palette = \"Dark2\") +     ggplot2::labs(x = paste0(\"T\", dx, \" \"), y = paste0(\"T\", dy, \" \")) +     ggplot2::theme(aspect.ratio = 1)   p1 } #ternary plot in tree different selected dierections  pl_ter(ternary_str(pprf.crab, id = c(1, 2, 3), sp = 3, dx = 1, dy = 2), 1, 2 ) #> Warning: `select_()` was deprecated in dplyr 0.7.0. #> ℹ Please use `select()` instead. #> ℹ The deprecated feature was likely used in the PPforest package. #>   Please report the issue to the authors."},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"Obtain predicted class new data baggtree function PPforest","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"","code":"trees_pred(object, xnew, parallel = FALSE, cores = 2, rule = 1)"},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"object Projection pursuit classification forest structure PPforest baggtree xnew data frame explicative variables used get new predicted values. parallel logical condition, TRUE  parallelize function cores number cores used parallelization rule split rule 1: mean two group means 2: weighted mean two group means - weight group size 3: weighted mean two group means - weight group sd 4: weighted mean two group means - weight group se 5: mean two group medians 6: weighted mean two group medians - weight group size 7: weighted mean two group median - weight group IQR 8: weighted mean two group median - weight group IQR size","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"predicted values PPforest baggtree","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"","code":"if (FALSE) { crab.trees <- baggtree(data = crab, class = 'Type',  m =  200, PPmethod = 'LDA', lambda = .1, size.p = 0.4 )   pr <- trees_pred(  crab.trees,xnew = crab[, -1], parallel= FALSE, cores = 2)  pprf.crab <- PPforest(data = crab, class = 'Type',  std = FALSE, size.tr = 2/3, m = 100, size.p = .4, PPmethod = 'LDA', parallel = TRUE )   trees_pred(pprf.crab, xnew = pprf.crab$test ,parallel = TRUE) }"},{"path":"https://github.com/natydasilva/PPforest/reference/wine.html","id":null,"dir":"Reference","previous_headings":"","what":"Wine data set — wine","title":"Wine data set — wine","text":"data set containing 178 observations 3 wine grown cultivares Italy.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/wine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wine data set — wine","text":"","code":"data(wine)"},{"path":"https://github.com/natydasilva/PPforest/reference/wine.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Wine data set — wine","text":"data frame 178 rows 14 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/wine.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Wine data set — wine","text":"Type Class variable 3 classes 3 different wine grown cultivares Italy. X1 X13Check vbles","code":""},{"path":"https://github.com/natydasilva/PPforest/news/index.html","id":"ppforest-013","dir":"Changelog","previous_headings":"","what":"PPforest 0.1.3","title":"PPforest 0.1.3","text":"CRAN release: 2022-09-09 fourth release package, minor changes included. Since R 4.2.0 switched use HTML5 documentation pages. Fix problems HTML generated package Rd files. Changed deprected functions.","code":""}]
