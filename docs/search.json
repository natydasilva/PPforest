[{"path":"https://github.com/natydasilva/PPforest/articles/PPforest-vignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Projection pursuit classification random forest","text":"PPforest package (projection pursuit random forest) contains functions run projection pursuit random forest classification problems. method utilize combinations variables tree construction. random forest split based single variable, chosen subset predictors. PPforest, split based linear combination randomly chosen variables. linear combination computed optimizing projection pursuit index, get projection variables best separates classes. PPforest uses PPtree algorithm, fits single tree data. Utilizing linear combinations variables separate classes takes correlation variables account, can outperform basic forest separations groups occurs combinations variables. Two projection pursuit indexes, LDA PDA, used PPforest. improve speed performance PPforest package, PPtree algorithm translated Rcpp. PPforest package utilizes number R packages included “suggests” load package start-. can install package CRAN: development version PPforest can installed github using: ##Projection pursuit classification forest PPforest, projection pursuit classification trees used individual model combined forest. original algorithm PPtreeViz package, translate original tree algorithm Rcpp improve speed performance run forest. One important characteristic PPtree treats data always two-class system, classes two algorithm uses two step projection pursuits optimization every node split. Let (Xi,yi)(X_i,y_i) data set, XiX_i p-dimensional vector explanatory variables yi∈1,2,…Gy_i\\{1,2,\\ldots G} represents class information =1,…ni=1,\\ldots n. first step optimize projection pursuit index find optimal one-dimension projection α*\\alpha^* separating classes current data. projected data redefine problem two class problem comparing means, assign new label G1G1 G2G2 observation, new variable yi*y_i^* created. new groups G1G1 G2G2 can contain one original classes. Next step find optimal one-dimensional projection α\\alpha, using (Xi,yi*)(X_i,y_i^*) separate two class problem G1G1 G2G2. best separation G1G1 G2G2 determine step decision rule defined current node, ∑=1pαiM1<c\\sum_{=1}^p \\alpha_i M1< c assign G1G1 left node else assign G2G2 right node, M1M1 mean G1G1. groups can repeat previous steps G1G1 G2G2 one class original classes. Base process grow tree, depth PPtree number classes one class assigned one final node. Trees PPtree algorithm simple, use association variables find separation. linear boundary exists, PPtree produces tree without misclassification. Projection pursuit random forest algorithm description Let N number cases training set Θ=(X,Y)\\Theta=(X,Y), BB bootstrap samples training set taking (samples size N replacement). bootstrap sample \\verb PPtree grown largest extent possible h(x,Θk)h(x, {\\Theta_k}). pruning. tree grown using step 3 modification. Let M number input variables, number m<<Mm<<M variables selected random node best split based linear combination randomly chosen variables. linear combination computed optimizing projection pursuit index, get projection variables best separates classes. Predict classes case included bootstrap sample compute oob error. Based majority vote predict class new data. ###Overview PPforest package PPforest package implements classification random forest using projection pursuit classification trees. following table present functions PPforest package. Also PPforest package includes data set used test predictive performance method. data sets included : crab, fishcatch, glass, image, leukemia, lymphoma NCI60, parkinson wine.","code":"install.package(PPforest) library(PPforest) library(devtools) install_github(\"natydasilva/PPforest\") library(PPforest)"},{"path":"https://github.com/natydasilva/PPforest/articles/PPforest-vignette.html","id":"example","dir":"Articles","previous_headings":"Introduction","what":"Example","title":"Projection pursuit classification random forest","text":"Australian crab data set used example. data contains measurements rock crabs genus Leptograpsus. 200 observations two species (blue orange) specie (50 one) 50 males 50 females. Class variable 4 classes combinations specie sex (BlueMale, BlueFemale, OrangeMale OrangeFemale). data collected site Fremantle, Western Australia. specimen, five measurements made, using vernier calipers. FL size frontal lobe length, mm RW rear width, mm CL length mid line carapace, mm CW maximum width carapace, mm BD depth body; females, measured displacement abdomen, mm visualize data set use scatterplot matrix package GGally     Scatter plot matrix crab data     figure can see strong, positive linear association different variables. Also look like classes can separated linear combinations. main function package PPforest implements projection pursuit random forest. PPtree_split function implements projection pursuit classification tree random variable selection split, based original PPtreeViz algorithm. function returns PPtreeclass object. use function need specify formula describing model fitted response~predictors (form), data data frame complete data set. Also need specify method PPmethod, index use projection pursuit: ‘LDA’ ‘PDA’, size.p proportion variables randomly sampled split. size.p = 1 classic PPtreeclass object fitted using variables node partition instead subset . lambda penalty parameter PDA index 0 1 . following example fits projection pursuit classification tree constructed using 0.6 variables (3 5) node split. selected LDA method. PPforest function runs projection pursuit random forest. arguments data frame data information, class name class variable argument. size.tr specify proportion observations using training. Using function option split data training test using size.tr directly. size.tr proportion data used training test proportion 1- size.tr. number trees forest specified using argument m. argument size.p sample proportion variables used node split, PPmethod projection pursuit index optimized, two options LDA PDA available. PPforest print summary result model confusion matrix information oob-error rate similar way randomForest packages . function returns predicted values training data, training error, test error predicted test values. Also information bag error forest also tree forest. Bootstrap samples, output trees forest , proximity matrix vote matrix, number trees grown forest, number predictor variables selected use splitting node. Confusion matrix prediction (based OOb data), training data test data vote matrix also returned. printed version PPforest object follows randomForest printed version make comparable. Based confusion matrix, can observe biggest error BlueMale class. wrong classified values BlueFemale BlueMale. output PPforest object contains lot information can see next output. example get predicted values test data can use PPforest output: new data available can use function trees_pred get predicted classes PPforest object. PPforest algorithm calculates variable importance two ways: (1) permuted importance using accuracy, (2) importance based projection coefficients standardized variables. permuted variable importance comparable measure defined classical random forest algorithm. computed using bag (oob) sample tree k(B(k))k\\;\\;(B^{(k)}) XjX_j predictor variable. permuted importance variable XjX_j tree kk can defined : IMP(k)(Xj)=∑∈B(k)(yi=ŷ(k))−(yi=ŷ,Pj(k))|B(k)| IMP^{(k)}(X_j) = \\frac{\\sum_{\\B^{(k)} } (y_i=\\hat y_i^{(k)})-(y_i=\\hat y_{,P_j}^{(k)})}{|B^{(k)}|} ŷ(k)\\hat y_i^{(k)} predicted class observation ii tree kk yi,Pj(k)y_{,P_j}^{(k)} predicted class observation ii tree kk permuting values variable XjX_j. global permuted importance measure average importance trees forest. measure based comparing accuracy classifying --bag observations, using true class permuted (nonsense) class. compute measure use permute_importance function.         Permuted importance variable     function returns data frame permuted importance measures, imp permuted importance measure defined Brieman paper, imp2 permuted importance measure defined randomForest package, standard deviation (sd.im sd.imp2) measure computed also standardized measure. second importance measure, coefficients projection examined. magnitude values indicates importance, variables standardized. variable importance single tree computed weighted sum absolute values coefficients across nodes. weights takes number classes node account (Lee et al. 2013). importance variable XjX_j PPtree kk can defined : IMPpptree(k)(Xj)=∑nd=1nn|αnd(k)|clnd   IMP_{pptree}^{(k)}(X_j)=\\sum_{nd = 1}^{nn}\\frac{|\\alpha_{nd}^{(k)}|}{cl_{nd} } αnd(k)\\alpha_{nd}^{(k)} projected coefficient node nsns variable kk nnnn total number node partitions tree kk. global variable importance PPforest can defined different ways. intuitive average variable importance PPtree across trees forest. IMPppforest1(Xj)=∑k=1KIMPpptree(k)(Xj)K IMP_{ppforest1}(X_j)=\\frac{\\sum_{k=1}^K IMP_{pptree}^{(k)}(X_j)}{K} Alternatively defined global importance measure forest weighted mean absolute value projection coefficients across nodes every tree. weights based projection pursuit indexes node (IxndIx_{nd}), 1-(OOB-error tree)(acckacc_k). IMPppforest2(Xj)=∑k=1Kacck∑nd=1nnIxnd|αnd(k)|nnKIMP_{ppforest2}(X_j)=\\frac{\\sum_{k=1}^K acc_k \\sum_{nd = 1}^{nn}\\frac{Ix_{nd}|\\alpha_{nd}^{(k)}|}{nn }}{K}          Average importance variable     Finally can get last importance measure proposed PPforest using `ppf_global_imp’ function.         Global importance variable Using information available PPforest object, visualization can done. include useful examples visualize data important diagnostics forest structure. describe data structure parallel plot can done, data standardized color represents class variable.     Parallel coordinate plot crab data     ternary_str auxiliary functions PPforest get data structure needed ternary plot generalized ternary plot 3 classes available. PPforest composed many tree fits subsets data, lot statistics can calculated analyze separate data set, better understand model working. diagnostics interest : variable importance, OOB error rate, vote matrix proximity matrix. decision tree can compute every pair observations proximity matrix. nxnnxn matrix two cases kik_i kjk_j terminal node increase proximity one, end normalize proximities dividing number trees. visualize proximity matrix use scatter plot information multidimensional scaling method. plot color indicates true species sex. data two dimensions enough see four groups separated quite well. crabs clearly similar different group, though, especially examining sex differences.     Multidimensional scaling plot examine similarities cases     vote matrix (n×pn \\times p) contains proportion times observation classified class, whole oob. Two possible approaches visualize vote matrix information shown, side--side jittered dot plot ternary plots. side--side jittered dotplot used display, class displayed one axis proportion displayed . dotplot, ideal arrangement points observations class values bigger 0.5, observations less. data close ideal perfect, e.g. blue male crabs (orange) frequently predicted blue females (green), blue female crabs predicted another class.     Vote matrix representation jittered side--side dotplot. dotplot shows proportion times case predicted group, 1 indicating case always predicted group 0 never.     ternary plot triangular diagram shows proportion three variables sum constant done using barycentric coordinates. Compositional data lies (p−1)(p-1)-D simplex pp-space. One advantage ternary plot good visualize compositional data proportion three variables two dimensional space can shown. tree classes ternary plot well defined. tree classes ternary plot idea need generalized.@sutherland2000orca suggest best approach visualize compositional data project data (p−1)−(p-1)-D space (ternary diagram 2−D2-D) approach used visualize vote matrix information. ternary plot triangular diagram used display compositional data three components. generally, compositional data can number components, say pp, hence contrained (p−1)(p-1)-D simplex pp-space. vote matrix example compositional data, GG components.     Generalized ternary plot representation vote matrix four classes. tetrahedron shown pairwise. point corresponds one observation color true class.     see complete description visualize PPforest object read Interactive Graphics Visually Diagnosing Forest Classifiers R (Silva, Cook, Lee 2017).","code":"Tree.crab <- PPforest::PPtree_split(\"Type~.\", data = crab, PPmethod = \"LDA\", size.p = 0.6)  Tree.crab ## =============================================================  ## Projection Pursuit Classification Tree result  ## ============================================================= ##  ## 1) root ##    2)  proj1*X < cut1 ##       4)* proj2*X < cut2  ->  \"2\" ##       5)* proj2*X >= cut2  ->  \"1\" ##    3)  proj1*X >= cut1 ##       6)* proj3*X < cut3  ->  \"4\" ##       7)* proj3*X >= cut3  ->  \"3\" ##  ## Error rates of various cutoff values  ## ------------------------------------------------------------- ##            Rule1 Rule2 Rule3 Rule4 Rule5 Rule6 Rule7 Rule8 ## error.rate 0.065 0.065 0.065 0.065 0.075 0.075 0.075 0.075 pprf.crab <- PPforest::PPforest(data = crab, class = \"Type\", size.tr = .8, m = 200,                                 size.p =  .5,  PPmethod = 'LDA',  parallel =FALSE, cores = 2)  pprf.crab ##  ## Call: ##  PPforest::PPforest(data = crab, class = \"Type\", size.tr = 0.8,      m = 200, PPmethod = \"LDA\", size.p = 0.5, parallel = FALSE,      cores = 2)  ##                Type of random forest: Classification ##                      Number of trees: 200 ## No. of variables tried at each split: 3 ##  ##         OOB estimate of  error rate: 4.37% ## Confusion matrix: ##              BlueFemale BlueMale OrangeFemale OrangeMale class.error ## BlueFemale           38        2            0          0        0.05 ## BlueMale              3       37            0          0        0.07 ## OrangeFemale          0        0           39          1        0.03 ## OrangeMale            0        1            0         39        0.03 str(pprf.crab, max.level = 1 ) ## List of 21 ##  $ predicting.training: Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 2 2 1 2 2 2 1 2 ... ##  $ training.error     : num 0.0375 ##  $ prediction.test    : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 1 2 2 2 2 2 2 2 ... ##  $ error.test         : num 0.15 ##  $ oob.error.forest   : num 0.0437 ##  $ oob.error.tree     : num [1:200, 1] 0.1695 0.2679 0.0317 0.1207 0.3273 ... ##  $ boot.samp          :List of 200 ##  $ output.trees       :List of 200 ##  $ proximity          : num [1:160, 1:160] 0 0.8 0.87 0.815 0.39 0.9 0.78 0.51 0.395 0.705 ... ##  $ votes              : num [1:160, 1:4] 0.222 0.333 0.191 0.222 0.661 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##  $ prediction.oob     : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 2 2 2 1 2 2 2 1 2 ... ##  $ n.tree             : num 200 ##  $ n.var              : int 3 ##  $ type               : chr \"Classification\" ##  $ confusion          : num [1:4, 1:5] 38 3 0 0 2 37 0 1 0 0 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##  $ call               : language PPforest::PPforest(data = crab, class = \"Type\", size.tr = 0.8, m = 200,      PPmethod = \"LDA\", size.p = 0.5, para| __truncated__ ##  $ train              :'data.frame': 160 obs. of  6 variables: ##  $ test               :'data.frame': 40 obs. of  5 variables: ##  $ vote.mat           : num [1:200, 1:160] 1 1 2 2 1 1 2 4 4 2 ... ##   ..- attr(*, \"dimnames\")=List of 2 ##  $ class.var          : chr \"Type\" ##  $ oob.obs            : num [1:200, 1:160] 0 1 1 0 0 0 0 1 1 1 ... ##  - attr(*, \"class\")= chr \"PPforest\" pprf.crab$prediction.test ##  [1] BlueMale     BlueMale     BlueFemale   BlueMale     BlueMale     ##  [6] BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     ## [11] BlueMale     BlueFemale   BlueFemale   BlueFemale   BlueFemale   ## [16] BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   ## [21] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   ## [26] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   ## [31] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeFemale ## [36] OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale ## Levels: BlueFemale BlueMale OrangeFemale OrangeMale trees_pred(pprf.crab, xnew = newdata, parallel = TRUE) impo1 <- permute_importance(pprf.crab) impo1 ##   nm    imp    sd.imp      imp2   sd.imp2 imp2.std  imp.std ## 1 CW 17.975  9.342418 0.3104134 0.1596670 1.944129 1.924020 ## 2 BD 18.470 10.632703 0.3199451 0.1844948 1.734169 1.737094 ## 3 CL 20.505 10.005023 0.3559586 0.1728535 2.059308 2.049471 ## 4 FL 20.805 11.036576 0.3594990 0.1874475 1.917865 1.885096 ## 5 RW 21.195  9.461213 0.3668738 0.1613988 2.273088 2.240199 impo2 <-  ppf_avg_imp(pprf.crab, \"Type\") impo2 ## # A tibble: 5 × 2 ##   variable  mean ##   <fct>    <dbl> ## 1 CL       0.462 ## 2 CW       0.452 ## 3 RW       0.385 ## 4 BD       0.313 ## 5 FL       0.279 impo3 <- ppf_global_imp(data = crab, class = \"Type\", pprf.crab) impo3 ## # A tibble: 5 × 2 ##   variable  mean ##   <fct>    <dbl> ## 1 CW       0.419 ## 2 CL       0.384 ## 3 RW       0.335 ## 4 BD       0.281 ## 5 FL       0.236"},{"path":[]},{"path":"https://github.com/natydasilva/PPforest/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Natalia da Silva. Author, maintainer. Dianne Cook. Author. Eun-Kyung Lee. Author.","code":""},{"path":"https://github.com/natydasilva/PPforest/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"da Silva N, Cook D, Lee E (2025). PPforest: Projection Pursuit Classification Forest. R package version 0.1.3, https://github.com/natydasilva/PPforest.","code":"@Manual{,   title = {PPforest: Projection Pursuit Classification Forest},   author = {Natalia {da Silva} and Dianne Cook and Eun-Kyung Lee},   year = {2025},   note = {R package version 0.1.3},   url = {https://github.com/natydasilva/PPforest}, }"},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"ppforest-package","dir":"","previous_headings":"","what":"Projection Pursuit Classification Forest","title":"Projection Pursuit Classification Forest","text":"Natalia da Silva, Dianne Cook & Eun-Kyung Lee","code":""},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Projection Pursuit Classification Forest","text":"PPforest package (projection pursuit random forest) contains functions run projection pursuit random forest classification problems. method utilize combinations variables tree construction. random forest split based single variable, chosen subset predictors. PPforest, split based linear combination randomly chosen variables. linear combination computed optimizing projection pursuit index, get projection variables best separates classes. PPforest uses PPtree algorithm, fits single tree data. Utilizing linear combinations variables separate classes takes correlation variables account, can outperform basic forest separations groups occurs combinations variables. Two projection pursuit indexes, LDA PDA, used PPforest. improve speed performance PPforest package, PPtree algorithm translated Rcpp. PPforest package utilizes number R packages included “suggests” load package start-. development version ofPPforest can installed github using:","code":"library(devtools) install_github(\"natydasilva/PPforest\") library(PPforest)"},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"overview-ppforest-package","dir":"","previous_headings":"","what":"Overview PPforest package","title":"Projection Pursuit Classification Forest","text":"PPforest package implements classification random forest using projection pursuit classification trees. following table present functions PPforest package. Also PPforest package includes data set used test predictive performance method. data sets included : crab, fishcatch, glass, image, leukemia, lymphoma NCI60, parkinson wine.","code":""},{"path":"https://github.com/natydasilva/PPforest/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Projection Pursuit Classification Forest","text":"Australian crab data set used example. data contains measurements rock crabs genus Leptograpsus. 200 observations two species (blue orange) specie (50 one) 50 males 50 females. Class variable 4 classes combinations specie sex (BlueMale, BlueFemale, OrangeMale OrangeFemale). data collected site Fremantle, Western Australia. specimen, five measurements made, using vernier calipers. FL size frontal lobe length, mm RW rear width, mm CL length mid line carapace, mm CW maximum width carapace, mm BD depth body; females, measured displacement abdomen, mm PPforest function runs projection pursuit random forest. arguments data frame data information, class name class variable argument. size.tr specify proportion observations using training. Using function option split data training test using size.tr directly. size.tr proportion data used training test proportion 1- size.tr. number trees forest specified using argument m. argument size.p sample proportion variables used node split, PPmethod projection pursuit index optimized, two options LDA PDA available. PPforest print summary result model confusion matrix information oob-error rate similar way randomForest packages . function returns predicted values training data, training error, test error predicted test values. Also information bag error forest also tree forest. Bootstrap samples, output trees forest , proximity matrix vote matrix, number trees grown forest, number predictor variables selected use splitting node. Confusion matrix prediction (based OOb data), training data test data vote matrix also returned. printed version PPforest object follows randomForest printed version make comparable. Based confusion matrix, can observe biggest error BlueMale class. wrong classified values BlueFemale BlueMale. PPforest object can used predict new data using predict function. predicted values returned factor class levels.","code":"pprf.crab <- PPforest::PPforest(data = crab, class = \"Type\", size.tr = 0.7, m = 200,                                 size.p =  .5,  PPmethod = 'LDA',  parallel =TRUE, cores = 2)  pprf.crab  Call:  PPforest::PPforest(data = crab, class = \"Type\", size.tr = 0.7,      m = 200, PPmethod = \"LDA\", size.p = 0.5, parallel = TRUE,      cores = 2)                 Type of random forest: Classification                      Number of trees: 200 No. of variables tried at each split: 3          OOB estimate of  error rate: 4.29% Confusion matrix:              BlueFemale BlueMale OrangeFemale OrangeMale class.error BlueFemale           35        0            0          0        0.00 BlueMale              3       32            0          0        0.09 OrangeFemale          0        0           32          3        0.09 OrangeMale            0        0            0         35        0.00 str(pprf.crab, max.level = 1) List of 22  $ predicting.training: Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 1 2 2 2 2 1 2 1 2 ...  $ training.error     : num 0.0429  $ prediction.test    : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 1 2 2 2 1 2 2 2 1 2 ...  $ error.test         : num 0.05  $ oob.error.forest   : num 0.0429  $ oob.error.tree     : num [1:200, 1] 0.3158 0.1404 0.16 0.102 0.0769 ...  $ boot.samp          :List of 200  $ output.trees       :List of 200  $ proximity          : num [1:140, 1:140] 0 0.68 0.855 0.845 0.785 0.87 0.35 0.71 0.395 0.48 ...  $ votes              : num [1:140, 1:4] 0.415 0.802 0.481 0.191 0.2 ...   ..- attr(*, \"dimnames\")=List of 2  $ prediction.oob     : Factor w/ 4 levels \"BlueFemale\",\"BlueMale\",..: 2 1 2 2 2 2 1 2 1 2 ...  $ n.tree             : num 200  $ n.var              : int 3  $ type               : chr \"Classification\"  $ confusion          : num [1:4, 1:5] 35 3 0 0 0 32 0 0 0 0 ...   ..- attr(*, \"dimnames\")=List of 2  $ call               : language PPforest::PPforest(data = crab, class = \"Type\", size.tr = 0.7, m = 200, PPmethod = \"LDA\",      size.p = 0.5, para| __truncated__  $ train              :'data.frame':    140 obs. of  6 variables:  $ test               :'data.frame':    60 obs. of  5 variables:  $ vote.mat           : num [1:200, 1:140] 1 1 2 2 2 2 1 2 1 1 ...   ..- attr(*, \"dimnames\")=List of 2  $ vote.mat_cl        : chr [1:4] \"BlueFemale\" \"BlueMale\" \"OrangeFemale\" \"OrangeMale\"  $ class.var          : chr \"Type\"  $ oob.obs            : num [1:200, 1:140] 0 1 1 0 1 0 0 0 0 1 ...  - attr(*, \"class\")= chr \"PPforest\" pred.crab <- predict(pprf.crab, newdata = crab[1:10,-1 ])  pred.crab[[3]]   [1] BlueFemale BlueFemale BlueFemale BlueFemale BlueFemale BlueFemale BlueFemale BlueFemale  [9] BlueFemale BlueFemale   Levels: BlueFemale BlueMale OrangeFemale OrangeMale"},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":null,"dir":"Reference","previous_headings":"","what":"NCI60 data set — NCI60","title":"NCI60 data set — NCI60","text":"cDNA microarrays used examine variation gene expression among 60 cell lines.  cell lines derived tumors different sites origin. data set contain 61 observations 30 feature variables 8 different tissue types. Type 8 different tissue types, 9 cases breast, 5 cases central nervous system (CNS), 7 cases pf colon, 8 cases leukemia, 8 cases melanoma, 9 cases  non-small-cell lung carcinoma (NSCLC), 6 cases ovarian 9 cases renal. Gene1 Gen 30 gene expression information","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NCI60 data set — NCI60","text":"","code":"data(NCI60)"},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"NCI60 data set — NCI60","text":"data frame 61 rows 31 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/NCI60.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"NCI60 data set — NCI60","text":"Dudoit, S., Fridlyand, J. Speed, T. P. (2002). Comparison Discrimination Methods Classification Tumors Using Gene Expression Data. Journal American statistical Association 97 77-87.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"Predict class test set calculate prediction error finding PPtree structure, .","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"","code":"PPclassify( Tree.result, test.data = NULL, Rule = 1, true.class = NULL)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"Tree.result result PP.Tree test.data test dataset Rule split rule 1:mean two group means, 2:weighted mean, 3: mean max(left group) min(right group), 4: weighted mean max(left group) min(right group) true.class true class test dataset available","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"predict.class predicted class predict.error prediction error","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"Lee, YD, Cook, D., Park JW, Lee, EK(2013) PPtree: Projection pursuit classification tree, Electronic Journal Statistics, 7:1369-1386.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify","text":"","code":"#crab data set set.seed(143) idx <-sample(1:200, 150) Tree.crab <- PPtree_split('Type~.', data = crab[idx,], PPmethod = 'LDA', size.p = 1) Tree.crab #> $Tree.Struct #>      id L.node.ID R.F.node.ID Coef.ID     Index #> [1,]  1         2           3       1 0.8795096 #> [2,]  2         4           5       2 0.7606543 #> [3,]  3         6           7       3 0.8381403 #> [4,]  4         0           2       0 0.0000000 #> [5,]  5         0           1       0 0.0000000 #> [6,]  6         0           4       0 0.0000000 #> [7,]  7         0           3       0 0.0000000 #>  #> $projbest.node #>           [,1]       [,2]       [,3]       [,4]       [,5] #> [1,] 0.6221931 0.04545035  0.1615019 -0.5949674  0.4803551 #> [2,] 0.4234606 0.80544215 -0.3837714 -0.1149470  0.1070084 #> [3,] 0.0780935 0.80140034 -0.4893062  0.2586300 -0.2129528 #>  #> $splitCutoff.node #>       Rule1     Rule2    Rule3     Rule4    Rule5     Rule6    Rule7     Rule8 #> 1 0.5431429 0.5838904 0.409899 0.3899181 0.536802 0.5756544 0.344993 0.3263904 #> 2 1.3486145 1.3091564 1.421485 1.4410025 1.373320 1.3358879 1.462184 1.4805776 #> 3 2.0242023 1.9959521 1.875268 1.8891210 2.075108 2.0469258 2.026585 2.0406553 #>  #> $origclass #>          120            6          180          168          129          140  #>   OrangeMale     BlueMale OrangeFemale OrangeFemale   OrangeMale   OrangeMale  #>          150           65          136          105          146          171  #>   OrangeMale   BlueFemale   OrangeMale   OrangeMale   OrangeMale OrangeFemale  #>          172           38           51          200           84          181  #> OrangeFemale     BlueMale   BlueFemale OrangeFemale   BlueFemale OrangeFemale  #>           18          167          107          165           79           21  #>     BlueMale OrangeFemale   OrangeMale OrangeFemale   BlueFemale     BlueMale  #>           71           43           55           39          137          141  #>   BlueFemale     BlueMale   BlueFemale     BlueMale   OrangeMale   OrangeMale  #>          176           81          174           46           25          138  #> OrangeFemale   BlueFemale OrangeFemale     BlueMale     BlueMale   OrangeMale  #>           83           99          173          186          198           14  #>   BlueFemale   BlueFemale OrangeFemale OrangeFemale OrangeFemale     BlueMale  #>           37           90          189           44           70           11  #>     BlueMale   BlueFemale OrangeFemale     BlueMale   BlueFemale     BlueMale  #>          151           87           69          190          159            4  #> OrangeFemale   BlueFemale   BlueFemale OrangeFemale OrangeFemale     BlueMale  #>          109          104           82          122          118          121  #>   OrangeMale   OrangeMale   BlueFemale   OrangeMale   OrangeMale   OrangeMale  #>           86           12          161           34          132           91  #>   BlueFemale     BlueMale OrangeFemale     BlueMale   OrangeMale   BlueFemale  #>          114           49           26          170            8           42  #>   OrangeMale     BlueMale     BlueMale OrangeFemale     BlueMale     BlueMale  #>           64          179          160          100           48          187  #>   BlueFemale OrangeFemale OrangeFemale   BlueFemale     BlueMale OrangeFemale  #>           94          156          197           89           93            3  #>   BlueFemale OrangeFemale OrangeFemale   BlueFemale   BlueFemale     BlueMale  #>          155           63          178          177          185           47  #> OrangeFemale   BlueFemale OrangeFemale OrangeFemale OrangeFemale     BlueMale  #>            1          182           97          112          123          119  #>     BlueMale OrangeFemale   BlueFemale   OrangeMale   OrangeMale   OrangeMale  #>           72          154           30          133          128          192  #>   BlueFemale OrangeFemale     BlueMale   OrangeMale   OrangeMale OrangeFemale  #>           13           23          164           96          194           17  #>     BlueMale     BlueMale OrangeFemale   BlueFemale OrangeFemale     BlueMale  #>           27           62           35          117           59           53  #>     BlueMale   BlueFemale     BlueMale   OrangeMale   BlueFemale   BlueFemale  #>          103          124          135           19          113           52  #>   OrangeMale   OrangeMale   OrangeMale     BlueMale   OrangeMale   BlueFemale  #>           85            9           31           41           78           88  #>   BlueFemale     BlueMale     BlueMale     BlueMale   BlueFemale   BlueFemale  #>           75           74          144          110           57           33  #>   BlueFemale   BlueFemale   OrangeMale   OrangeMale   BlueFemale     BlueMale  #>           50           60          152          193          158           73  #>     BlueMale   BlueFemale OrangeFemale OrangeFemale OrangeFemale   BlueFemale  #>            5          169          139           56          143          148  #>     BlueMale OrangeFemale   OrangeMale   BlueFemale   OrangeMale   OrangeMale  #>          131          149           67           80           66           32  #>   OrangeMale   OrangeMale   BlueFemale   BlueFemale   BlueFemale     BlueMale  #> Levels: BlueFemale BlueMale OrangeFemale OrangeMale #>  #> $origclass_num #>   [1] 4 2 3 3 4 4 4 1 4 4 4 3 3 2 1 3 1 3 2 3 4 3 1 2 1 2 1 2 4 4 3 1 3 2 2 4 1 #>  [38] 1 3 3 3 2 2 1 3 2 1 2 3 1 1 3 3 2 4 4 1 4 4 4 1 2 3 2 4 1 4 2 2 3 2 2 1 3 #>  [75] 3 1 2 3 1 3 3 1 1 2 3 1 3 3 3 2 2 3 1 4 4 4 1 3 2 4 4 3 2 2 3 1 3 2 2 1 2 #> [112] 4 1 1 4 4 4 2 4 1 1 2 2 2 1 1 1 1 4 4 1 2 2 1 3 3 3 1 2 3 4 1 4 4 4 4 1 1 #> [149] 1 2 #>  #> $origdata #>       FL   RW   CL   CW   BD #> 120 15.1 11.4 30.2 33.3 14.0 #> 6   10.8  9.0 23.0 26.5  9.8 #> 180 18.5 14.6 37.0 42.0 16.6 #> 168 16.2 14.0 31.6 35.6 13.7 #> 129 17.5 12.7 34.6 38.4 16.1 #> 140 19.4 14.4 39.8 44.3 17.9 #> 150 23.1 15.7 47.6 52.8 21.6 #> 65  11.6 11.4 23.7 27.7 10.0 #> 136 18.6 13.5 36.9 40.2 17.0 #> 105 12.5  9.4 23.2 26.0 10.8 #> 146 21.6 14.8 43.4 48.2 20.1 #> 171 17.5 14.3 34.5 39.6 15.6 #> 172 17.5 14.4 34.5 39.0 16.0 #> 38  17.1 12.6 36.4 42.0 15.1 #> 51   7.2  6.5 14.7 17.1  6.1 #> 200 23.1 20.2 46.2 52.5 21.1 #> 84  15.1 13.3 31.8 36.3 13.5 #> 181 18.6 14.5 34.7 39.4 15.0 #> 18  13.1 10.9 28.3 32.4 11.2 #> 167 16.1 13.7 31.4 36.1 13.9 #> 107 12.7 10.4 26.0 28.8 12.1 #> 165 15.7 13.6 31.0 34.8 13.8 #> 79  13.9 13.0 30.0 34.9 13.1 #> 21  14.3 11.6 31.3 35.5 12.7 #> 71  12.8 11.7 27.1 31.2 11.9 #> 43  18.0 13.7 39.2 44.4 16.2 #> 55   9.5  8.2 19.6 22.4  7.8 #> 39  17.1 12.7 36.7 41.9 15.6 #> 137 18.8 13.4 37.2 41.1 17.5 #> 141 20.1 13.7 40.6 44.5 18.0 #> 176 18.0 16.3 37.9 43.0 17.2 #> 81  14.9 13.2 30.1 35.6 12.0 #> 174 17.6 14.0 34.0 38.6 15.5 #> 46  19.3 13.8 40.9 46.5 16.8 #> 25  15.0 11.9 32.5 37.2 13.6 #> 138 18.8 13.8 39.2 43.3 17.9 #> 83  15.0 14.2 32.8 37.4 14.0 #> 99  17.5 16.7 38.6 44.5 17.0 #> 173 17.5 14.7 33.3 37.6 14.6 #> 186 19.7 16.7 39.9 43.6 18.2 #> 198 21.9 17.2 42.6 47.4 19.5 #> 14  12.8 10.2 27.2 31.8 10.9 #> 37  16.9 13.2 37.3 42.7 15.6 #> 90  15.5 13.8 33.4 38.7 14.7 #> 189 20.0 16.7 40.4 45.1 17.7 #> 44  18.8 15.8 42.1 49.0 17.8 #> 70  12.6 12.2 26.1 31.6 11.2 #> 11  12.2 10.8 27.3 31.6 10.9 #> 151 10.7  9.7 21.4 24.0  9.8 #> 87  15.2 14.3 33.9 38.5 14.7 #> 69  12.0 11.1 25.4 29.2 11.0 #> 190 20.1 17.2 39.8 44.1 18.6 #> 159 14.7 13.2 29.6 33.4 12.9 #> 4    9.6  7.9 20.1 23.1  8.2 #> 109 13.4 10.1 26.6 29.6 12.0 #> 104 11.4  9.0 22.7 24.8 10.1 #> 82  15.0 13.8 31.7 36.9 14.0 #> 122 15.4 11.1 30.2 33.6 13.5 #> 118 14.6 11.3 29.9 33.5 12.8 #> 121 15.1 11.5 30.9 34.0 13.9 #> 86  15.1 13.8 31.7 36.6 13.0 #> 12  12.3 11.0 26.8 31.5 11.4 #> 161 15.0 12.3 30.1 33.3 14.0 #> 34  16.4 13.0 35.7 41.8 15.2 #> 132 18.0 13.4 36.7 41.3 17.1 #> 91  15.6 13.9 32.8 37.9 13.4 #> 114 14.1 10.7 28.7 31.9 13.3 #> 49  19.8 14.3 42.4 48.9 18.3 #> 26  15.2 12.1 32.3 36.7 13.6 #> 170 17.1 14.5 33.1 37.2 14.6 #> 8   11.6  9.1 24.5 28.4 10.4 #> 42  17.9 14.1 39.7 44.6 16.8 #> 64  11.6 11.0 24.6 28.5 10.4 #> 179 18.4 15.7 36.5 41.6 16.4 #> 160 14.9 13.0 30.0 33.7 13.3 #> 100 19.2 16.5 40.9 47.9 18.1 #> 48  19.8 14.2 43.2 49.7 18.6 #> 187 19.9 16.6 39.4 43.9 17.9 #> 94  15.8 15.0 34.5 40.3 15.3 #> 156 14.0 11.9 27.0 31.4 12.6 #> 197 21.7 17.1 41.7 47.2 19.6 #> 89  15.4 13.3 32.4 37.6 13.8 #> 93  15.7 13.9 33.6 38.5 14.1 #> 3    9.2  7.8 19.0 22.4  7.7 #> 155 12.9 11.2 25.8 29.1 11.9 #> 63  11.5 11.0 24.7 29.2 10.1 #> 178 18.4 15.5 35.6 40.0 15.9 #> 177 18.3 15.7 35.1 40.5 16.1 #> 185 19.1 16.3 37.9 42.6 17.2 #> 47  19.7 15.3 41.9 48.5 17.8 #> 1    8.1  6.7 16.1 19.0  7.0 #> 182 18.8 15.2 35.8 40.5 16.6 #> 97  16.7 16.1 36.6 41.9 15.4 #> 112 14.1 10.4 28.9 31.8 13.5 #> 123 15.7 12.2 31.7 34.2 14.2 #> 119 14.7 11.1 29.0 32.1 13.1 #> 72  12.8 12.2 26.7 31.1 11.1 #> 154 12.6 11.5 25.0 28.1 11.5 #> 30  16.1 11.6 33.8 39.0 14.4 #> 133 18.2 13.7 38.8 42.7 17.2 #> 128 17.5 12.0 34.4 37.3 15.3 #> 192 20.5 17.5 40.0 45.5 19.2 #> 13  12.6 10.0 27.7 31.7 11.4 #> 23  15.0 10.9 31.4 36.4 13.2 #> 164 15.6 14.1 31.0 34.5 13.8 #> 96  16.4 14.0 34.2 39.8 15.2 #> 194 20.9 16.5 39.9 44.7 17.5 #> 17  13.1 10.6 28.2 32.3 11.0 #> 27  15.4 11.8 33.0 37.5 13.6 #> 62  11.2 10.0 22.8 26.9  9.4 #> 35  16.6 13.5 38.1 43.4 14.9 #> 117 14.2 11.3 29.2 32.2 13.5 #> 59  10.4  9.7 21.7 25.4  8.3 #> 53   9.1  8.1 18.5 21.6  7.7 #> 103 10.7  8.6 20.7 22.7  9.2 #> 124 16.2 11.8 32.3 35.3 14.7 #> 135 18.6 13.4 37.8 41.9 17.3 #> 19  13.3 11.1 27.8 32.3 11.3 #> 113 14.1 10.5 29.1 31.6 13.1 #> 52   9.0  8.5 19.3 22.7  7.7 #> 85  15.1 13.5 31.9 37.0 13.8 #> 9   11.8  9.6 24.2 27.8  9.7 #> 31  16.1 12.8 34.9 40.7 15.7 #> 41  17.7 13.6 38.7 44.5 16.0 #> 78  13.7 12.5 28.6 33.8 11.9 #> 88  15.3 14.2 32.6 38.3 13.8 #> 75  13.1 11.5 27.6 32.6 11.1 #> 74  13.0 11.4 27.3 31.8 11.3 #> 144 21.5 15.5 45.5 49.7 20.9 #> 110 13.7 11.0 27.5 30.5 12.2 #> 57  10.1  9.3 20.9 24.4  8.4 #> 33  16.3 12.7 35.6 40.9 14.9 #> 50  21.3 15.7 47.1 54.6 20.0 #> 60  10.8  9.5 22.5 26.3  9.1 #> 152 11.4  9.2 21.7 24.1  9.7 #> 193 20.6 17.5 41.5 46.2 19.2 #> 158 14.3 12.2 28.1 31.8 12.5 #> 73  12.8 12.2 27.9 31.9 11.5 #> 5    9.8  8.0 20.3 23.0  8.2 #> 169 16.7 14.3 32.3 37.0 14.7 #> 139 19.4 14.1 39.1 43.2 17.8 #> 56   9.8  8.9 20.4 23.9  8.8 #> 143 21.0 15.0 42.9 47.2 19.4 #> 148 22.1 15.8 44.6 49.6 20.5 #> 131 17.9 12.9 36.9 40.9 16.5 #> 149 23.0 16.8 47.2 52.1 21.5 #> 67  11.9 11.4 26.0 30.1 10.9 #> 80  14.7 12.5 30.1 34.7 12.5 #> 66  11.7 10.6 24.9 28.5 10.4 #> 32  16.2 13.3 36.0 41.7 15.4 #>  #> attr(,\"class\") #> [1] \"list\"         \"PPtree_split\" PPclassify(Tree.crab, test.data = crab[-idx, 2:6], Rule = 1,true.class = crab[-idx, 1]) #> $predict.error #> [1] 0.1 #>  #> $predict.class #>  [1] BlueFemale   BlueFemale   BlueFemale   BlueMale     BlueFemale   #>  [6] BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     #> [11] BlueMale     BlueMale     BlueMale     BlueFemale   BlueFemale   #> [16] BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   #> [21] BlueFemale   BlueFemale   OrangeMale   OrangeMale   OrangeMale   #> [26] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   #> [31] OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   #> [36] OrangeMale   OrangeMale   OrangeMale   OrangeFemale OrangeFemale #> [41] OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale #> [46] OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale #> Levels: BlueFemale BlueMale OrangeFemale OrangeMale #>"},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"Predict class test set calculate prediction error finding PPtree structure, .","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"","code":"PPclassify2( Tree.result, test.data = NULL, Rule = 1, true.class = NULL)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"Tree.result result PP.Tree test.data test dataset Rule split rule 1:mean two group means, 2:weighted mean, 3: mean max(left group) min(right group), 4: weighted mean max(left group) min(right group) true.class true class test dataset available","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"predict.class predicted class predict.error prediction error","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"Lee, YD, Cook, D., Park JW, Lee, EK(2013) PPtree: Projection pursuit classification tree, Electronic Journal Statistics, 7:1369-1386.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPclassify2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict class for the test set and calculate prediction error after finding the PPtree structure, . — PPclassify2","text":"","code":"#crab data set  Tree.crab <- PPtree_split('Type~.', data = crab, PPmethod = 'LDA', size.p = 0.5) Tree.crab #> $Tree.Struct #>      id L.node.ID R.F.node.ID Coef.ID     Index #> [1,]  1         2           3       1 0.8696281 #> [2,]  2         4           5       2 0.7106348 #> [3,]  3         6           7       3 0.8183021 #> [4,]  4         0           2       0 0.0000000 #> [5,]  5         0           1       0 0.0000000 #> [6,]  6         0           4       0 0.0000000 #> [7,]  7         0           3       0 0.0000000 #>  #> $projbest.node #>           [,1]      [,2]       [,3]       [,4]      [,5] #> [1,] 0.6702113 0.0000000  0.0000000 -0.4901992 0.5572447 #> [2,] 0.4102387 0.7901918 -0.4553033  0.0000000 0.0000000 #> [3,] 0.0000000 0.8647947 -0.4711478  0.1736371 0.0000000 #>  #> $splitCutoff.node #>       Rule1     Rule2    Rule3    Rule4     Rule5     Rule6     Rule7     Rule8 #> 1 0.4119657 0.4119657 0.262617 0.262617 0.4291882 0.4291882 0.2647079 0.2647079 #> 2 1.5062172 1.5062172 1.588110 1.588110 1.4780090 1.4780090 1.5739142 1.5739142 #> 3 2.2436484 2.2436484 2.030341 2.030341 2.2778575 2.2778575 2.1885841 2.1885841 #>  #> $origclass #>   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 #> [112] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 #> [149] 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [186] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  #> $origdata #>          FL   RW   CL   CW   BD #>   [1,]  8.1  6.7 16.1 19.0  7.0 #>   [2,]  8.8  7.7 18.1 20.8  7.4 #>   [3,]  9.2  7.8 19.0 22.4  7.7 #>   [4,]  9.6  7.9 20.1 23.1  8.2 #>   [5,]  9.8  8.0 20.3 23.0  8.2 #>   [6,] 10.8  9.0 23.0 26.5  9.8 #>   [7,] 11.1  9.9 23.8 27.1  9.8 #>   [8,] 11.6  9.1 24.5 28.4 10.4 #>   [9,] 11.8  9.6 24.2 27.8  9.7 #>  [10,] 11.8 10.5 25.2 29.3 10.3 #>  [11,] 12.2 10.8 27.3 31.6 10.9 #>  [12,] 12.3 11.0 26.8 31.5 11.4 #>  [13,] 12.6 10.0 27.7 31.7 11.4 #>  [14,] 12.8 10.2 27.2 31.8 10.9 #>  [15,] 12.8 10.9 27.4 31.5 11.0 #>  [16,] 12.9 11.0 26.8 30.9 11.4 #>  [17,] 13.1 10.6 28.2 32.3 11.0 #>  [18,] 13.1 10.9 28.3 32.4 11.2 #>  [19,] 13.3 11.1 27.8 32.3 11.3 #>  [20,] 13.9 11.1 29.2 33.3 12.1 #>  [21,] 14.3 11.6 31.3 35.5 12.7 #>  [22,] 14.6 11.3 31.9 36.4 13.7 #>  [23,] 15.0 10.9 31.4 36.4 13.2 #>  [24,] 15.0 11.5 32.4 37.0 13.4 #>  [25,] 15.0 11.9 32.5 37.2 13.6 #>  [26,] 15.2 12.1 32.3 36.7 13.6 #>  [27,] 15.4 11.8 33.0 37.5 13.6 #>  [28,] 15.7 12.6 35.8 40.3 14.5 #>  [29,] 15.9 12.7 34.0 38.9 14.2 #>  [30,] 16.1 11.6 33.8 39.0 14.4 #>  [31,] 16.1 12.8 34.9 40.7 15.7 #>  [32,] 16.2 13.3 36.0 41.7 15.4 #>  [33,] 16.3 12.7 35.6 40.9 14.9 #>  [34,] 16.4 13.0 35.7 41.8 15.2 #>  [35,] 16.6 13.5 38.1 43.4 14.9 #>  [36,] 16.8 12.8 36.2 41.8 14.9 #>  [37,] 16.9 13.2 37.3 42.7 15.6 #>  [38,] 17.1 12.6 36.4 42.0 15.1 #>  [39,] 17.1 12.7 36.7 41.9 15.6 #>  [40,] 17.2 13.5 37.6 43.9 16.1 #>  [41,] 17.7 13.6 38.7 44.5 16.0 #>  [42,] 17.9 14.1 39.7 44.6 16.8 #>  [43,] 18.0 13.7 39.2 44.4 16.2 #>  [44,] 18.8 15.8 42.1 49.0 17.8 #>  [45,] 19.3 13.5 41.6 47.4 17.8 #>  [46,] 19.3 13.8 40.9 46.5 16.8 #>  [47,] 19.7 15.3 41.9 48.5 17.8 #>  [48,] 19.8 14.2 43.2 49.7 18.6 #>  [49,] 19.8 14.3 42.4 48.9 18.3 #>  [50,] 21.3 15.7 47.1 54.6 20.0 #>  [51,]  7.2  6.5 14.7 17.1  6.1 #>  [52,]  9.0  8.5 19.3 22.7  7.7 #>  [53,]  9.1  8.1 18.5 21.6  7.7 #>  [54,]  9.1  8.2 19.2 22.2  7.7 #>  [55,]  9.5  8.2 19.6 22.4  7.8 #>  [56,]  9.8  8.9 20.4 23.9  8.8 #>  [57,] 10.1  9.3 20.9 24.4  8.4 #>  [58,] 10.3  9.5 21.3 24.7  8.9 #>  [59,] 10.4  9.7 21.7 25.4  8.3 #>  [60,] 10.8  9.5 22.5 26.3  9.1 #>  [61,] 11.0  9.8 22.5 25.7  8.2 #>  [62,] 11.2 10.0 22.8 26.9  9.4 #>  [63,] 11.5 11.0 24.7 29.2 10.1 #>  [64,] 11.6 11.0 24.6 28.5 10.4 #>  [65,] 11.6 11.4 23.7 27.7 10.0 #>  [66,] 11.7 10.6 24.9 28.5 10.4 #>  [67,] 11.9 11.4 26.0 30.1 10.9 #>  [68,] 12.0 10.7 24.6 28.9 10.5 #>  [69,] 12.0 11.1 25.4 29.2 11.0 #>  [70,] 12.6 12.2 26.1 31.6 11.2 #>  [71,] 12.8 11.7 27.1 31.2 11.9 #>  [72,] 12.8 12.2 26.7 31.1 11.1 #>  [73,] 12.8 12.2 27.9 31.9 11.5 #>  [74,] 13.0 11.4 27.3 31.8 11.3 #>  [75,] 13.1 11.5 27.6 32.6 11.1 #>  [76,] 13.2 12.2 27.9 32.1 11.5 #>  [77,] 13.4 11.8 28.4 32.7 11.7 #>  [78,] 13.7 12.5 28.6 33.8 11.9 #>  [79,] 13.9 13.0 30.0 34.9 13.1 #>  [80,] 14.7 12.5 30.1 34.7 12.5 #>  [81,] 14.9 13.2 30.1 35.6 12.0 #>  [82,] 15.0 13.8 31.7 36.9 14.0 #>  [83,] 15.0 14.2 32.8 37.4 14.0 #>  [84,] 15.1 13.3 31.8 36.3 13.5 #>  [85,] 15.1 13.5 31.9 37.0 13.8 #>  [86,] 15.1 13.8 31.7 36.6 13.0 #>  [87,] 15.2 14.3 33.9 38.5 14.7 #>  [88,] 15.3 14.2 32.6 38.3 13.8 #>  [89,] 15.4 13.3 32.4 37.6 13.8 #>  [90,] 15.5 13.8 33.4 38.7 14.7 #>  [91,] 15.6 13.9 32.8 37.9 13.4 #>  [92,] 15.6 14.7 33.9 39.5 14.3 #>  [93,] 15.7 13.9 33.6 38.5 14.1 #>  [94,] 15.8 15.0 34.5 40.3 15.3 #>  [95,] 16.2 15.2 34.5 40.1 13.9 #>  [96,] 16.4 14.0 34.2 39.8 15.2 #>  [97,] 16.7 16.1 36.6 41.9 15.4 #>  [98,] 17.4 16.9 38.2 44.1 16.6 #>  [99,] 17.5 16.7 38.6 44.5 17.0 #> [100,] 19.2 16.5 40.9 47.9 18.1 #> [101,]  9.1  6.9 16.7 18.6  7.4 #> [102,] 10.2  8.2 20.2 22.2  9.0 #> [103,] 10.7  8.6 20.7 22.7  9.2 #> [104,] 11.4  9.0 22.7 24.8 10.1 #> [105,] 12.5  9.4 23.2 26.0 10.8 #> [106,] 12.5  9.4 24.2 27.0 11.2 #> [107,] 12.7 10.4 26.0 28.8 12.1 #> [108,] 13.2 11.0 27.1 30.4 12.2 #> [109,] 13.4 10.1 26.6 29.6 12.0 #> [110,] 13.7 11.0 27.5 30.5 12.2 #> [111,] 14.0 11.5 29.2 32.2 13.1 #> [112,] 14.1 10.4 28.9 31.8 13.5 #> [113,] 14.1 10.5 29.1 31.6 13.1 #> [114,] 14.1 10.7 28.7 31.9 13.3 #> [115,] 14.2 10.6 28.7 31.7 12.9 #> [116,] 14.2 10.7 27.8 30.9 12.7 #> [117,] 14.2 11.3 29.2 32.2 13.5 #> [118,] 14.6 11.3 29.9 33.5 12.8 #> [119,] 14.7 11.1 29.0 32.1 13.1 #> [120,] 15.1 11.4 30.2 33.3 14.0 #> [121,] 15.1 11.5 30.9 34.0 13.9 #> [122,] 15.4 11.1 30.2 33.6 13.5 #> [123,] 15.7 12.2 31.7 34.2 14.2 #> [124,] 16.2 11.8 32.3 35.3 14.7 #> [125,] 16.3 11.6 31.6 34.2 14.5 #> [126,] 17.1 12.6 35.0 38.9 15.7 #> [127,] 17.4 12.8 36.1 39.5 16.2 #> [128,] 17.5 12.0 34.4 37.3 15.3 #> [129,] 17.5 12.7 34.6 38.4 16.1 #> [130,] 17.8 12.5 36.0 39.8 16.7 #> [131,] 17.9 12.9 36.9 40.9 16.5 #> [132,] 18.0 13.4 36.7 41.3 17.1 #> [133,] 18.2 13.7 38.8 42.7 17.2 #> [134,] 18.4 13.4 37.9 42.2 17.7 #> [135,] 18.6 13.4 37.8 41.9 17.3 #> [136,] 18.6 13.5 36.9 40.2 17.0 #> [137,] 18.8 13.4 37.2 41.1 17.5 #> [138,] 18.8 13.8 39.2 43.3 17.9 #> [139,] 19.4 14.1 39.1 43.2 17.8 #> [140,] 19.4 14.4 39.8 44.3 17.9 #> [141,] 20.1 13.7 40.6 44.5 18.0 #> [142,] 20.6 14.4 42.8 46.5 19.6 #> [143,] 21.0 15.0 42.9 47.2 19.4 #> [144,] 21.5 15.5 45.5 49.7 20.9 #> [145,] 21.6 15.4 45.7 49.7 20.6 #> [146,] 21.6 14.8 43.4 48.2 20.1 #> [147,] 21.9 15.7 45.4 51.0 21.1 #> [148,] 22.1 15.8 44.6 49.6 20.5 #> [149,] 23.0 16.8 47.2 52.1 21.5 #> [150,] 23.1 15.7 47.6 52.8 21.6 #> [151,] 10.7  9.7 21.4 24.0  9.8 #> [152,] 11.4  9.2 21.7 24.1  9.7 #> [153,] 12.5 10.0 24.1 27.0 10.9 #> [154,] 12.6 11.5 25.0 28.1 11.5 #> [155,] 12.9 11.2 25.8 29.1 11.9 #> [156,] 14.0 11.9 27.0 31.4 12.6 #> [157,] 14.0 12.8 28.8 32.4 12.7 #> [158,] 14.3 12.2 28.1 31.8 12.5 #> [159,] 14.7 13.2 29.6 33.4 12.9 #> [160,] 14.9 13.0 30.0 33.7 13.3 #> [161,] 15.0 12.3 30.1 33.3 14.0 #> [162,] 15.6 13.5 31.2 35.1 14.1 #> [163,] 15.6 14.0 31.6 35.3 13.8 #> [164,] 15.6 14.1 31.0 34.5 13.8 #> [165,] 15.7 13.6 31.0 34.8 13.8 #> [166,] 16.1 13.6 31.6 36.0 14.0 #> [167,] 16.1 13.7 31.4 36.1 13.9 #> [168,] 16.2 14.0 31.6 35.6 13.7 #> [169,] 16.7 14.3 32.3 37.0 14.7 #> [170,] 17.1 14.5 33.1 37.2 14.6 #> [171,] 17.5 14.3 34.5 39.6 15.6 #> [172,] 17.5 14.4 34.5 39.0 16.0 #> [173,] 17.5 14.7 33.3 37.6 14.6 #> [174,] 17.6 14.0 34.0 38.6 15.5 #> [175,] 18.0 14.9 34.7 39.5 15.7 #> [176,] 18.0 16.3 37.9 43.0 17.2 #> [177,] 18.3 15.7 35.1 40.5 16.1 #> [178,] 18.4 15.5 35.6 40.0 15.9 #> [179,] 18.4 15.7 36.5 41.6 16.4 #> [180,] 18.5 14.6 37.0 42.0 16.6 #> [181,] 18.6 14.5 34.7 39.4 15.0 #> [182,] 18.8 15.2 35.8 40.5 16.6 #> [183,] 18.9 16.7 36.3 41.7 15.3 #> [184,] 19.1 16.0 37.8 42.3 16.8 #> [185,] 19.1 16.3 37.9 42.6 17.2 #> [186,] 19.7 16.7 39.9 43.6 18.2 #> [187,] 19.9 16.6 39.4 43.9 17.9 #> [188,] 19.9 17.9 40.1 46.4 17.9 #> [189,] 20.0 16.7 40.4 45.1 17.7 #> [190,] 20.1 17.2 39.8 44.1 18.6 #> [191,] 20.3 16.0 39.4 44.1 18.0 #> [192,] 20.5 17.5 40.0 45.5 19.2 #> [193,] 20.6 17.5 41.5 46.2 19.2 #> [194,] 20.9 16.5 39.9 44.7 17.5 #> [195,] 21.3 18.4 43.8 48.4 20.0 #> [196,] 21.4 18.0 41.2 46.2 18.7 #> [197,] 21.7 17.1 41.7 47.2 19.6 #> [198,] 21.9 17.2 42.6 47.4 19.5 #> [199,] 22.5 17.2 43.0 48.7 19.8 #> [200,] 23.1 20.2 46.2 52.5 21.1 #>  #> attr(,\"class\") #> [1] \"list\"        \"PPtreeclass\"   PPclassify2(Tree.crab) #> $predict.error #> [1] NA #>  #> $predict.class #>        [,1] #>   [1,]    2 #>   [2,]    2 #>   [3,]    2 #>   [4,]    2 #>   [5,]    2 #>   [6,]    2 #>   [7,]    1 #>   [8,]    2 #>   [9,]    2 #>  [10,]    1 #>  [11,]    2 #>  [12,]    1 #>  [13,]    2 #>  [14,]    2 #>  [15,]    2 #>  [16,]    1 #>  [17,]    2 #>  [18,]    2 #>  [19,]    1 #>  [20,]    2 #>  [21,]    2 #>  [22,]    2 #>  [23,]    2 #>  [24,]    2 #>  [25,]    2 #>  [26,]    2 #>  [27,]    2 #>  [28,]    2 #>  [29,]    2 #>  [30,]    2 #>  [31,]    2 #>  [32,]    2 #>  [33,]    2 #>  [34,]    2 #>  [35,]    2 #>  [36,]    2 #>  [37,]    2 #>  [38,]    2 #>  [39,]    2 #>  [40,]    2 #>  [41,]    2 #>  [42,]    2 #>  [43,]    2 #>  [44,]    2 #>  [45,]    2 #>  [46,]    2 #>  [47,]    2 #>  [48,]    2 #>  [49,]    2 #>  [50,]    2 #>  [51,]    2 #>  [52,]    1 #>  [53,]    1 #>  [54,]    2 #>  [55,]    2 #>  [56,]    1 #>  [57,]    1 #>  [58,]    1 #>  [59,]    1 #>  [60,]    1 #>  [61,]    1 #>  [62,]    1 #>  [63,]    1 #>  [64,]    1 #>  [65,]    1 #>  [66,]    1 #>  [67,]    1 #>  [68,]    1 #>  [69,]    1 #>  [70,]    1 #>  [71,]    1 #>  [72,]    1 #>  [73,]    1 #>  [74,]    1 #>  [75,]    1 #>  [76,]    1 #>  [77,]    1 #>  [78,]    1 #>  [79,]    1 #>  [80,]    1 #>  [81,]    1 #>  [82,]    1 #>  [83,]    1 #>  [84,]    1 #>  [85,]    1 #>  [86,]    1 #>  [87,]    1 #>  [88,]    1 #>  [89,]    1 #>  [90,]    1 #>  [91,]    1 #>  [92,]    1 #>  [93,]    1 #>  [94,]    1 #>  [95,]    1 #>  [96,]    1 #>  [97,]    1 #>  [98,]    1 #>  [99,]    1 #> [100,]    1 #> [101,]    4 #> [102,]    4 #> [103,]    4 #> [104,]    4 #> [105,]    4 #> [106,]    4 #> [107,]    4 #> [108,]    4 #> [109,]    4 #> [110,]    4 #> [111,]    4 #> [112,]    4 #> [113,]    4 #> [114,]    4 #> [115,]    4 #> [116,]    4 #> [117,]    4 #> [118,]    4 #> [119,]    4 #> [120,]    4 #> [121,]    4 #> [122,]    4 #> [123,]    4 #> [124,]    4 #> [125,]    4 #> [126,]    4 #> [127,]    4 #> [128,]    4 #> [129,]    4 #> [130,]    4 #> [131,]    4 #> [132,]    4 #> [133,]    4 #> [134,]    4 #> [135,]    4 #> [136,]    4 #> [137,]    4 #> [138,]    4 #> [139,]    4 #> [140,]    4 #> [141,]    4 #> [142,]    4 #> [143,]    4 #> [144,]    4 #> [145,]    4 #> [146,]    4 #> [147,]    4 #> [148,]    4 #> [149,]    4 #> [150,]    4 #> [151,]    3 #> [152,]    4 #> [153,]    4 #> [154,]    3 #> [155,]    3 #> [156,]    3 #> [157,]    3 #> [158,]    3 #> [159,]    3 #> [160,]    3 #> [161,]    4 #> [162,]    3 #> [163,]    3 #> [164,]    3 #> [165,]    3 #> [166,]    3 #> [167,]    3 #> [168,]    3 #> [169,]    3 #> [170,]    3 #> [171,]    3 #> [172,]    3 #> [173,]    3 #> [174,]    3 #> [175,]    3 #> [176,]    3 #> [177,]    3 #> [178,]    3 #> [179,]    3 #> [180,]    3 #> [181,]    3 #> [182,]    3 #> [183,]    3 #> [184,]    3 #> [185,]    3 #> [186,]    3 #> [187,]    3 #> [188,]    3 #> [189,]    3 #> [190,]    3 #> [191,]    3 #> [192,]    3 #> [193,]    3 #> [194,]    3 #> [195,]    3 #> [196,]    3 #> [197,]    3 #> [198,]    3 #> [199,]    3 #> [200,]    3 #>"},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":null,"dir":"Reference","previous_headings":"","what":"Projection Pursuit Random Forest — PPforest","title":"Projection Pursuit Random Forest — PPforest","text":"PPforest implements random forest using projection pursuit trees algorithm (based PPtreeViz package).","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Projection Pursuit Random Forest — PPforest","text":"","code":"PPforest(data, class, std = TRUE, size.tr, m, PPmethod, size.p,  lambda = .1, parallel = FALSE, cores = 2, rule = 1)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Projection Pursuit Random Forest — PPforest","text":"data Data frame complete data set. class character name class variable. std TRUE standardize data set, needed compute global importance measure. size.tr size proportion training want split data training test. m number bootstrap replicates, corresponds number trees grow. ensure observation predicted times select number small. m = 500 default. PPmethod projection pursuit index optimize classification tree. options LDA PDA, linear discriminant penalized linear discriminant. default LDA. size.p proportion variables randomly sampled split. lambda penalty parameter PDA index 0 1 . lambda = 0, penalty parameter added PDA index LDA index. lambda = 1 variables treated uncorrelated. default value lambda = 0.1. parallel logical condition, TRUE  parallelize function cores number cores used parallelization rule split rule 1: mean two group means 2: weighted mean two group means - weight group size 3: weighted mean two group means - weight group sd 4: weighted mean two group means - weight group se 5: mean two group medians 6: weighted mean two group medians - weight group size 7: weighted mean two group median - weight group IQR 8: weighted mean two group median - weight group IQR size","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Projection Pursuit Random Forest — PPforest","text":"object class PPforest components. prediction.training predicted values training data set. training.error error training data set. prediction.test predicted values test data set testap = TRUE(default). error.test error test data set testap = TRUE(default). oob.error.forest bag error forest. oob.error.tree bag error tree forest. boot.samp information bootrap samples. output.trees output trees_pp bootrap sample. proximity Proximity matrix, two cases classified terminal node proximity matrix increased one PPforest one terminal node per class. votes matrix one row input data point one column class, giving fraction (OOB) votes PPforest. n.tree number trees grown PPforest. n.var number predictor variables selected use spliting node. type classification. confusion confusion matrix prediction (based OOB data). call original call PPforest. train training data based size.tr sample proportion test test data based 1-size.tr sample proportion","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Projection Pursuit Random Forest — PPforest","text":"Natalia da Silva, Dianne Cook & Eun-Kyung Lee (2021) Projection Pursuit Forest Algorithm Supervised Classification, Journal Computational Graphical Statistics, DOI: 10.1080/10618600.2020.1870480","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPforest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Projection Pursuit Random Forest — PPforest","text":"","code":"#crab example with all the observations used as training set.seed(123) pprf.crab <- PPforest(data = crab, class = 'Type',  std = FALSE, size.tr = 0.7, m = 200, size.p = .5,   PPmethod = 'LDA' , parallel = TRUE, cores = 2, rule=1) pprf.crab #>  #> Call: #>  PPforest(data = crab, class = \"Type\", std = FALSE, size.tr = 0.7,      m = 200, PPmethod = \"LDA\", size.p = 0.5, parallel = TRUE,      cores = 2, rule = 1)  #>                Type of random forest: Classification #>                      Number of trees: 200 #> No. of variables tried at each split: 3 #>  #>         OOB estimate of  error rate: 5% #> Confusion matrix: #>              BlueFemale BlueMale OrangeFemale OrangeMale class.error #> BlueFemale           33        2            0          0        0.06 #> BlueMale              3       32            0          0        0.09 #> OrangeFemale          0        0           33          2        0.06 #> OrangeMale            0        0            0         35        0.00"},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"Find tree structure using various projection pursuit indices classification split.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"","code":"PPtree_split(form, data, PPmethod='LDA',  size.p=1,  lambda = 0.1,...)"},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"form character name class variable. data Data frame complete data set. PPmethod index use projection pursuit: 'LDA', 'PDA' size.p proportion variables randomly sampled split, default 1, returns PPtree. lambda penalty parameter PDA index 0 1 . lambda = 0, penalty parameter added PDA index LDA index. lambda = 1 variables treated uncorrelated. default value lambda = 0.1. ... arguments passed methods","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"object class PPtreeclass components Tree.Struct Tree structure projection pursuit classification tree projbest.node 1-dim optimal projections split node splitCutoff.node cutoff values split node origclass_num original class numeric origdata original data","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"Lee, YD, Cook, D., Park JW, Lee, EK (2013) PPtree: Projection pursuit classification tree, Electronic Journal Statistics, 7:1369-1386.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/PPtree_split.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Projection pursuit classification tree with random variable selection in each split — PPtree_split","text":"","code":"#crab data set  Tree.crab <- PPtree_split('Type~.', data = crab, PPmethod = 'LDA', size.p = 0.5) Tree.crab #> $Tree.Struct #>      id L.node.ID R.F.node.ID Coef.ID     Index #> [1,]  1         2           3       1 0.8355102 #> [2,]  2         4           5       2 0.8176681 #> [3,]  3         6           7       3 0.2075079 #> [4,]  4         0           4       0 0.0000000 #> [5,]  5         0           3       0 0.0000000 #> [6,]  6         0           1       0 0.0000000 #> [7,]  7         0           2       0 0.0000000 #>  #> $projbest.node #>            [,1]      [,2]       [,3]       [,4]       [,5] #> [1,] -0.7569527 0.0000000 -0.3091091  0.5757380  0.0000000 #> [2,]  0.1648817 0.9130497 -0.3730340  0.0000000  0.0000000 #> [3,]  0.0000000 0.0000000  0.7806121 -0.5254337 -0.3384735 #>  #> $splitCutoff.node #>        Rule1      Rule2      Rule3      Rule4      Rule5      Rule6      Rule7 #> 1 -0.7544874 -0.7544874 -0.6154436 -0.6154436 -0.7648766 -0.7648766 -0.5880624 #> 2  2.4518051  2.4518051  2.2411676  2.2411676  2.5249566  2.5249566  2.4950510 #> 3  0.9631451  0.9631451  0.9390422  0.9390422  0.9609781  0.9609781  0.9432945 #>        Rule8 #> 1 -0.5880624 #> 2  2.4950510 #> 3  0.9432945 #>  #> $origclass #>            1            2            3            4            5            6  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>            7            8            9           10           11           12  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           13           14           15           16           17           18  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           19           20           21           22           23           24  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           25           26           27           28           29           30  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           31           32           33           34           35           36  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           37           38           39           40           41           42  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           43           44           45           46           47           48  #>     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale     BlueMale  #>           49           50           51           52           53           54  #>     BlueMale     BlueMale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           55           56           57           58           59           60  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           61           62           63           64           65           66  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           67           68           69           70           71           72  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           73           74           75           76           77           78  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           79           80           81           82           83           84  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           85           86           87           88           89           90  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           91           92           93           94           95           96  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale   BlueFemale  #>           97           98           99          100          101          102  #>   BlueFemale   BlueFemale   BlueFemale   BlueFemale   OrangeMale   OrangeMale  #>          103          104          105          106          107          108  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          109          110          111          112          113          114  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          115          116          117          118          119          120  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          121          122          123          124          125          126  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          127          128          129          130          131          132  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          133          134          135          136          137          138  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          139          140          141          142          143          144  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          145          146          147          148          149          150  #>   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale   OrangeMale  #>          151          152          153          154          155          156  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          157          158          159          160          161          162  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          163          164          165          166          167          168  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          169          170          171          172          173          174  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          175          176          177          178          179          180  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          181          182          183          184          185          186  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          187          188          189          190          191          192  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          193          194          195          196          197          198  #> OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale OrangeFemale  #>          199          200  #> OrangeFemale OrangeFemale  #> Levels: BlueFemale BlueMale OrangeFemale OrangeMale #>  #> $origclass_num #>   [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 #>  [38] 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 #>  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 #> [112] 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 #> [149] 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #> [186] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 #>  #> $origdata #>          FL   RW   CL   CW   BD #>   [1,]  8.1  6.7 16.1 19.0  7.0 #>   [2,]  8.8  7.7 18.1 20.8  7.4 #>   [3,]  9.2  7.8 19.0 22.4  7.7 #>   [4,]  9.6  7.9 20.1 23.1  8.2 #>   [5,]  9.8  8.0 20.3 23.0  8.2 #>   [6,] 10.8  9.0 23.0 26.5  9.8 #>   [7,] 11.1  9.9 23.8 27.1  9.8 #>   [8,] 11.6  9.1 24.5 28.4 10.4 #>   [9,] 11.8  9.6 24.2 27.8  9.7 #>  [10,] 11.8 10.5 25.2 29.3 10.3 #>  [11,] 12.2 10.8 27.3 31.6 10.9 #>  [12,] 12.3 11.0 26.8 31.5 11.4 #>  [13,] 12.6 10.0 27.7 31.7 11.4 #>  [14,] 12.8 10.2 27.2 31.8 10.9 #>  [15,] 12.8 10.9 27.4 31.5 11.0 #>  [16,] 12.9 11.0 26.8 30.9 11.4 #>  [17,] 13.1 10.6 28.2 32.3 11.0 #>  [18,] 13.1 10.9 28.3 32.4 11.2 #>  [19,] 13.3 11.1 27.8 32.3 11.3 #>  [20,] 13.9 11.1 29.2 33.3 12.1 #>  [21,] 14.3 11.6 31.3 35.5 12.7 #>  [22,] 14.6 11.3 31.9 36.4 13.7 #>  [23,] 15.0 10.9 31.4 36.4 13.2 #>  [24,] 15.0 11.5 32.4 37.0 13.4 #>  [25,] 15.0 11.9 32.5 37.2 13.6 #>  [26,] 15.2 12.1 32.3 36.7 13.6 #>  [27,] 15.4 11.8 33.0 37.5 13.6 #>  [28,] 15.7 12.6 35.8 40.3 14.5 #>  [29,] 15.9 12.7 34.0 38.9 14.2 #>  [30,] 16.1 11.6 33.8 39.0 14.4 #>  [31,] 16.1 12.8 34.9 40.7 15.7 #>  [32,] 16.2 13.3 36.0 41.7 15.4 #>  [33,] 16.3 12.7 35.6 40.9 14.9 #>  [34,] 16.4 13.0 35.7 41.8 15.2 #>  [35,] 16.6 13.5 38.1 43.4 14.9 #>  [36,] 16.8 12.8 36.2 41.8 14.9 #>  [37,] 16.9 13.2 37.3 42.7 15.6 #>  [38,] 17.1 12.6 36.4 42.0 15.1 #>  [39,] 17.1 12.7 36.7 41.9 15.6 #>  [40,] 17.2 13.5 37.6 43.9 16.1 #>  [41,] 17.7 13.6 38.7 44.5 16.0 #>  [42,] 17.9 14.1 39.7 44.6 16.8 #>  [43,] 18.0 13.7 39.2 44.4 16.2 #>  [44,] 18.8 15.8 42.1 49.0 17.8 #>  [45,] 19.3 13.5 41.6 47.4 17.8 #>  [46,] 19.3 13.8 40.9 46.5 16.8 #>  [47,] 19.7 15.3 41.9 48.5 17.8 #>  [48,] 19.8 14.2 43.2 49.7 18.6 #>  [49,] 19.8 14.3 42.4 48.9 18.3 #>  [50,] 21.3 15.7 47.1 54.6 20.0 #>  [51,]  7.2  6.5 14.7 17.1  6.1 #>  [52,]  9.0  8.5 19.3 22.7  7.7 #>  [53,]  9.1  8.1 18.5 21.6  7.7 #>  [54,]  9.1  8.2 19.2 22.2  7.7 #>  [55,]  9.5  8.2 19.6 22.4  7.8 #>  [56,]  9.8  8.9 20.4 23.9  8.8 #>  [57,] 10.1  9.3 20.9 24.4  8.4 #>  [58,] 10.3  9.5 21.3 24.7  8.9 #>  [59,] 10.4  9.7 21.7 25.4  8.3 #>  [60,] 10.8  9.5 22.5 26.3  9.1 #>  [61,] 11.0  9.8 22.5 25.7  8.2 #>  [62,] 11.2 10.0 22.8 26.9  9.4 #>  [63,] 11.5 11.0 24.7 29.2 10.1 #>  [64,] 11.6 11.0 24.6 28.5 10.4 #>  [65,] 11.6 11.4 23.7 27.7 10.0 #>  [66,] 11.7 10.6 24.9 28.5 10.4 #>  [67,] 11.9 11.4 26.0 30.1 10.9 #>  [68,] 12.0 10.7 24.6 28.9 10.5 #>  [69,] 12.0 11.1 25.4 29.2 11.0 #>  [70,] 12.6 12.2 26.1 31.6 11.2 #>  [71,] 12.8 11.7 27.1 31.2 11.9 #>  [72,] 12.8 12.2 26.7 31.1 11.1 #>  [73,] 12.8 12.2 27.9 31.9 11.5 #>  [74,] 13.0 11.4 27.3 31.8 11.3 #>  [75,] 13.1 11.5 27.6 32.6 11.1 #>  [76,] 13.2 12.2 27.9 32.1 11.5 #>  [77,] 13.4 11.8 28.4 32.7 11.7 #>  [78,] 13.7 12.5 28.6 33.8 11.9 #>  [79,] 13.9 13.0 30.0 34.9 13.1 #>  [80,] 14.7 12.5 30.1 34.7 12.5 #>  [81,] 14.9 13.2 30.1 35.6 12.0 #>  [82,] 15.0 13.8 31.7 36.9 14.0 #>  [83,] 15.0 14.2 32.8 37.4 14.0 #>  [84,] 15.1 13.3 31.8 36.3 13.5 #>  [85,] 15.1 13.5 31.9 37.0 13.8 #>  [86,] 15.1 13.8 31.7 36.6 13.0 #>  [87,] 15.2 14.3 33.9 38.5 14.7 #>  [88,] 15.3 14.2 32.6 38.3 13.8 #>  [89,] 15.4 13.3 32.4 37.6 13.8 #>  [90,] 15.5 13.8 33.4 38.7 14.7 #>  [91,] 15.6 13.9 32.8 37.9 13.4 #>  [92,] 15.6 14.7 33.9 39.5 14.3 #>  [93,] 15.7 13.9 33.6 38.5 14.1 #>  [94,] 15.8 15.0 34.5 40.3 15.3 #>  [95,] 16.2 15.2 34.5 40.1 13.9 #>  [96,] 16.4 14.0 34.2 39.8 15.2 #>  [97,] 16.7 16.1 36.6 41.9 15.4 #>  [98,] 17.4 16.9 38.2 44.1 16.6 #>  [99,] 17.5 16.7 38.6 44.5 17.0 #> [100,] 19.2 16.5 40.9 47.9 18.1 #> [101,]  9.1  6.9 16.7 18.6  7.4 #> [102,] 10.2  8.2 20.2 22.2  9.0 #> [103,] 10.7  8.6 20.7 22.7  9.2 #> [104,] 11.4  9.0 22.7 24.8 10.1 #> [105,] 12.5  9.4 23.2 26.0 10.8 #> [106,] 12.5  9.4 24.2 27.0 11.2 #> [107,] 12.7 10.4 26.0 28.8 12.1 #> [108,] 13.2 11.0 27.1 30.4 12.2 #> [109,] 13.4 10.1 26.6 29.6 12.0 #> [110,] 13.7 11.0 27.5 30.5 12.2 #> [111,] 14.0 11.5 29.2 32.2 13.1 #> [112,] 14.1 10.4 28.9 31.8 13.5 #> [113,] 14.1 10.5 29.1 31.6 13.1 #> [114,] 14.1 10.7 28.7 31.9 13.3 #> [115,] 14.2 10.6 28.7 31.7 12.9 #> [116,] 14.2 10.7 27.8 30.9 12.7 #> [117,] 14.2 11.3 29.2 32.2 13.5 #> [118,] 14.6 11.3 29.9 33.5 12.8 #> [119,] 14.7 11.1 29.0 32.1 13.1 #> [120,] 15.1 11.4 30.2 33.3 14.0 #> [121,] 15.1 11.5 30.9 34.0 13.9 #> [122,] 15.4 11.1 30.2 33.6 13.5 #> [123,] 15.7 12.2 31.7 34.2 14.2 #> [124,] 16.2 11.8 32.3 35.3 14.7 #> [125,] 16.3 11.6 31.6 34.2 14.5 #> [126,] 17.1 12.6 35.0 38.9 15.7 #> [127,] 17.4 12.8 36.1 39.5 16.2 #> [128,] 17.5 12.0 34.4 37.3 15.3 #> [129,] 17.5 12.7 34.6 38.4 16.1 #> [130,] 17.8 12.5 36.0 39.8 16.7 #> [131,] 17.9 12.9 36.9 40.9 16.5 #> [132,] 18.0 13.4 36.7 41.3 17.1 #> [133,] 18.2 13.7 38.8 42.7 17.2 #> [134,] 18.4 13.4 37.9 42.2 17.7 #> [135,] 18.6 13.4 37.8 41.9 17.3 #> [136,] 18.6 13.5 36.9 40.2 17.0 #> [137,] 18.8 13.4 37.2 41.1 17.5 #> [138,] 18.8 13.8 39.2 43.3 17.9 #> [139,] 19.4 14.1 39.1 43.2 17.8 #> [140,] 19.4 14.4 39.8 44.3 17.9 #> [141,] 20.1 13.7 40.6 44.5 18.0 #> [142,] 20.6 14.4 42.8 46.5 19.6 #> [143,] 21.0 15.0 42.9 47.2 19.4 #> [144,] 21.5 15.5 45.5 49.7 20.9 #> [145,] 21.6 15.4 45.7 49.7 20.6 #> [146,] 21.6 14.8 43.4 48.2 20.1 #> [147,] 21.9 15.7 45.4 51.0 21.1 #> [148,] 22.1 15.8 44.6 49.6 20.5 #> [149,] 23.0 16.8 47.2 52.1 21.5 #> [150,] 23.1 15.7 47.6 52.8 21.6 #> [151,] 10.7  9.7 21.4 24.0  9.8 #> [152,] 11.4  9.2 21.7 24.1  9.7 #> [153,] 12.5 10.0 24.1 27.0 10.9 #> [154,] 12.6 11.5 25.0 28.1 11.5 #> [155,] 12.9 11.2 25.8 29.1 11.9 #> [156,] 14.0 11.9 27.0 31.4 12.6 #> [157,] 14.0 12.8 28.8 32.4 12.7 #> [158,] 14.3 12.2 28.1 31.8 12.5 #> [159,] 14.7 13.2 29.6 33.4 12.9 #> [160,] 14.9 13.0 30.0 33.7 13.3 #> [161,] 15.0 12.3 30.1 33.3 14.0 #> [162,] 15.6 13.5 31.2 35.1 14.1 #> [163,] 15.6 14.0 31.6 35.3 13.8 #> [164,] 15.6 14.1 31.0 34.5 13.8 #> [165,] 15.7 13.6 31.0 34.8 13.8 #> [166,] 16.1 13.6 31.6 36.0 14.0 #> [167,] 16.1 13.7 31.4 36.1 13.9 #> [168,] 16.2 14.0 31.6 35.6 13.7 #> [169,] 16.7 14.3 32.3 37.0 14.7 #> [170,] 17.1 14.5 33.1 37.2 14.6 #> [171,] 17.5 14.3 34.5 39.6 15.6 #> [172,] 17.5 14.4 34.5 39.0 16.0 #> [173,] 17.5 14.7 33.3 37.6 14.6 #> [174,] 17.6 14.0 34.0 38.6 15.5 #> [175,] 18.0 14.9 34.7 39.5 15.7 #> [176,] 18.0 16.3 37.9 43.0 17.2 #> [177,] 18.3 15.7 35.1 40.5 16.1 #> [178,] 18.4 15.5 35.6 40.0 15.9 #> [179,] 18.4 15.7 36.5 41.6 16.4 #> [180,] 18.5 14.6 37.0 42.0 16.6 #> [181,] 18.6 14.5 34.7 39.4 15.0 #> [182,] 18.8 15.2 35.8 40.5 16.6 #> [183,] 18.9 16.7 36.3 41.7 15.3 #> [184,] 19.1 16.0 37.8 42.3 16.8 #> [185,] 19.1 16.3 37.9 42.6 17.2 #> [186,] 19.7 16.7 39.9 43.6 18.2 #> [187,] 19.9 16.6 39.4 43.9 17.9 #> [188,] 19.9 17.9 40.1 46.4 17.9 #> [189,] 20.0 16.7 40.4 45.1 17.7 #> [190,] 20.1 17.2 39.8 44.1 18.6 #> [191,] 20.3 16.0 39.4 44.1 18.0 #> [192,] 20.5 17.5 40.0 45.5 19.2 #> [193,] 20.6 17.5 41.5 46.2 19.2 #> [194,] 20.9 16.5 39.9 44.7 17.5 #> [195,] 21.3 18.4 43.8 48.4 20.0 #> [196,] 21.4 18.0 41.2 46.2 18.7 #> [197,] 21.7 17.1 41.7 47.2 19.6 #> [198,] 21.9 17.2 42.6 47.4 19.5 #> [199,] 22.5 17.2 43.0 48.7 19.8 #> [200,] 23.1 20.2 46.2 52.5 21.1 #>  #> attr(,\"class\") #> [1] \"list\"         \"PPtree_split\""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":null,"dir":"Reference","previous_headings":"","what":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"bootstrap sample grow projection pursuit tree (PPtree object).","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"","code":"baggtree(   data,   class,   m = 500,   PPmethod = \"LDA\",   lambda = 0.1,   size.p = 1,   parallel = FALSE,   cores = 2 )"},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"data Data frame complete data set. class character name class variable. m number bootstrap replicates, corresponds number trees grow. ensure observation predicted times select number small. m = 500 default. PPmethod projection pursuit index optimized, options LDA PDA, default LDA. lambda parameter PDA index size.p proportion random sample variables split  size.p= 1 bagging size.p<1 forest. parallel logical condition, TRUE  parallelize function cores number cores used parallelization","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"data frame trees_pp output bootstraps samples.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/baggtree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"For each bootstrap sample grow a projection pursuit tree (PPtree object). — baggtree","text":"","code":"#crab data set crab.trees <- baggtree(data = crab, class = 'Type', m =  200, PPmethod = 'LDA', lambda = .1, size.p = 1 , parallel = TRUE, cores = 2) str(crab.trees, max.level = 1) #> List of 200 #>  $ 1  :List of 2 #>  $ 2  :List of 2 #>  $ 3  :List of 2 #>  $ 4  :List of 2 #>  $ 5  :List of 2 #>  $ 6  :List of 2 #>  $ 7  :List of 2 #>  $ 8  :List of 2 #>  $ 9  :List of 2 #>  $ 10 :List of 2 #>  $ 11 :List of 2 #>  $ 12 :List of 2 #>  $ 13 :List of 2 #>  $ 14 :List of 2 #>  $ 15 :List of 2 #>  $ 16 :List of 2 #>  $ 17 :List of 2 #>  $ 18 :List of 2 #>  $ 19 :List of 2 #>  $ 20 :List of 2 #>  $ 21 :List of 2 #>  $ 22 :List of 2 #>  $ 23 :List of 2 #>  $ 24 :List of 2 #>  $ 25 :List of 2 #>  $ 26 :List of 2 #>  $ 27 :List of 2 #>  $ 28 :List of 2 #>  $ 29 :List of 2 #>  $ 30 :List of 2 #>  $ 31 :List of 2 #>  $ 32 :List of 2 #>  $ 33 :List of 2 #>  $ 34 :List of 2 #>  $ 35 :List of 2 #>  $ 36 :List of 2 #>  $ 37 :List of 2 #>  $ 38 :List of 2 #>  $ 39 :List of 2 #>  $ 40 :List of 2 #>  $ 41 :List of 2 #>  $ 42 :List of 2 #>  $ 43 :List of 2 #>  $ 44 :List of 2 #>  $ 45 :List of 2 #>  $ 46 :List of 2 #>  $ 47 :List of 2 #>  $ 48 :List of 2 #>  $ 49 :List of 2 #>  $ 50 :List of 2 #>  $ 51 :List of 2 #>  $ 52 :List of 2 #>  $ 53 :List of 2 #>  $ 54 :List of 2 #>  $ 55 :List of 2 #>  $ 56 :List of 2 #>  $ 57 :List of 2 #>  $ 58 :List of 2 #>  $ 59 :List of 2 #>  $ 60 :List of 2 #>  $ 61 :List of 2 #>  $ 62 :List of 2 #>  $ 63 :List of 2 #>  $ 64 :List of 2 #>  $ 65 :List of 2 #>  $ 66 :List of 2 #>  $ 67 :List of 2 #>  $ 68 :List of 2 #>  $ 69 :List of 2 #>  $ 70 :List of 2 #>  $ 71 :List of 2 #>  $ 72 :List of 2 #>  $ 73 :List of 2 #>  $ 74 :List of 2 #>  $ 75 :List of 2 #>  $ 76 :List of 2 #>  $ 77 :List of 2 #>  $ 78 :List of 2 #>  $ 79 :List of 2 #>  $ 80 :List of 2 #>  $ 81 :List of 2 #>  $ 82 :List of 2 #>  $ 83 :List of 2 #>  $ 84 :List of 2 #>  $ 85 :List of 2 #>  $ 86 :List of 2 #>  $ 87 :List of 2 #>  $ 88 :List of 2 #>  $ 89 :List of 2 #>  $ 90 :List of 2 #>  $ 91 :List of 2 #>  $ 92 :List of 2 #>  $ 93 :List of 2 #>  $ 94 :List of 2 #>  $ 95 :List of 2 #>  $ 96 :List of 2 #>  $ 97 :List of 2 #>  $ 98 :List of 2 #>  $ 99 :List of 2 #>   [list output truncated] #>  - attr(*, \"split_type\")= chr \"data.frame\" #>  - attr(*, \"split_labels\")='data.frame':\t200 obs. of  1 variable:"},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":null,"dir":"Reference","previous_headings":"","what":"Astralian crabs — crab","title":"Astralian crabs — crab","text":"Measurements rock crabs genus Leptograpsus. data set contains 200 observations  two species crab (blue orange), 50 specimens sex species,   collected site Fremantle, Western Australia. Type class variable 4 classes combinations specie sex (BlueMale, BlueFemale, OrangeMale OrangeFemale) FL size frontal lobe length, mm RW rear width, mm CL length midline carapace, mm CW maximum width carapace, mm BD depth body; females, measured displacement abdomen, mm","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Astralian crabs — crab","text":"","code":"data(crab)"},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Astralian crabs — crab","text":"data frame 200 rows 6 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/crab.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Astralian crabs — crab","text":"Campbell, N. . & Mahon, R. J. (1974), Multivariate Study Variation Two Species Rock Crab genus Leptograpsus, Australian Journal Zoology 22(3), 417 - 425.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Fish catch data set — fishcatch","title":"Fish catch data set — fishcatch","text":"159 fishes 7 species caught measured. Altogether   7 variables.  fishes caught lake(Laengelmavesi) near Tampere Finland. Type 7 fish classes, 35 cases Bream, 11 cases Parkki, 56 cases Perch 17 cases Pike, 20 cases Roach, 14 cases Smelt 6 cases Whitewish. weight Weight fish (grams) length1 Length nose beginning tail (cm) length2 Length nose notch tail (cm) length3 Length nose end tail (cm) height Maximal height % Length3 width Maximal width % Length3","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fish catch data set — fishcatch","text":"","code":"data(fishcatch)"},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Fish catch data set — fishcatch","text":"data frame 159 rows 7 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/fishcatch.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Fish catch data set — fishcatch","text":"[http://www.amstat.org/publications/jse/jse_data_archive.htm](fishcatch)","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/glass.html","id":null,"dir":"Reference","previous_headings":"","what":"Glass data set — glass","title":"Glass data set — glass","text":"Contains measurements 214 observations 6 types glass; defined terms oxide content. Type 6 types glasses X1 refractive index X2 Sodium (unit measurement: weight percent corresponding oxide). X3 Magnesium X4 Aluminum X5 Silicon X6 Potassium X7 Calcium X8 Barium X9 Iron","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/glass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Glass data set — glass","text":"","code":"data(glass)"},{"path":"https://github.com/natydasilva/PPforest/reference/glass.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Glass data set — glass","text":"data frame 214 rows 10 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/image.html","id":null,"dir":"Reference","previous_headings":"","what":"The image data set — image","title":"The image data set — image","text":"contains  2310 observations instances 7 outdoor images Type 7 types outdoor images, brickface, cement,  foliage, grass, path, sky, window. X1 column center pixel region X2 row center pixel region. X3 number pixels region = 9. X4 results line extraction algorithm counts many lines length 5 (orientation) low contrast, less equal 5, go region. X5 measure contrast horizontally adjacent pixels region. 6, mean standard deviation given. attribute used vertical edge detector. X6 X5 sd X7 measures contrast vertically adjacent pixels. Used horizontal line detection. X8 sd X7 X9 average region (R + G + B)/3 X10 average region R value. X11 average region B value. X12 average region G value. X13 measure excess red: (2R - (G + B)) X14 measure excess blue: (2B - (G + R)) X15 measure excess green: (2G - (R + B)) X16 3-d nonlinear transformation RGB. (Algorithm can found Foley VanDam, Fundamentals Interactive Computer Graphics) X17 mean X16 X18 hue  mean","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/image.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The image data set — image","text":"","code":"data(image)"},{"path":"https://github.com/natydasilva/PPforest/reference/image.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The image data set — image","text":"data frame contains 2310 observations 19 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":null,"dir":"Reference","previous_headings":"","what":"Leukemia data set This dataset comes from a study of gene expression in two types of acute leukemias, acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML). Gene expression levels were measured using Affymetrix high density oligonucleotide arrays containing 6817 human genes. A data set containing 72 observations from 3 leukemia types classes.  Type has 3 classes with 38 cases of B-cell ALL, 25 cases of AML and 9 cases of T-cell ALL . Gene1 to Gen 40 gene expression levels  — leukemia","title":"Leukemia data set This dataset comes from a study of gene expression in two types of acute leukemias, acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML). Gene expression levels were measured using Affymetrix high density oligonucleotide arrays containing 6817 human genes. A data set containing 72 observations from 3 leukemia types classes.  Type has 3 classes with 38 cases of B-cell ALL, 25 cases of AML and 9 cases of T-cell ALL . Gene1 to Gen 40 gene expression levels  — leukemia","text":"Leukemia data set dataset comes study gene expression two types acute leukemias, acute lymphoblastic leukemia () acute myeloid leukemia (AML). Gene expression levels measured using Affymetrix high density oligonucleotide arrays containing 6817 human genes. data set containing 72 observations 3 leukemia types classes. Type 3 classes 38 cases B-cell , 25 cases AML 9 cases T-cell Gene1 Gen 40 gene expression levels","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Leukemia data set This dataset comes from a study of gene expression in two types of acute leukemias, acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML). Gene expression levels were measured using Affymetrix high density oligonucleotide arrays containing 6817 human genes. A data set containing 72 observations from 3 leukemia types classes.  Type has 3 classes with 38 cases of B-cell ALL, 25 cases of AML and 9 cases of T-cell ALL . Gene1 to Gen 40 gene expression levels  — leukemia","text":"","code":"data(leukemia)"},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Leukemia data set This dataset comes from a study of gene expression in two types of acute leukemias, acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML). Gene expression levels were measured using Affymetrix high density oligonucleotide arrays containing 6817 human genes. A data set containing 72 observations from 3 leukemia types classes.  Type has 3 classes with 38 cases of B-cell ALL, 25 cases of AML and 9 cases of T-cell ALL . Gene1 to Gen 40 gene expression levels  — leukemia","text":"data frame 72 rows 41 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/leukemia.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Leukemia data set This dataset comes from a study of gene expression in two types of acute leukemias, acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML). Gene expression levels were measured using Affymetrix high density oligonucleotide arrays containing 6817 human genes. A data set containing 72 observations from 3 leukemia types classes.  Type has 3 classes with 38 cases of B-cell ALL, 25 cases of AML and 9 cases of T-cell ALL . Gene1 to Gen 40 gene expression levels  — leukemia","text":"Dudoit, S., Fridlyand, J. Speed, T. P. (2002). Comparison Discrimination Methods Classification Tumors Using Gene Expression Data. Journal American statistical Association 97 77-87.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":null,"dir":"Reference","previous_headings":"","what":"Lymphoma data set — lymphoma","title":"Lymphoma data set — lymphoma","text":"Gene expression three prevalent adult lymphoid malignancies: B-cell chronic lymphocytic leukemia (B-CLL), follicular lymphoma (FL), diffuse large B-cell lym- phoma (DLBCL). Gene expression levels measured using specialized cDNA microarray, Lymphochip, containing genes preferentially expressed lymphoid cells known immunologic oncologic importance. data set contain 80 observations 3 lymphoma types. Type Class variable 3 classes 29 cases B-cell (B-CLL), 42 cases diffuse large B-cell lymphoma (DLBCL) 9 cases follicular lymphoma (FL) Gene1 Gen 50 gene expression","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lymphoma data set — lymphoma","text":"","code":"data(lymphoma)"},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Lymphoma data set — lymphoma","text":"data frame 80 rows 51 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/lymphoma.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Lymphoma data set — lymphoma","text":"Dudoit, S., Fridlyand, J. Speed, T. P. (2002). Comparison Discrimination Methods Classification Tumors Using Gene Ex- pression Data. Journal American statistical Association 97 77-87.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Data structure with the projected and boundary by node and class. — node_data","title":"Data structure with the projected and boundary by node and class. — node_data","text":"Data structure  projected boundary node class.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data structure with the projected and boundary by node and class. — node_data","text":"","code":"node_data(ppf, tr, Rule = 1)"},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data structure with the projected and boundary by node and class. — node_data","text":"ppf PPforest object tr numerical value  identify tree Rule split rule 1:mean two group means, 2:weighted mean, 3: mean max(left group) min(right group), 4: weighted mean max(left group) min(right group)","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data structure with the projected and boundary by node and class. — node_data","text":"Data frame projected data class node id boundaries","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/node_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data structure with the projected and boundary by node and class. — node_data","text":"","code":"#crab data set with all the observations used as training  pprf.crab <- PPforest(data = crab, std =TRUE, class = 'Type',  size.tr = 1, m = 200, size.p = .5, PPmethod = 'LDA') node_data(ppf = pprf.crab, tr = 1)  #>                proj.data        Class          cut node.id LR.class   Dir #> 100...1     -0.136705852   BlueFemale  0.007882217       1        L FALSE #> 84...2      -0.080607983   BlueFemale  0.007882217       1        L FALSE #> 71...3      -0.028568960   BlueFemale  0.007882217       1        L FALSE #> 67...4      -0.116914319   BlueFemale  0.007882217       1        L FALSE #> 92...5      -0.184399798   BlueFemale  0.007882217       1        L FALSE #> 58...6      -0.092855685   BlueFemale  0.007882217       1        L FALSE #> 60...7      -0.166550064   BlueFemale  0.007882217       1        L FALSE #> 95...8      -0.273875326   BlueFemale  0.007882217       1        L FALSE #> 66...9      -0.082019930   BlueFemale  0.007882217       1        L FALSE #> 69...10     -0.040858575   BlueFemale  0.007882217       1        L FALSE #> 90...11     -0.069867755   BlueFemale  0.007882217       1        L FALSE #> 60.1...12   -0.166550064   BlueFemale  0.007882217       1        L FALSE #> 51...13     -0.056115025   BlueFemale  0.007882217       1        L FALSE #> 71.1...14   -0.028568960   BlueFemale  0.007882217       1        L FALSE #> 75...15     -0.261867490   BlueFemale  0.007882217       1        L FALSE #> 72...16     -0.154493765   BlueFemale  0.007882217       1        L FALSE #> 68...17     -0.122454181   BlueFemale  0.007882217       1        L FALSE #> 94...18     -0.090201539   BlueFemale  0.007882217       1        L FALSE #> 73...19     -0.118368179   BlueFemale  0.007882217       1        L FALSE #> 77...20     -0.145536590   BlueFemale  0.007882217       1        L FALSE #> 99...21     -0.066184817   BlueFemale  0.007882217       1        L FALSE #> 89...22     -0.138770683   BlueFemale  0.007882217       1        L FALSE #> 61...23     -0.237071448   BlueFemale  0.007882217       1        L FALSE #> 66.1...24   -0.082019930   BlueFemale  0.007882217       1        L FALSE #> 99.1...25   -0.066184817   BlueFemale  0.007882217       1        L FALSE #> 80...26     -0.147807580   BlueFemale  0.007882217       1        L FALSE #> 89.1...27   -0.138770683   BlueFemale  0.007882217       1        L FALSE #> 69.1...28   -0.040858575   BlueFemale  0.007882217       1        L FALSE #> 89.2...29   -0.138770683   BlueFemale  0.007882217       1        L FALSE #> 77.1...30   -0.145536590   BlueFemale  0.007882217       1        L FALSE #> 96...31     -0.068970902   BlueFemale  0.007882217       1        L FALSE #> 60.2...32   -0.166550064   BlueFemale  0.007882217       1        L FALSE #> 65...33     -0.118145516   BlueFemale  0.007882217       1        L FALSE #> 55...34     -0.104004478   BlueFemale  0.007882217       1        L FALSE #> 61.1...35   -0.237071448   BlueFemale  0.007882217       1        L FALSE #> 99.2...36   -0.066184817   BlueFemale  0.007882217       1        L FALSE #> 65.1...37   -0.118145516   BlueFemale  0.007882217       1        L FALSE #> 87...38     -0.025283934   BlueFemale  0.007882217       1        L FALSE #> 90.1...39   -0.069867755   BlueFemale  0.007882217       1        L FALSE #> 56...40     -0.070653975   BlueFemale  0.007882217       1        L FALSE #> 62...41     -0.168746834   BlueFemale  0.007882217       1        L FALSE #> 64...42     -0.096665410   BlueFemale  0.007882217       1        L FALSE #> 56.1...43   -0.070653975   BlueFemale  0.007882217       1        L FALSE #> 56.2...44   -0.070653975   BlueFemale  0.007882217       1        L FALSE #> 100.1...45  -0.136705852   BlueFemale  0.007882217       1        L FALSE #> 100.2...46  -0.136705852   BlueFemale  0.007882217       1        L FALSE #> 57...47     -0.154923986   BlueFemale  0.007882217       1        L FALSE #> 96.1...48   -0.068970902   BlueFemale  0.007882217       1        L FALSE #> 79...49     -0.085500462   BlueFemale  0.007882217       1        L FALSE #> 70...50     -0.219660840   BlueFemale  0.007882217       1        L FALSE #> 23...51     -0.153904449     BlueMale  0.007882217       1        L FALSE #> 36...52     -0.216763073     BlueMale  0.007882217       1        L FALSE #> 5...53      -0.072113336     BlueMale  0.007882217       1        L FALSE #> 17...54     -0.216875104     BlueMale  0.007882217       1        L FALSE #> 35...55     -0.285405877     BlueMale  0.007882217       1        L FALSE #> 16...56     -0.085755434     BlueMale  0.007882217       1        L FALSE #> 42...57     -0.051693281     BlueMale  0.007882217       1        L FALSE #> 11...58     -0.204760738     BlueMale  0.007882217       1        L FALSE #> 25...59     -0.122660690     BlueMale  0.007882217       1        L FALSE #> 14...60     -0.229817253     BlueMale  0.007882217       1        L FALSE #> 10...61     -0.162633810     BlueMale  0.007882217       1        L FALSE #> 48...62     -0.133193011     BlueMale  0.007882217       1        L FALSE #> 17.1...63   -0.216875104     BlueMale  0.007882217       1        L FALSE #> 24...64     -0.136489039     BlueMale  0.007882217       1        L FALSE #> 2...65      -0.074076790     BlueMale  0.007882217       1        L FALSE #> 28...66     -0.143222637     BlueMale  0.007882217       1        L FALSE #> 33...67     -0.155267934     BlueMale  0.007882217       1        L FALSE #> 30...68     -0.124284298     BlueMale  0.007882217       1        L FALSE #> 17.2...69   -0.216875104     BlueMale  0.007882217       1        L FALSE #> 45...70     -0.095778161     BlueMale  0.007882217       1        L FALSE #> 32...71     -0.143636355     BlueMale  0.007882217       1        L FALSE #> 16.1...72   -0.085755434     BlueMale  0.007882217       1        L FALSE #> 20...73     -0.108763621     BlueMale  0.007882217       1        L FALSE #> 9...74      -0.147505544     BlueMale  0.007882217       1        L FALSE #> 44...75     -0.232766537     BlueMale  0.007882217       1        L FALSE #> 48.1...76   -0.133193011     BlueMale  0.007882217       1        L FALSE #> 29...77     -0.133554512     BlueMale  0.007882217       1        L FALSE #> 17.3...78   -0.216875104     BlueMale  0.007882217       1        L FALSE #> 50...79     -0.233233169     BlueMale  0.007882217       1        L FALSE #> 12...80     -0.146279499     BlueMale  0.007882217       1        L FALSE #> 31...81     -0.052781188     BlueMale  0.007882217       1        L FALSE #> 6...82      -0.060391382     BlueMale  0.007882217       1        L FALSE #> 25.1...83   -0.122660690     BlueMale  0.007882217       1        L FALSE #> 5.1...84    -0.072113336     BlueMale  0.007882217       1        L FALSE #> 9.1...85    -0.147505544     BlueMale  0.007882217       1        L FALSE #> 15...86     -0.175230962     BlueMale  0.007882217       1        L FALSE #> 30.1...87   -0.124284298     BlueMale  0.007882217       1        L FALSE #> 37...88     -0.151924842     BlueMale  0.007882217       1        L FALSE #> 9.2...89    -0.147505544     BlueMale  0.007882217       1        L FALSE #> 44.1...90   -0.232766537     BlueMale  0.007882217       1        L FALSE #> 36.1...91   -0.216763073     BlueMale  0.007882217       1        L FALSE #> 39...92     -0.100517047     BlueMale  0.007882217       1        L FALSE #> 8...93      -0.091459892     BlueMale  0.007882217       1        L FALSE #> 18...94     -0.192959411     BlueMale  0.007882217       1        L FALSE #> 34...95     -0.197490390     BlueMale  0.007882217       1        L FALSE #> 27...96     -0.128513590     BlueMale  0.007882217       1        L FALSE #> 18.1...97   -0.192959411     BlueMale  0.007882217       1        L FALSE #> 13...98     -0.122517749     BlueMale  0.007882217       1        L FALSE #> 3...99      -0.147856043     BlueMale  0.007882217       1        L FALSE #> 12.1...100  -0.146279499     BlueMale  0.007882217       1        L FALSE #> 195...101    0.231081900 OrangeFemale  0.007882217       1        R  TRUE #> 191...102    0.158825227 OrangeFemale  0.007882217       1        R  TRUE #> 188...103   -0.053571511 OrangeFemale  0.007882217       1        R FALSE #> 158...104    0.047088873 OrangeFemale  0.007882217       1        R  TRUE #> 157...105    0.049858804 OrangeFemale  0.007882217       1        R  TRUE #> 199...106    0.132644044 OrangeFemale  0.007882217       1        R  TRUE #> 172...107    0.142858175 OrangeFemale  0.007882217       1        R  TRUE #> 174...108    0.085995392 OrangeFemale  0.007882217       1        R  TRUE #> 159...109    0.017161184 OrangeFemale  0.007882217       1        R  TRUE #> 180...110    0.049647143 OrangeFemale  0.007882217       1        R  TRUE #> 164...111    0.105591418 OrangeFemale  0.007882217       1        R  TRUE #> 162...112    0.098512822 OrangeFemale  0.007882217       1        R  TRUE #> 185...113    0.120423149 OrangeFemale  0.007882217       1        R  TRUE #> 165...114    0.075329385 OrangeFemale  0.007882217       1        R  TRUE #> 191.1...115  0.158825227 OrangeFemale  0.007882217       1        R  TRUE #> 155...116    0.119801525 OrangeFemale  0.007882217       1        R  TRUE #> 192...117    0.221620632 OrangeFemale  0.007882217       1        R  TRUE #> 172.1...118  0.142858175 OrangeFemale  0.007882217       1        R  TRUE #> 188.1...119 -0.053571511 OrangeFemale  0.007882217       1        R FALSE #> 184...120    0.087560933 OrangeFemale  0.007882217       1        R  TRUE #> 173...121    0.021650600 OrangeFemale  0.007882217       1        R  TRUE #> 182...122    0.142375389 OrangeFemale  0.007882217       1        R  TRUE #> 151...123    0.113683000 OrangeFemale  0.007882217       1        R  TRUE #> 161...124    0.211824321 OrangeFemale  0.007882217       1        R  TRUE #> 186...125    0.262792291 OrangeFemale  0.007882217       1        R  TRUE #> 161.1...126  0.211824321 OrangeFemale  0.007882217       1        R  TRUE #> 191.2...127  0.158825227 OrangeFemale  0.007882217       1        R  TRUE #> 166...128    0.012693424 OrangeFemale  0.007882217       1        R  TRUE #> 185.1...129  0.120423149 OrangeFemale  0.007882217       1        R  TRUE #> 197...130    0.191369252 OrangeFemale  0.007882217       1        R  TRUE #> 156...131    0.048298763 OrangeFemale  0.007882217       1        R  TRUE #> 157.1...132  0.049858804 OrangeFemale  0.007882217       1        R  TRUE #> 184.1...133  0.087560933 OrangeFemale  0.007882217       1        R  TRUE #> 172.2...134  0.142858175 OrangeFemale  0.007882217       1        R  TRUE #> 192.1...135  0.221620632 OrangeFemale  0.007882217       1        R  TRUE #> 199.1...136  0.132644044 OrangeFemale  0.007882217       1        R  TRUE #> 154...137    0.123377933 OrangeFemale  0.007882217       1        R  TRUE #> 173.1...138  0.021650600 OrangeFemale  0.007882217       1        R  TRUE #> 186.1...139  0.262792291 OrangeFemale  0.007882217       1        R  TRUE #> 155.1...140  0.119801525 OrangeFemale  0.007882217       1        R  TRUE #> 200...141    0.094831282 OrangeFemale  0.007882217       1        R  TRUE #> 163...142    0.054183623 OrangeFemale  0.007882217       1        R  TRUE #> 153...143    0.103038649 OrangeFemale  0.007882217       1        R  TRUE #> 185.2...144  0.120423149 OrangeFemale  0.007882217       1        R  TRUE #> 190...145    0.265716165 OrangeFemale  0.007882217       1        R  TRUE #> 168...146    0.009360985 OrangeFemale  0.007882217       1        R  TRUE #> 169...147    0.047917006 OrangeFemale  0.007882217       1        R  TRUE #> 165.1...148  0.075329385 OrangeFemale  0.007882217       1        R  TRUE #> 154.1...149  0.123377933 OrangeFemale  0.007882217       1        R  TRUE #> 169.1...150  0.047917006 OrangeFemale  0.007882217       1        R  TRUE #> 109...151    0.122980021   OrangeMale  0.007882217       1        R  TRUE #> 127...152    0.199651889   OrangeMale  0.007882217       1        R  TRUE #> 126...153    0.133672835   OrangeMale  0.007882217       1        R  TRUE #> 148...154    0.221891408   OrangeMale  0.007882217       1        R  TRUE #> 118...155    0.007158714   OrangeMale  0.007882217       1        R FALSE #> 124...156    0.219401858   OrangeMale  0.007882217       1        R  TRUE #> 105...157    0.145415047   OrangeMale  0.007882217       1        R  TRUE #> 144...158    0.313982924   OrangeMale  0.007882217       1        R  TRUE #> 120...159    0.216706148   OrangeMale  0.007882217       1        R  TRUE #> 137...160    0.281242343   OrangeMale  0.007882217       1        R  TRUE #> 109.1...161  0.122980021   OrangeMale  0.007882217       1        R  TRUE #> 123...162    0.228268658   OrangeMale  0.007882217       1        R  TRUE #> 139...163    0.205844634   OrangeMale  0.007882217       1        R  TRUE #> 104...164    0.140129807   OrangeMale  0.007882217       1        R  TRUE #> 141...165    0.177057768   OrangeMale  0.007882217       1        R  TRUE #> 116...166    0.152350702   OrangeMale  0.007882217       1        R  TRUE #> 119...167    0.148126911   OrangeMale  0.007882217       1        R  TRUE #> 116.1...168  0.152350702   OrangeMale  0.007882217       1        R  TRUE #> 102...169    0.120188435   OrangeMale  0.007882217       1        R  TRUE #> 126.1...170  0.133672835   OrangeMale  0.007882217       1        R  TRUE #> 134...171    0.233575553   OrangeMale  0.007882217       1        R  TRUE #> 146...172    0.246289888   OrangeMale  0.007882217       1        R  TRUE #> 102.1...173  0.120188435   OrangeMale  0.007882217       1        R  TRUE #> 150...174    0.205717848   OrangeMale  0.007882217       1        R  TRUE #> 116.2...175  0.152350702   OrangeMale  0.007882217       1        R  TRUE #> 147...176    0.207086833   OrangeMale  0.007882217       1        R  TRUE #> 135...177    0.200713338   OrangeMale  0.007882217       1        R  TRUE #> 123.1...178  0.228268658   OrangeMale  0.007882217       1        R  TRUE #> 141.1...179  0.177057768   OrangeMale  0.007882217       1        R  TRUE #> 102.2...180  0.120188435   OrangeMale  0.007882217       1        R  TRUE #> 137.1...181  0.281242343   OrangeMale  0.007882217       1        R  TRUE #> 118.1...182  0.007158714   OrangeMale  0.007882217       1        R FALSE #> 142...183    0.315680753   OrangeMale  0.007882217       1        R  TRUE #> 127.1...184  0.199651889   OrangeMale  0.007882217       1        R  TRUE #> 114...185    0.182777331   OrangeMale  0.007882217       1        R  TRUE #> 141.2...186  0.177057768   OrangeMale  0.007882217       1        R  TRUE #> 105.1...187  0.145415047   OrangeMale  0.007882217       1        R  TRUE #> 142.1...188  0.315680753   OrangeMale  0.007882217       1        R  TRUE #> 114.1...189  0.182777331   OrangeMale  0.007882217       1        R  TRUE #> 138...190    0.215199722   OrangeMale  0.007882217       1        R  TRUE #> 149...191    0.242241346   OrangeMale  0.007882217       1        R  TRUE #> 105.2...192  0.145415047   OrangeMale  0.007882217       1        R  TRUE #> 143...193    0.220829959   OrangeMale  0.007882217       1        R  TRUE #> 141.3...194  0.177057768   OrangeMale  0.007882217       1        R  TRUE #> 120.1...195  0.216706148   OrangeMale  0.007882217       1        R  TRUE #> 117...196    0.206045642   OrangeMale  0.007882217       1        R  TRUE #> 111...197    0.147803220   OrangeMale  0.007882217       1        R  TRUE #> 129...198    0.222824672   OrangeMale  0.007882217       1        R  TRUE #> 145...199    0.280064761   OrangeMale  0.007882217       1        R  TRUE #> 127.2...200  0.199651889   OrangeMale  0.007882217       1        R  TRUE #> 100...201   -0.175091888   BlueFemale -0.162968406       2        R FALSE #> 84...202    -0.108167149   BlueFemale -0.162968406       2        R  TRUE #> 71...203    -0.015382255   BlueFemale -0.162968406       2        R  TRUE #> 67...204    -0.135408253   BlueFemale -0.162968406       2        R  TRUE #> 92...205    -0.239067949   BlueFemale -0.162968406       2        R FALSE #> 58...206    -0.066145149   BlueFemale -0.162968406       2        R  TRUE #> 60...207    -0.161079605   BlueFemale -0.162968406       2        R  TRUE #> 95...208    -0.351141033   BlueFemale -0.162968406       2        R FALSE #> 66...209    -0.087368031   BlueFemale -0.162968406       2        R  TRUE #> 69...210    -0.027668014   BlueFemale -0.162968406       2        R  TRUE #> 90...211    -0.090319694   BlueFemale -0.162968406       2        R  TRUE #> 60.1...212  -0.161079605   BlueFemale -0.162968406       2        R  TRUE #> 51...213     0.004005905   BlueFemale -0.162968406       2        R  TRUE #> 71.1...214  -0.015382255   BlueFemale -0.162968406       2        R  TRUE #> 75...215    -0.290433730   BlueFemale -0.162968406       2        R FALSE #> 72...216    -0.159450067   BlueFemale -0.162968406       2        R  TRUE #> 68...217    -0.095281488   BlueFemale -0.162968406       2        R  TRUE #> 94...218    -0.115613436   BlueFemale -0.162968406       2        R  TRUE #> 73...219    -0.158244293   BlueFemale -0.162968406       2        R  TRUE #> 77...220    -0.174071207   BlueFemale -0.162968406       2        R FALSE #> 99...221    -0.125560830   BlueFemale -0.162968406       2        R  TRUE #> 89...222    -0.162696475   BlueFemale -0.162968406       2        R  TRUE #> 61...223    -0.270002539   BlueFemale -0.162968406       2        R FALSE #> 66.1...224  -0.087368031   BlueFemale -0.162968406       2        R  TRUE #> 99.1...225  -0.125560830   BlueFemale -0.162968406       2        R  TRUE #> 80...226    -0.163186723   BlueFemale -0.162968406       2        R FALSE #> 89.1...227  -0.162696475   BlueFemale -0.162968406       2        R  TRUE #> 69.1...228  -0.027668014   BlueFemale -0.162968406       2        R  TRUE #> 89.2...229  -0.162696475   BlueFemale -0.162968406       2        R  TRUE #> 77.1...230  -0.174071207   BlueFemale -0.162968406       2        R FALSE #> 96...231    -0.066238422   BlueFemale -0.162968406       2        R  TRUE #> 60.2...232  -0.161079605   BlueFemale -0.162968406       2        R  TRUE #> 65...233    -0.092131339   BlueFemale -0.162968406       2        R  TRUE #> 55...234    -0.088477546   BlueFemale -0.162968406       2        R  TRUE #> 61.1...235  -0.270002539   BlueFemale -0.162968406       2        R FALSE #> 99.2...236  -0.125560830   BlueFemale -0.162968406       2        R  TRUE #> 65.1...237  -0.092131339   BlueFemale -0.162968406       2        R  TRUE #> 87...238    -0.082104794   BlueFemale -0.162968406       2        R  TRUE #> 90.1...239  -0.090319694   BlueFemale -0.162968406       2        R  TRUE #> 56...240    -0.027571756   BlueFemale -0.162968406       2        R  TRUE #> 62...241    -0.145945139   BlueFemale -0.162968406       2        R  TRUE #> 64...242    -0.090925565   BlueFemale -0.162968406       2        R  TRUE #> 56.1...243  -0.027571756   BlueFemale -0.162968406       2        R  TRUE #> 56.2...244  -0.027571756   BlueFemale -0.162968406       2        R  TRUE #> 100.1...245 -0.175091888   BlueFemale -0.162968406       2        R FALSE #> 100.2...246 -0.175091888   BlueFemale -0.162968406       2        R FALSE #> 57...247    -0.140873691   BlueFemale -0.162968406       2        R  TRUE #> 96.1...248  -0.066238422   BlueFemale -0.162968406       2        R  TRUE #> 79...249    -0.095400824   BlueFemale -0.162968406       2        R  TRUE #> 70...250    -0.194594944   BlueFemale -0.162968406       2        R FALSE #> 23...251    -0.178735271     BlueMale -0.162968406       2        L FALSE #> 36...252    -0.298450143     BlueMale -0.162968406       2        L FALSE #> 5...253     -0.057711669     BlueMale -0.162968406       2        L  TRUE #> 17...254    -0.281291422     BlueMale -0.162968406       2        L FALSE #> 35...255    -0.456665227     BlueMale -0.162968406       2        L FALSE #> 16...256    -0.079438194     BlueMale -0.162968406       2        L  TRUE #> 42...257    -0.159152336     BlueMale -0.162968406       2        L  TRUE #> 11...258    -0.266391916     BlueMale -0.162968406       2        L FALSE #> 25...259    -0.177529497     BlueMale -0.162968406       2        L FALSE #> 14...260    -0.263934215     BlueMale -0.162968406       2        L FALSE #> 10...261    -0.178549451     BlueMale -0.162968406       2        L FALSE #> 48...262    -0.227789476     BlueMale -0.162968406       2        L FALSE #> 17.1...263  -0.281291422     BlueMale -0.162968406       2        L FALSE #> 24...264    -0.197019886     BlueMale -0.162968406       2        L FALSE #> 2...265     -0.039036049     BlueMale -0.162968406       2        L  TRUE #> 28...266    -0.272682533     BlueMale -0.162968406       2        L FALSE #> 33...267    -0.231244054     BlueMale -0.162968406       2        L FALSE #> 30...268    -0.154872579     BlueMale -0.162968406       2        L  TRUE #> 17.2...269  -0.281291422     BlueMale -0.162968406       2        L FALSE #> 45...270    -0.181882435     BlueMale -0.162968406       2        L FALSE #> 32...271    -0.214406869     BlueMale -0.162968406       2        L FALSE #> 16.1...272  -0.079438194     BlueMale -0.162968406       2        L  TRUE #> 20...273    -0.136190262     BlueMale -0.162968406       2        L  TRUE #> 9...274     -0.152026858     BlueMale -0.162968406       2        L  TRUE #> 44...275    -0.350770121     BlueMale -0.162968406       2        L FALSE #> 48.1...276  -0.227789476     BlueMale -0.162968406       2        L FALSE #> 29...277    -0.190921787     BlueMale -0.162968406       2        L FALSE #> 17.3...278  -0.281291422     BlueMale -0.162968406       2        L FALSE #> 50...279    -0.368525031     BlueMale -0.162968406       2        L FALSE #> 12...280    -0.157445905     BlueMale -0.162968406       2        L  TRUE #> 31...281    -0.065960057     BlueMale -0.162968406       2        L  TRUE #> 6...282     -0.045644489     BlueMale -0.162968406       2        L  TRUE #> 25.1...283  -0.177529497     BlueMale -0.162968406       2        L FALSE #> 5.1...284   -0.057711669     BlueMale -0.162968406       2        L  TRUE #> 9.1...285   -0.152026858     BlueMale -0.162968406       2        L  TRUE #> 15...286    -0.216414016     BlueMale -0.162968406       2        L FALSE #> 30.1...287  -0.154872579     BlueMale -0.162968406       2        L  TRUE #> 37...288    -0.245563751     BlueMale -0.162968406       2        L FALSE #> 9.2...289   -0.152026858     BlueMale -0.162968406       2        L  TRUE #> 44.1...290  -0.350770121     BlueMale -0.162968406       2        L FALSE #> 36.1...291  -0.298450143     BlueMale -0.162968406       2        L FALSE #> 39...292    -0.162898674     BlueMale -0.162968406       2        L  TRUE #> 8...293     -0.081481814     BlueMale -0.162968406       2        L  TRUE #> 18...294    -0.252357283     BlueMale -0.162968406       2        L FALSE #> 34...295    -0.255113443     BlueMale -0.162968406       2        L FALSE #> 27...296    -0.191630614     BlueMale -0.162968406       2        L FALSE #> 18.1...297  -0.252357283     BlueMale -0.162968406       2        L FALSE #> 13...298    -0.165660805     BlueMale -0.162968406       2        L FALSE #> 3...299     -0.118339093     BlueMale -0.162968406       2        L  TRUE #> 12.1...300  -0.157445905     BlueMale -0.162968406       2        L  TRUE #> 195...301   -0.657684908 OrangeFemale -0.086472974       3        L FALSE #> 191...302   -0.312964701 OrangeFemale -0.086472974       3        L FALSE #> 188...303   -0.678603025 OrangeFemale -0.086472974       3        L FALSE #> 158...304   -0.227506216 OrangeFemale -0.086472974       3        L FALSE #> 157...305   -0.353601411 OrangeFemale -0.086472974       3        L FALSE #> 199...306   -0.280106152 OrangeFemale -0.086472974       3        L FALSE #> 172...307   -0.270559869 OrangeFemale -0.086472974       3        L FALSE #> 174...308   -0.186554413 OrangeFemale -0.086472974       3        L FALSE #> 159...309   -0.387126677 OrangeFemale -0.086472974       3        L FALSE #> 180...310   -0.078544919 OrangeFemale -0.086472974       3        L  TRUE #> 164...311   -0.558814324 OrangeFemale -0.086472974       3        L FALSE #> 162...312   -0.332860896 OrangeFemale -0.086472974       3        L FALSE #> 185...313   -0.526669763 OrangeFemale -0.086472974       3        L FALSE #> 165...314   -0.387133836 OrangeFemale -0.086472974       3        L FALSE #> 191.1...315 -0.312964701 OrangeFemale -0.086472974       3        L FALSE #> 155...316   -0.160162065 OrangeFemale -0.086472974       3        L FALSE #> 192...317   -0.635987638 OrangeFemale -0.086472974       3        L FALSE #> 172.1...318 -0.270559869 OrangeFemale -0.086472974       3        L FALSE #> 188.1...319 -0.678603025 OrangeFemale -0.086472974       3        L FALSE #> 184...320   -0.463709177 OrangeFemale -0.086472974       3        L FALSE #> 173...321   -0.475232818 OrangeFemale -0.086472974       3        L FALSE #> 182...322   -0.379348517 OrangeFemale -0.086472974       3        L FALSE #> 151...323   -0.146732071 OrangeFemale -0.086472974       3        L FALSE #> 161...324   -0.131382725 OrangeFemale -0.086472974       3        L FALSE #> 186...325   -0.560253037 OrangeFemale -0.086472974       3        L FALSE #> 161.1...326 -0.131382725 OrangeFemale -0.086472974       3        L FALSE #> 191.2...327 -0.312964701 OrangeFemale -0.086472974       3        L FALSE #> 166...328   -0.286869549 OrangeFemale -0.086472974       3        L FALSE #> 185.1...329 -0.526669763 OrangeFemale -0.086472974       3        L FALSE #> 197...330   -0.376287650 OrangeFemale -0.086472974       3        L FALSE #> 156...331   -0.173055674 OrangeFemale -0.086472974       3        L FALSE #> 157.1...332 -0.353601411 OrangeFemale -0.086472974       3        L FALSE #> 184.1...333 -0.463709177 OrangeFemale -0.086472974       3        L FALSE #> 172.2...334 -0.270559869 OrangeFemale -0.086472974       3        L FALSE #> 192.1...335 -0.635987638 OrangeFemale -0.086472974       3        L FALSE #> 199.1...336 -0.280106152 OrangeFemale -0.086472974       3        L FALSE #> 154...337   -0.331664951 OrangeFemale -0.086472974       3        L FALSE #> 173.1...338 -0.475232818 OrangeFemale -0.086472974       3        L FALSE #> 186.1...339 -0.560253037 OrangeFemale -0.086472974       3        L FALSE #> 155.1...340 -0.160162065 OrangeFemale -0.086472974       3        L FALSE #> 200...341   -0.842675796 OrangeFemale -0.086472974       3        L FALSE #> 163...342   -0.462803270 OrangeFemale -0.086472974       3        L FALSE #> 153...343    0.016424057 OrangeFemale -0.086472974       3        L  TRUE #> 185.2...344 -0.526669763 OrangeFemale -0.086472974       3        L FALSE #> 190...345   -0.664955317 OrangeFemale -0.086472974       3        L FALSE #> 168...346   -0.437447160 OrangeFemale -0.086472974       3        L FALSE #> 169...347   -0.408421474 OrangeFemale -0.086472974       3        L FALSE #> 165.1...348 -0.387133836 OrangeFemale -0.086472974       3        L FALSE #> 154.1...349 -0.331664951 OrangeFemale -0.086472974       3        L FALSE #> 169.1...350 -0.408421474 OrangeFemale -0.086472974       3        L FALSE #> 109...351    0.204359797   OrangeMale -0.086472974       3        R  TRUE #> 127...352    0.240228364   OrangeMale -0.086472974       3        R  TRUE #> 126...353    0.248683980   OrangeMale -0.086472974       3        R  TRUE #> 148...354    0.205206377   OrangeMale -0.086472974       3        R  TRUE #> 118...355    0.178286120   OrangeMale -0.086472974       3        R  TRUE #> 124...356    0.182648210   OrangeMale -0.086472974       3        R  TRUE #> 105...357    0.109001144   OrangeMale -0.086472974       3        R  TRUE #> 144...358    0.301163002   OrangeMale -0.086472974       3        R  TRUE #> 120...359    0.132581233   OrangeMale -0.086472974       3        R  TRUE #> 137...360    0.198479512   OrangeMale -0.086472974       3        R  TRUE #> 109.1...361  0.204359797   OrangeMale -0.086472974       3        R  TRUE #> 123...362   -0.026629597   OrangeMale -0.086472974       3        R  TRUE #> 139...363    0.168623822   OrangeMale -0.086472974       3        R  TRUE #> 104...364    0.125622337   OrangeMale -0.086472974       3        R  TRUE #> 141...365    0.394689687   OrangeMale -0.086472974       3        R  TRUE #> 116...366    0.137254835   OrangeMale -0.086472974       3        R  TRUE #> 119...367    0.120285596   OrangeMale -0.086472974       3        R  TRUE #> 116.1...368  0.137254835   OrangeMale -0.086472974       3        R  TRUE #> 102...369    0.142772758   OrangeMale -0.086472974       3        R  TRUE #> 126.1...370  0.248683980   OrangeMale -0.086472974       3        R  TRUE #> 134...371    0.289943716   OrangeMale -0.086472974       3        R  TRUE #> 146...372    0.381440874   OrangeMale -0.086472974       3        R  TRUE #> 102.1...373  0.142772758   OrangeMale -0.086472974       3        R  TRUE #> 150...374    0.501862019   OrangeMale -0.086472974       3        R  TRUE #> 116.2...375  0.137254835   OrangeMale -0.086472974       3        R  TRUE #> 147...376    0.351117544   OrangeMale -0.086472974       3        R  TRUE #> 135...377    0.265051667   OrangeMale -0.086472974       3        R  TRUE #> 123.1...378 -0.026629597   OrangeMale -0.086472974       3        R  TRUE #> 141.1...379  0.394689687   OrangeMale -0.086472974       3        R  TRUE #> 102.2...380  0.142772758   OrangeMale -0.086472974       3        R  TRUE #> 137.1...381  0.198479512   OrangeMale -0.086472974       3        R  TRUE #> 118.1...382  0.178286120   OrangeMale -0.086472974       3        R  TRUE #> 142...383    0.356439968   OrangeMale -0.086472974       3        R  TRUE #> 127.1...384  0.240228364   OrangeMale -0.086472974       3        R  TRUE #> 114...385    0.220557041   OrangeMale -0.086472974       3        R  TRUE #> 141.2...386  0.394689687   OrangeMale -0.086472974       3        R  TRUE #> 105.1...387  0.109001144   OrangeMale -0.086472974       3        R  TRUE #> 142.1...388  0.356439968   OrangeMale -0.086472974       3        R  TRUE #> 114.1...389  0.220557041   OrangeMale -0.086472974       3        R  TRUE #> 138...390    0.264580448   OrangeMale -0.086472974       3        R  TRUE #> 149...391    0.120900145   OrangeMale -0.086472974       3        R  TRUE #> 105.2...392  0.109001144   OrangeMale -0.086472974       3        R  TRUE #> 143...393    0.239086848   OrangeMale -0.086472974       3        R  TRUE #> 141.3...394  0.394689687   OrangeMale -0.086472974       3        R  TRUE #> 120.1...395  0.132581233   OrangeMale -0.086472974       3        R  TRUE #> 117...396    0.069685812   OrangeMale -0.086472974       3        R  TRUE #> 111...397    0.010924030   OrangeMale -0.086472974       3        R  TRUE #> 129...398    0.177913020   OrangeMale -0.086472974       3        R  TRUE #> 145...399    0.330543893   OrangeMale -0.086472974       3        R  TRUE #> 127.2...400  0.240228364   OrangeMale -0.086472974       3        R  TRUE"},{"path":"https://github.com/natydasilva/PPforest/reference/olive.html","id":null,"dir":"Reference","previous_headings":"","what":"The olive data set — olive","title":"The olive data set — olive","text":"contains  572 observations 10 variables Region Three super-classes Italy: North, South island Sardinia area Nine collection areas: three North, four South 2 Sardinia palmitic fatty acids percent x 100 palmitoleic fatty acids percent x 100 stearic fatty acids percent x 100 oleic fatty acids percent x 100 linoleic fatty acids percent x 100 linolenic fatty acids percent x 100 arachidic fatty acids percent x 100 eicosenoic fatty acids percent x 100","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/olive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The olive data set — olive","text":"","code":"data(olive)"},{"path":"https://github.com/natydasilva/PPforest/reference/olive.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The olive data set — olive","text":"data frame contains 573 observations 10 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":null,"dir":"Reference","previous_headings":"","what":"Parkinson data set — parkinson","title":"Parkinson data set — parkinson","text":"data set containing 195 observations 2 parkinson types. Type Class variable 2 classes, 48 cases healthy people 147 cases Parkinson. feature variables biomedical voice measures X1 Average vocal fundamental frequency X2 Maximum vocal fundamental frequency X3 Minimum vocal fundamental frequency X4 MDVP:Jitter(%) measures variation fundamental frequency X5 MDVP:Jitter(Abs) measures variation fundamental frequency X6 MDVP:RAP measures variation fundamental frequency X7 MDVP:PPQ measures variation fundamental frequency X8 Jitter:DDP measures variation fundamental frequency X9 MDVP:Shimmer measures variation amplitude X10 MDVP:Shimmer(dB) measures variation amplitude X11 Shimmer:APQ3 measures variation amplitude X12 Shimmer:APQ5 measures variation amplitude X13 MDVP:APQ measures variation amplitude X14 Shimmer:DDA measures variation amplitude X15 NHR measures ratio noise tonal components voice X16 HNR measures ratio noise tonal components voice X17 RPDE nonlinear dynamical complexity measures X18 D2 nonlinear dynamical complexity measures X19 DFA - Signal fractal scaling exponent X20 spread1 Nonlinear measures fundamental frequency variation X21 spread2 Nonlinear measures fundamental frequency variation X22 PPE Nonlinear measures fundamental frequency variation","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parkinson data set — parkinson","text":"","code":"data(parkinson)"},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Parkinson data set — parkinson","text":"data frame 195 rows 23 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/parkinson.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Parkinson data set — parkinson","text":"[https://archive.ics.uci.edu/ml/datasets/Parkinsons](Parkinson)","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain the permuted importance variable measure — permute_importance","title":"Obtain the permuted importance variable measure — permute_importance","text":"Obtain permuted importance variable measure","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain the permuted importance variable measure — permute_importance","text":"","code":"permute_importance(ppf)"},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain the permuted importance variable measure — permute_importance","text":"ppf PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain the permuted importance variable measure — permute_importance","text":"data frame permuted importance measures, imp permuted importance measure defined Brieman paper, imp2 permuted importance measure defined randomForest package, standard deviation (sd.im sd.imp2) measure computed also standardized mesure.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/permute_importance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain the permuted importance variable measure — permute_importance","text":"","code":"pprf.crab <- PPforest(data = crab, class = 'Type', std = TRUE, size.tr = 1, m = 100, size.p = .4, PPmethod = 'LDA', parallel = TRUE, core = 2) permute_importance(ppf = pprf.crab)  #>   nm   imp   sd.imp      imp2   sd.imp2 imp2.std  imp.std #> 1 CW 11.69 10.98272 0.1601326 0.1496193 1.070267 1.064400 #> 2 BD 13.80 12.18046 0.1910307 0.1700485 1.123389 1.132962 #> 3 CL 15.03 12.03988 0.2062711 0.1638146 1.259174 1.248351 #> 4 FL 17.10 12.43691 0.2350805 0.1704783 1.378947 1.374939 #> 5 RW 17.24 11.36815 0.2356610 0.1548813 1.521559 1.516518"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"Global importance measure PPforest object average IMP PPtree measure trees forest","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"","code":"ppf_avg_imp(ppf, class)"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"ppf PPforest object class character name class variable.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"Data frame global importance measure","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_avg_imp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global importance measure for a PPforest object as the average IMP PPtree measure over all the trees in the forest — ppf_avg_imp","text":"","code":"#crab data set with all the observations used as training  pprf.crab <- PPforest(data = crab, std =TRUE, class = 'Type',  size.tr = 1, m = 100, size.p = .5, PPmethod = 'LDA')  ppf_avg_imp(pprf.crab, 'Type')  #> # A tibble: 5 × 2 #>   variable  mean #>   <fct>    <dbl> #> 1 CL       0.453 #> 2 CW       0.440 #> 3 RW       0.354 #> 4 BD       0.329 #> 5 FL       0.308"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Global importance measure for a PPforest object — ppf_global_imp","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"Global importance measure PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"","code":"ppf_global_imp(data, class, ppf)"},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"data Data frame complete data set. class character name class variable. ppf PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"Data frame global importance measure","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ppf_global_imp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Global importance measure for a PPforest object — ppf_global_imp","text":"","code":"#crab data set with all the observations used as training  pprf.crab <- PPforest(data = crab, std = TRUE, class = 'Type',  size.tr = 1, m = 200, size.p = .5, PPmethod = 'LDA', parallel = TRUE, cores = 2)   ppf_global_imp(data = crab, class = 'Type', pprf.crab)  #> # A tibble: 5 × 2 #>   variable  mean #>   <fct>    <dbl> #> 1 CW       0.395 #> 2 CL       0.369 #> 3 RW       0.289 #> 4 BD       0.254 #> 5 FL       0.230"},{"path":"https://github.com/natydasilva/PPforest/reference/predict.PPforest.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for PPforest objects — predict.PPforest","title":"Predict method for PPforest objects — predict.PPforest","text":"Predict method PPforest objects","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/predict.PPforest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for PPforest objects — predict.PPforest","text":"","code":"# S3 method for class 'PPforest' predict(object, newdata, rule = 1, parallel = TRUE, cores = 2, ...)"},{"path":"https://github.com/natydasilva/PPforest/reference/predict.PPforest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for PPforest objects — predict.PPforest","text":"object fitted PPforest object newdata data frame predictors (structure training data) rule Split rule used classification (integer 1 8) 1: mean two group means 2: weighted mean two group means - weight group size 3: weighted mean two group means - weight group sd 4: weighted mean two group means - weight group se 5: mean two group medians 6: weighted mean two group medians - weight group size 7: weighted mean two group median - weight group IQR 8: weighted mean two group median - weight group IQR size parallel Logical, whether use parallel processing cores Number cores use parallel = TRUE ... Additional arguments (ignored)","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/predict.PPforest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict method for PPforest objects — predict.PPforest","text":"list : predtree Matrix individual tree predictions predforest Final predicted classes based majority vote","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":null,"dir":"Reference","previous_headings":"","what":"Print PPforest object — print.PPforest","title":"Print PPforest object — print.PPforest","text":"Print PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print PPforest object — print.PPforest","text":"","code":"# S3 method for class 'PPforest' print(x, ...)"},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print PPforest object — print.PPforest","text":"x PPforest class object ... additional parameter","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/print.PPforest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print PPforest object — print.PPforest","text":"printed results PPforest object","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":null,"dir":"Reference","previous_headings":"","what":"Data structure with the projected and boundary by node and class. — ternary_str","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"Data structure  projected boundary node class.","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"","code":"ternary_str(ppf, id, sp, dx, dy)"},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"ppf PPforest object id vector selected projection directions sp simplex dimensions, k number classes sp = k - 1 dx first direction included id dy second direction included id","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"Data frame needed visualize ternary plot","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/ternary_str.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data structure with the projected and boundary by node and class. — ternary_str","text":"","code":"#crab data set with all the observations used as training pprf.crab <- PPforest(data = crab, std =TRUE, class = \"Type\",  size.tr = 1, m = 100, size.p = .5, PPmethod = 'LDA')  require(dplyr) #> Loading required package: dplyr #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union pl_ter <- function(dat, dx, dy ){   p1  <- dat[[1]] %>% dplyr::filter(pair %in% paste(dx, dy, sep = \"-\") ) %>%     dplyr::select(Class, x, y) %>%     ggplot2::ggplot(ggplot2::aes(x, y, color = Class)) +     ggplot2::geom_segment(data = dat[[2]], ggplot2::aes(x = x1, xend = x2,                                                y = y1, yend = y2), color = \"black\" ) +     ggplot2::geom_point(size = I(3), alpha = .5) +     ggplot2::labs(y = \" \",  x = \" \") +     ggplot2::theme(legend.position = \"none\", aspect.ratio = 1) +     ggplot2::scale_colour_brewer(type = \"qual\", palette = \"Dark2\") +     ggplot2::labs(x = paste0(\"T\", dx, \" \"), y = paste0(\"T\", dy, \" \")) +     ggplot2::theme(aspect.ratio = 1)   p1 } #ternary plot in tree different selected dierections  pl_ter(ternary_str(pprf.crab, id = c(1, 2, 3), sp = 3, dx = 1, dy = 2), 1, 2 ) #> Warning: `select_()` was deprecated in dplyr 0.7.0. #> ℹ Please use `select()` instead. #> ℹ The deprecated feature was likely used in the PPforest package. #>   Please report the issue to the authors."},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":null,"dir":"Reference","previous_headings":"","what":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"Obtain predicted class new data baggtree function PPforest","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"","code":"trees_pred(object, xnew, parallel = FALSE, cores = 2, rule = 1)"},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"object Projection pursuit classification forest structure PPforest baggtree xnew data frame explicative variables used get new predicted values. parallel logical condition, TRUE  parallelize function cores number cores used parallelization rule Split rule used classification (integer 1 8). 1: mean two group means 2: weighted mean two group means - weight group size 3: weighted mean two group means - weight group sd 4: weighted mean two group means - weight group se 5: mean two group medians 6: weighted mean two group medians - weight group size 7: weighted mean two group median - weight group IQR 8: weighted mean two group median - weight group IQR size","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"predicted values PPforest baggtree","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/trees_pred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Obtain predicted class for new data from baggtree function or PPforest — trees_pred","text":"","code":"if (FALSE) { # \\dontrun{ crab.trees <- baggtree(data = crab, class = 'Type',  m =  200, PPmethod = 'LDA', lambda = .1, size.p = 0.4 )   pr <- trees_pred(  crab.trees,xnew = crab[, -1], parallel= FALSE, cores = 2)  pprf.crab <- PPforest(data = crab, class = 'Type',  std = FALSE, size.tr = 2/3, m = 100, size.p = .4, PPmethod = 'LDA', parallel = TRUE )   trees_pred(pprf.crab, xnew = pprf.crab$test ,parallel = TRUE) pprf.crab$error.test } # }"},{"path":"https://github.com/natydasilva/PPforest/reference/wine.html","id":null,"dir":"Reference","previous_headings":"","what":"Wine data set — wine","title":"Wine data set — wine","text":"data set containing 178 observations 3 wine grown cultivares Italy. Type Class variable 3 classes 3 different wine grown cultivares Italy. X1 X13 Check vbles","code":""},{"path":"https://github.com/natydasilva/PPforest/reference/wine.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wine data set — wine","text":"","code":"data(wine)"},{"path":"https://github.com/natydasilva/PPforest/reference/wine.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Wine data set — wine","text":"data frame 178 rows 14 variables","code":""},{"path":"https://github.com/natydasilva/PPforest/news/index.html","id":"ppforest-013","dir":"Changelog","previous_headings":"","what":"PPforest 0.1.3","title":"PPforest 0.1.3","text":"CRAN release: 2022-09-09 fourth release package, minor changes included. Since R 4.2.0 switched use HTML5 documentation pages. Fix problems HTML generated package Rd files. Changed deprecated functions.","code":""}]
